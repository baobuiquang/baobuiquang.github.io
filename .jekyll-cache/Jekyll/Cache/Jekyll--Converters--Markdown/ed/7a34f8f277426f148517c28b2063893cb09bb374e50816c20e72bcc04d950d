I"î<p>Kubernetes is a tool for managing and automating containerized workloads in the cloud.</p>

<p>Imagine you have an orchestra. Think of each individual musician as a docker container. To create beautiful music, we need a conductor to manage the musicians and set the tempo.</p>

<p>Now imagine the conductor as Kubernetes and the orchestra as an app like Robinhood. When the markets are closed, an app like Robinhood isn‚Äôt doing much. But when they open it needs to fulfill millions of trades for overpriced stocks like Tesla and Shopify.</p>

<p>Kubernetes is the tool that orchestrates the infrastructure to handle the changing workload. It can scale containers across multiple machines. And if one fails, it knows how to replace it with a new one.</p>

<p>A system deployed on Kubernetes is known as a ‚Äúcluster‚Äù.</p>

<p>The brain of the operation is known as the ‚Äúcontrol plane‚Äù. It exposes an API server that can handle both internal and external requests to manage the cluster. It also contains its own key-value database called ‚ÄúETCD‚Äù, used to store important information about running the cluster.</p>

<p>What it‚Äôs managing is one or more worker machines called ‚Äúnodes‚Äù. When you hear node, think of a machine.</p>

<p>Each node is running something called a ‚Äúkubelet‚Äù, which is a tiny application that runs on the machine to communicate back with the main control plane mother ship.</p>

<p>Inside of each node, we have multiple ‚Äúpods‚Äù which is the smallest deployable unit in Kubernetes. When you hear pod, think of a pot of whales or containers running together.</p>

<p>As the workload increases, Kubernetes can automatically scale horizontally by adding more nodes to the cluster. In the process, it takes care of complicated things like networking, secret management, persistent storage, and so on.</p>

<p>It‚Äôs designed for high availability, and one way it achieves that is by maintaining a replica set, which is just a set of running pods or containers ready to go at any given time.</p>

<p>As a developer, you define objects in YAML that describe the desired state of your cluster. For example, we might have an Nginx deployment that has a replica set with three pods. In the spec field, we can define exactly how it should behave like its containers, volumes, ports, and so on.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
<span class="err">	</span><span class="na">name</span><span class="pi">:</span> <span class="s">nginx-deployment</span>
<span class="na">spec</span><span class="pi">:</span>
<span class="err">	</span><span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
<span class="err">	</span><span class="na">containers</span><span class="pi">:</span>
<span class="err">	</span><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="err">		</span><span class="na">image</span><span class="pi">:</span> <span class="na">nginx</span><span class="pi">:</span> <span class="s">1.14.5</span>
<span class="err">		</span><span class="na">ports</span><span class="pi">:</span>
<span class="err">		</span><span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
<span class="err">		</span><span class="na">volumes</span><span class="pi">:</span>
<span class="err">		</span><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume-oh-yeah</span>
</code></pre></div></div>

<p>You can then take this configuration and use it to provision and scale containers automatically and ensure that they‚Äôre always up and running and healthy.</p>
:ET