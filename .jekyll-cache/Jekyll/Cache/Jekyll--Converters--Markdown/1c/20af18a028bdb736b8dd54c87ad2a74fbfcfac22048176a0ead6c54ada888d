I"Ô®<h2 id="artificial-intelligence">Artificial intelligence</h2>

<p>At this exact moment in history, when people think about data science, the mind turns inexorably towards artificial intelligence, often with humanoid robots lost deep in thought. But before I compare and contrast data science and AI, I want to mention a few things about the nature of categories and definitions. First, categories are constructs, and by construct I mean something that you have to infer, something that is created in the mind, doesn‚Äôt have this essential existence. It‚Äôs a little bit like, when is something comedy and when is something performance art, and when is something acting? There‚Äôs nothing that clearly separates one from the other. These are all mental categories, and the same thing is true of any category or definition, including things like data science and AI. The second one is that categories serve functional purposes. A letter opener is anything that‚Äôs used to open letters. I actually use a knife to open letters. On the other hand, I know a family that uses knives to scoop ice cream exclusively. And, the tool is whatever you use it for. It‚Äôs defined by its utility. The same thing is true of categories. And then finally, the use of categories varies by needs. If you‚Äôre putting books on the shelf, you can use the Library of Congress system, the Dewey Decimal system. I know people who stack them by size or by color, or turn them around and do it decoratively. Any of those is going to work because they‚Äôre serving different purposes. And so, when we‚Äôre trying to think about categories and defining whether a particular activity is AI or whether it‚Äôs data science, all of these principles are going to apply. A good example of this is the question of whether tomatoes are fruits or vegetables. Everyone knows that tomatoes are supposed to be fruit, but everyone also knows you‚Äôd never put tomatoes in a fruit salad. Tomatoes go on veggie plates along with carrots and celery. The answer to this paradox, its fruit versus vegetable nature, is simple. The word fruit is a botanical term, and the word vegetable is a culinary term. They‚Äôre not parallel or even very well coordinated systems of categorizations, which is why confusion can arise. It‚Äôs a little like the joke about the bar that plays both kinds of music, country and western. The categories don‚Äôt always divide logically or exclusively, and the same is true for artificial intelligence and data science. So, what exactly is artificial intelligence? Well I‚Äôm going to let you know, there are a lot of different statements about this, and none of them are taken as definitive. And some of them I find to be useful, and some of them I find to be less useful. There‚Äôs a little joke that AI means anything that computers can‚Äôt do. Well, obviously, computers learn to do new things, but as soon as a computer learns how to do something, people say, well that‚Äôs not intelligent, that‚Äôs just a machine doing stuff. And so there‚Äôs a sort of moving target here to this particular definition in terms of things computers can‚Äôt do. You can also think of AI in terms of tasks that normally require humans. Like placing a phone call and making an appointment. Or like returning an email, or categorizing text. Traditionally humans have done that, but when a machine is able to do that, when a program‚Äôs able to do it, that‚Äôs probably a good example of artificial intelligence. Probably the most basic and useful definition is that artificial intelligence refers to programs that learn from data. And so, you give them some data, they build a model, and that that model adapts over time. A few common examples of this are things like categorizing photos. Is this a photo of a horse, a car, a balloon, a person? And programs learn how to do this by first having lots and lots, and lots, and lots of photos that are labeled by the people as one thing or another, as a cat or a dog. But then the algorithm is able to start learning on its own and abstracting the elements of the photo that best represent cat or dog. It‚Äôs also used for translations going from one language, like English, to another, like French. The use of artificial intelligence programs has made enormous leaps in the ability of computers to do this automatically. Another one is games, like Go here. It was a very big deal when not very long ago a computer was able to beat the world champion of Go. And, it was thought to be this intuitive game that couldn‚Äôt really be explained. What‚Äôs fascinating about that is the computer actually taught itself how to play go. And, we‚Äôll talk a little more about that when we talk about the derivation of rules in another video. But all three of these can be good examples of artificial intelligence, simply by the sorts of things it‚Äôs able to do. And so, probably, this is the best working definition of AI. And, while it can include even simple regression models, which really don‚Äôt require much in the way of computing power, it usually refers to two approaches in particular. AI is usually referring to machine learning algorithms, and in particular, deep learning neural networks. I‚Äôm going to talk about those more elsewhere, but I did want to bring up one more important distinction when talking about AI. And that‚Äôs the difference between what is called strong or general AI, which is the idea that you can build a computer replica of the human brain that can solve any cognitive task. This is what happens in science fiction. You have a machine that‚Äôs just like a human in a box. And that was the original goal of artificial intelligence back in the 50s, but it turned out that has been very difficult. Instead, you also have what is called weak or narrow, or specific, or focused AI. And these are algorithms that focus on one specific well defined task. Like, is this a photo of a cat or a photo of a dog? That has been where the enormous progress in AI has been over the last several years. So with all this in mind, how does artificial intelligence compare and contrast to data science? Well, it‚Äôs a little bit like the fruit versus vegetable conundrum. Artificial intelligence means algorithms that learn from data. Broadly speaking, there‚Äôs an enormous amount of overlap between our concept of AI and the field of machine learning. Data science on the other hand is the collection of skills and techniques for dealing with challenging data. You can see that these two are not exclusive. There‚Äôs a lot of overlap between them, and AI nearly always involves the data science skillset. You basically can‚Äôt do modern AI without data science. But there‚Äôs an enormous amount of data science that does not involve artificial intelligence. And I‚Äôll say more about that as we go on in this course. If you want to draw a diagram, I personally think of it this way. If this is data science, here‚Äôs machine learning, ML. There‚Äôs a lot of overlap between those two, and then within machine learning there‚Äôs a specific approach called neural networks. Those have been amazingly productive, and AI refers to this diffuse, not well defined category that mostly overlaps with neural networks and with machine learning. And, it gets at some of the ambiguities, and some of the difficulty in separating these, which is why there‚Äôs no consistent definition, and why there‚Äôs so much debate over what one thing is, and what the other one is. But I will say this. Artificial intelligence has been enormously influential within the field of data science recently, even though data science has many other things that it does. This course focuses specifically on data science, but you‚Äôll see just how much of this information also applies to machine learning, to neural networks, and even to the field of artificial intelligence.</p>

<h3 id="machine-learning">Machine learning</h3>

<p>Back in the day a machine was just a machine. It did whatever machine things it did like stamping metal or turning a propellor or maybe washing your clothes with a fair amount of help on your part. But nowadays, machines have to do more than just their given mechanical function. Now a washing machine‚Äôs supposed to be smart. It‚Äôs supposed to learn about you and how you like your clothes and it‚Äôs supposed to adjust its functions according to its sensors and it‚Äôs supposed to send you a gentle message on your phone when it‚Äôs all done taking care of everything. This is a big change, not just for washing machines, but for so many other machines and for data science processies as well. This gets to the issue of machine learning and a very simple definition of that is the ability of algorithms to learn from data and to learn in such a way that they can improve their function in the future. Now, learning is a pretty universal thing. Here‚Äôs how humans learn. Humans, memorization is hard. I know this, I teach and memorization is something my students struggle with every semester. On the other hand, spotting patterns is often pretty easy for humans as is reacting well and adaptively to new situations that resemble the old ones in many but not all ways. On the other hand, the way that machines learn is a little bit different. Unlike humans, memorization is really easy for machines. You can give them a million digits, it‚Äôll remember it perfectly and give it right back to you. But for a machine, for an algorithm, spotting patterns, in terms of here‚Äôs a visual pattern, here‚Äôs a pattern over time, those are much harder for algorithms. And new situations can be very challenging for algorithms to take what they learned previously and adapt it to something that may differ in a few significant ways. But the general idea is that once you figure out how machines learn and the ways that you can work with that, you can do some useful things. So for instance, there‚Äôs the spam email and you get a new email and the algorithm can tell whether it‚Äôs a spam. I used a couple of different email providers and I will tell you, some of them are much better at this than others. There‚Äôs also image identification. For instance, telling whether this is a human face or who‚Äôs face it is. Or there‚Äôs the translation of languages where you enter text, either written or spoken, and it translates it back. A very complicated task for humans but something that machines have learned how to do much better than they used to. Still not 100% but getting closer all the time. Now, the important thing here is that you‚Äôre not specifying all the criteria in each of these examples and you‚Äôre not laying out a giant collection of if this then that statements in a flow chart. That would be something called an expert system. Those were created several decades ago and have been found to have limited utility and they‚Äôre certainly not responsible for the modern developments of machine learning. Instead, a more common approach it really is to just teach your machine. You train it and the way you do that is you show the algorithm millions of labeled examples. If you‚Äôre trying to teach it to identify photos of cats versus other animals, you give it millions of photos and you say this is a cat, this is a cat, this is not, this is not, this is. And then the algorithm finds its own distinctive features that are consistent across many of the examples of cats. Now what‚Äôs important here is that the features, the things in the pictures that the algorithm latches onto may not be relevant to humans. We look at things like the eyes and the whiskers and the nose and the ears. It might be looking at the curve on the outside of the cheek relevant to the height of one ear to another. It might be looking just at a small patch of lines around the nose. Those may not be the things that humans latch onto and then sometimes they‚Äôre not even visible to humans. It turns out that algorithms can find things that are very subtle, pixel by pixel changes in images or very faint sounds in audio patches or individual letters in text and it can respond to those. That‚Äôs both a blessing and a curse. It means that it can find things that humans don‚Äôt but it also can react in strange ways occasionally. But once you take all this training, you give your algorithm millions of labeled examples and it starts classifying things, well, then you want use something like a neural network which has been responsible for the major growth in machine learning and data science in the past five years or so. These diagrams here are different layouts of possible neural networks that go from the left to the right, some of them circle around or they return back to where they were. But all of these are different ways of taking the information and processing it. Now, the theory of neural networks or artificial neural networks has existed for years. The theory is not new. What‚Äôs different, however, is that computing power has recently caught up to the demands that the theory places and in addition, the availability of labeled data primarily thanks to social media has recently caught up too. And so now we have this perfect combination. The theory has existed but the computing power and the raw data that it needs have both arrived to make it possible to do these computations that in many ways resembles what goes on in the human brain and then allow it to think creatively about the data, find its own patterns and label things. Now, I do want to say something about the relationship between data science and machine learning. Data science can definitely be done without machine learning. Any traditional classification task, logistic regression, decision tree. That‚Äôs not usually machine learning and it‚Äôs very effective data science. Most predictive models or even something like a sentiment analysis of social media text. On the other hand, machine learning without data science, well, you know, not so much. It‚Äôs possible to do machine learning without extensive domain expertise so that‚Äôs one element of data science. On the other hand, you would nearly always want to do this in collaboration with some sort of topical expert. Mostly I like to think of machine learning as a subdiscipline of data science. And that just brings up one more thing I want to say. The neural networks and the deep learning neural networks in particular that have been responsible for nearly all of these amazing developments in machine learning are a little bit of a black box which means it‚Äôs hard to know exactly what the algorithm is looking at or how it‚Äôs processing the data and one result of that is it kind of limits your ability to interpret what‚Äôs going on even though the predictions in classifications can be amazingly accurate. I‚Äôll say more about neural networks and these issues elsewhere, but they highlight the trade-offs, the potential and the compromises that are inherent in some of these really exciting developments that have been taking place in one extraordinary influential part of the data science world.</p>

<h3 id="deep-learning-neural-networks">Deep learning neural networks</h3>

<p>If you‚Äôve ever been around a baby, you know that babies take very little steps. But the thing about baby steps is that you still get moving and eventually, babies grow and they take bigger steps. And before you know it, you‚Äôve got a world-class sprinter. And there‚Äôs a similar thing, I like to think, that happens with neural networks. And what happens here is that tiny steps with data can lead to amazing analytical results. Now, an artificial neural network in computing is modeled roughly after the neurons that are inside a biological brain. Those neurons are nothing more than simple on and off switches that are connecting with each other, but give rise to things like love and consciousness. In the computing version, the idea is to take some very basic pieces of information, and by connecting it with many other nodes, you can give rise to the sort of emergent behavior, which really is very high-level cognitive decisions and classifications. It works this way. Over here on the left, you start with an input layer. That‚Äôs where your raw data comes in. And then, it gets passed along to one or more hidden layers. That‚Äôs what makes it a neural network, that you have these hidden layers. And these lines all represent connections like the connections between neurons in a biological brain. And then, after going through several hidden layers, you have an output layer, which is where you get the final classification or decision about what‚Äôs happening. And I want to give you an example of how this might work. Now, please understand, this is an analogy. The actual operation of neural networks is much more complicated and sometimes a little more mysterious than what‚Äôs going on here. But let‚Äôs take a simple example where you‚Äôre taking your input data from a digital image. In that case, for each pixel in the image, you‚Äôre going to have basically five pieces of information. You‚Äôre going to have the X and Y coordinates of that pixel. And then, for that pixel, you‚Äôre going to have its red, green, and blue color components. And then you‚Äôre going to repeat these five things for every pixel in the image. But that‚Äôs your raw input data. Those are numerical values. And you put those into the input layer. And then, what it does is it starts to combine these different X and Y positions and the RGB colors, and then, it decides whether it has found a line. Does this represent a distinct line against a color background? So, that might be the first layer. And then, from there, it‚Äôs going to say, I‚Äôve found some lines, and now I‚Äôm going to see if I can combine those lines to determine whether that line is the edge of an object as opposed to some sort of service marker. And then, if I found edges, I can then take the information about edges and then combine that to determine what‚Äôs the shape that I‚Äôm looking at. Is it a circle, a square, a hexagon, or something much more complex than that? And then maybe, it takes all of this shape information and then it goes to the output layer, and it says what the actual object is. So, we‚Äôve gone from the X Y RGB pieces of information about each pixel, and we‚Äôve put that in. And we‚Äôve gone to lines and we‚Äôve gone to edges, and then to shapes, and then possibly to objects. That‚Äôs one idea of how a neural network, and especially a deep-learning neural network, which has many hidden layers, might work. If you want to see something that‚Äôs slightly more complicated, here‚Äôs an example. And neural networks can potentially have millions of neurons. There can be a lot of stuff going on in there. And they might be arranged in a lot of different ways. These are called feedforward ones, where the information starts on the left and just kind of keeps moving forward to the right. But there are a lot of other potential arrangements for the data transfers within a neural network. These are some of the possible examples. They behave slightly differently. You‚Äôll want to use some of the different versions in different circumstances. Fortunately, we have other entire courses dedicated to the design and implementation of artificial neural networks here. There is one interesting thing, though. Just like a human brain, things can get a little complicated in a neural network, or really massively complicated. And it can be hard to know exactly what it is that‚Äôs going on inside there. What that means is you actually have to resort to inference. You sometimes have to infer how the neural network is functioning. What is it looking at? How is it processing that information? And curiously, that means you actually have to use some of the same methods as psychological researchers who are trying to find out what‚Äôs going on inside a human brain. You are testing and then inferring the processes that are going on. One other really important thing to keep in mind about neural networks is there‚Äôs a collection of legal issues that apply to these that don‚Äôt quite apply the same way to other forms of machine learning or data science. For instance, the European Union‚Äôs General Data Protection Regulation, better known as just GDPR, is a collection of policies that govern privacy and really how organizations gather and process information that they get from people. One really important part of this that relates to neural networks is what‚Äôs called a right to explanation. If a person feels that they have been harmed by a decision made by a neural network, such as it refused a loan application, they can sue the organization and demand an explanation. How did it reach that process? Now, because neural networks are so complicated, they tend to be kind of opaque and it‚Äôs hard to know what‚Äôs going on. You may have a difficult situation explaining exactly how it got there. That‚Äôs a problem, because there are some very stiff fines associated with violations of the GDPR. So, you will want to get a little more information on this. Fortunately, we have another course called AI Accountability Essential Training, which addresses some of these issues, gives you the basic parameters. If you‚Äôre going to be using neural networks, you owe it to yourself to spend a little bit of time on the social context and on the legal context of how these things work. But the most exciting thing about them is the amazing progress that‚Äôs been made in machine learning over just the past few years with neural networks and deep-learning neural networks, in particular, to model the general processes going on in the human brain, and to be able to reach some very, very sophisticated and a highly accurate conclusions based on that processing.</p>

<h2 id="big-data">Big data</h2>

<p>There was a time just a few years ago when data science and big data were practically synonymous terms as were semi-magical words like Hadoop that brought up all the amazing things happening in data science. But things are a little different now, so it‚Äôs important to distinguish between the two fields. I‚Äôll start by reminding you what we‚Äôre talking about when we talk about big data. Big data is data that is characterized by any or all of three characteristics. Unusual volume, unusual velocity, and unusual variety. Again, singly or together can constitute big data. Let me talk about each of these in turn. First, volume. The amount of data that‚Äôs become available even over the last five years is really extraordinary. Things like customer transactions at the grocery store. The databases that track these transactions and compile them and consumer loyalty programs have hundreds of billions of rows of data on purchases. GPS data from a phone includes information from billions of people constantly throughout the day. Or scientific data, for instance, this image of the black hole in Messier 97 from the Event Horizon Telescope that was released in April of 2019. It involved half a ton of hard drives that had to be transported on airplanes to central processing locations because that was several times faster than trying to use the internet. Any one of these is an overwhelming dataset for normal method, and that brought about some of the most common technologies associated with the big data, distributed file systems like Hadoop, that made it possible to take these collections that were simply too big to fit on any one computer, any one drive, put it across many, and still be able to integrate them in ways that let you get collective intelligence out of them. Then there‚Äôs velocity. The prime culprit in this one is social media. YouTube gets 300 hours of new video uploaded every single minute. That gets about five billion views per day. Instagram had 95 million posts per day, and that was back in 2016 when it only had half as many users as it does not. And Facebook generates about four petabytes of data per day. The data is coming in so fast it‚Äôs a fire hose that no common methods that existed before the big data revolution could handle it. This required new ways of transporting data, integrating data, and being able to update your analyses constantly to match the new information. And then finally there‚Äôs the variety, probably one of the most important elements of big data. That included things like multimedia data, images, and video, and audio. Those don‚Äôt fit into spreadsheets. Or biometric data, facial recognition, your fingerprints, your heart readings, and when you move the mouse on your computer to find out where the cursor went, that‚Äôs a distinctive signature that‚Äôs recorded and identified for each user. And then there‚Äôs graph data. That‚Äôs the data about the social networks and the connections between people. That requires a very special kind of database. Again, doesn‚Äôt fit into the regular rows and columns of conventional dataset. So all of these showed extraordinary challenges for simply getting the data in, let alone knowing how to process it in useful ways. Now it is possible to distinguish big data and data science. For instance, you can do big data without necessarily requiring the full toolkit of data science, which includes computer programming, math and statistics, and domain expertise. So for instance, you might have a large dataset, but if it‚Äôs structured and very consistent, maybe you don‚Äôt have to do any special programming. Or you have streaming data. It‚Äôs coming in very fast. But only has a few variables, a few kinds of measurements. Again, you can set it up once and kind of run with it as you go. And so that might be considered big data, but doesn‚Äôt necessarily require the full range of skills of data science. You can also have data science without big data. And that‚Äôs anytime you have a creative combination of multiple datasets or you have unstructured texts like social media posts. Or you‚Äôre doing data visualization. You may not have large datasets with these, but you‚Äôre definitely going to need the programming ability and the mathematical ability as well as the topical expertise to make these work well. So now that I‚Äôve distinguished them I want to return to one particularly important question. You can find this on the internet. And the question is, is big data dead? Because it‚Äôs interest peaked about four or five years ago. And it looks like it‚Äôs been going down since then. So is big data passe? Is it no longer there? Well, it‚Äôs actually quite the opposite. It turns out that big data is alive and well. It‚Äôs everywhere. It has simply become the new normal for data. The practices that it introduced, the techniques that it made possible are used every single day now in the data science world. And so while it‚Äôs possible to separate big data and data science, the two become so integrated now that big data is simply taken for granted as an element of the new normal in the data world.</p>

<h2 id="predictive-analytics">Predictive analytics</h2>

<p>When a person is convicted of a crime, a judge has to decide what the appropriate response is and how that might help bring about positive outcomes. One interesting thing that can contribute to that is what‚Äôs called restorative justice. This is a form of justice that focuses on repair to the harm done as opposed to punishment, and it often involves, at the judge‚Äôs discretion and the victim‚Äôs desire, mediation between the victim and the offender. Now one of the interesting things about this is it‚Äôs a pretty easy procedure, and it has some very significant outcomes. Participating in restorative justice predicts improved outcomes on all of the following. People feel that they were able to tell their story and that their opinion was considered. They feel that the process or outcome was fair. They feel that the judge or mediator was fair. They feel that the offender was held accountable. An apology or forgiveness was offered. There‚Äôs a better perception of the other party at the end of all of this. The victim is less upset about the crime. The victim is less afraid of revictimization. Those are absolutely critical. And then one more is that there‚Äôs a lower recidivism rate. Offenders who go through restorative justice are less likely to commit crimes again in the future. All of these are very significant outcomes and can be predicted with this one relatively simple intervention of restorative justice. And so when a judge is trying to make a decision, this is one thing they can keep in mind in trying to predict a particular outcome. Now in the world of predictive analytics, where you‚Äôre using data to try to predict outcomes, the restorative justice is a very simple one based on simple analysis. Within data science and predictive analytics, you‚Äôll see more complicated things like, for instance, whether a person is more likely to click on a particular button or make a purchase based on a particular offer. You‚Äôre going to see medical researchers looking at things that can predict the risk of a disease as well as the responsiveness of particular treatments. You‚Äôll also look at things like the classification of photos, and what‚Äôs being predicted there is whether a machine can accurately predict what a human would do if they did the same particular task. These are all major topics within the field of predictive analytics. Now the relationship between data science and predictive analytics is very vaguely like this. Data science is there, predictive analytics is there, and there‚Äôs a lot of overlap. An enormous amount of the work in predictive analytics is done by data science researchers. There are a few important meeting points at that intersection between the two, so predictions that involve difficult data, if you‚Äôre using unstructured data like social media posts or a video that doesn‚Äôt fit into the nice rows and columns of a spreadsheet. You‚Äôre probably going to need data science to do that. Similarly, predictions that involve sophisticated models like the neural network we have here, those require some really high-end programming to make them happen. And so data science is going to be important to those particular kinds of predictive analytics projects. On the other hand, it‚Äôs entirely possible to do predictions without the full data science tool kit. If you have clean, quantitative data sets, nice rows and columns of numbers, then you‚Äôre in good shape. And if you‚Äôre using a common model like a linear regression or a decision tree, both of which are extremely effective, but they‚Äôre also pretty easy to do and pretty easy to interpret. So in these situations, you can do useful and accurate predictions without having to have the entire background of data science. Also, it‚Äôs possible to do data science without necessarily being involved in the business of predictions. If you‚Äôre doing things like clustering cases or counting how often something happens, or mapping like what we see here, or a data visualization, these can be significant areas of data science, depending both on the data that you‚Äôre bringing in and the methods that you‚Äôre using. But they don‚Äôt involve predictions per se, and so what this lets you know is that while data science can contribute significantly to the practice of predictive analytics, they are still distinguishable fields, and depending on your purposes, you may or may not need the full range of data science skills, the full took kit to get to your predictive purposes. But either way, you‚Äôre going to be able to get more insight into how people are likely to react and how you can best adapt to those situations.</p>

<h2 id="prescriptive-analytics">Prescriptive analytics</h2>

<p>Sometimes you just have to do the impossible. About 2500 years ago the Greek philosopher, Zeno of Elea, argued that it was impossible to get from point a to point b, like walking across your room. His reasoning was that before you could get all the way to point b, you first had to get halfway there. And before you could get the rest of the way you had to go halfway again. The process of getting halfway would occur an infinite number of times, which Zeno said was impossible. So you could never get to point b. Now aside from the fact that Zeno didn‚Äôt know that you could solve an infinite series problem with calculus, the obvious answer is that people walk from one part of the room to the other all the time so the theoretically impossible task was obviously possible and accomplished frequently. And that gets us to an interesting issue about cause and effect relationships. Now strictly speaking, three things need to happen to be able to say one thing causes another. The first is that there needs to be an observed correlation between the putative cause and the effect. That is, the effect needs to be more likely when the cause is present. If it‚Äôs not it can‚Äôt possible cause it. The second thing is temporal precedence, and that simply means that the cause needs to come before the effect if it‚Äôs going to be a cause. And both of those are pretty easy to establish. The first one you just need something like a correlation coefficient. The second one, you just need to show that the cause happened first. You can set that up pretty easily. But the third one‚Äôs the kicker. No other explanations for the association between the possible cause and effect. The connection between those two can‚Äôt be accounted for by anything else. The problem is, that part is theoretically impossible. You can‚Äôt show that there‚Äôs nothing else there. And so, while we go along pretty well with number one, number two, three is this huge sticking point. On the other hand, that doesn‚Äôt mean you can‚Äôt establish causality, it means you just kind of have to get close enough for practical purposes. Now let me go back and compare what I‚Äôm talking about here with cause and effect to something we‚Äôve seen previously. I‚Äôve spoken about predictive analytics. That is where you‚Äôre focusing on correlations because correlations are adequate for saying if this happens then this will probably happen as well. And there‚Äôs a huge amount of work in data science on predictive analytics, and really amazing things have come out of that. On the other hand, prescriptive analytics is about causation. You‚Äôre trying to specifically focus on things that you can do to make something happen that‚Äôs important to you. Now, the gold standard for establishing cause and effect is what‚Äôs called an RCT, or a randomized controlled trial. Theoretically they‚Äôre very simple. You assign a bunch of people to one situation or another. You do that randomly. You control all the other conditions, and then you see how things come out. Theoretically very simple to do, but I can tell you, given my training as an experimental research psychologist, they can be enormously difficult, often complex in practice. And so the theory is nice and clean, but the practice can be really difficult. There is one major exception to that, and that‚Äôs A/B testing for web design, where for instance, you set up your software to have one offer on this version and another offer on another version of your website and you see which one gets more clicks. That can be automated. And it is an experimental design and it‚Äôs randomized. It‚Äôs an example of what we‚Äôre looking for even though that‚Äôs a very simple one. But something more complex like that, like for instance, does making public transportation in the city have a direct effect on the influx of new businesses? That‚Äôs a huge experiment. That‚Äôs very, very difficult to do well. And so the gold standard is the randomized controlled trial, but often very difficult to do in reality. And that leads you to some of the more practical solutions, the alternatives that can help you get close to a cause and effect conclusion even if they can‚Äôt get to you 100% of the way. Those include things like what-if simulations. These are ways of manipulating data in a spreadsheet. They say, well, if this is true and if we have these parameters then what will we expect? And then you can simply see how that matches up with reality a little bit later. You can do optimization models. These are correlational models based on the information you have that say if we balance things out, so we spend a certain amount of time and money on this, a certain amount of time and money on this, or if we price things in a particular way, that will maximize an outcome. Again, it‚Äôs correlational, but it often gives you specific suggestions on what to do based on that past information. You can do what are called cross-lag correlations. This is where you have data at two or more specific points in time, and you‚Äôre able to see if changes in the cause at time one produce corresponding changes in the effect at time two and not vice versa. And then finally there‚Äôs the entire category of what are called quasi-experiments. These are a whole host of research designs that let you use correlational data to try to estimate the size of the causal relationship between the two variables. On the other hand, one of the easiest ways to isolate causality is simply to do things again and again. Iteration is critical. You may be familiar with this chart, which comes from the agile design process. You design, you develop, you try something at once. Well, test it and do it again. Make a variation, do it again, make a variation. And as you do that you will come close enough to causality through your repeated experience that you‚Äôll then be able to isolate and say this particular action is producing the cause that we want. That is the prescriptive analysis. That‚Äôs the result that you‚Äôre looking for. And now, let me say something about how prescriptive analytics and data science compare and contrast with one another. Specifically, you can have prescriptive analytics without requiring the full data science toolkit. If you‚Äôre doing experimental research and you have well-structured data. It‚Äôs nice and quantitative, you got complete data, and that includes most automated A/B experiments. You can do a very good prescriptive analysis without needing everything that goes into data science. On the other hand, there are times where you‚Äôre doing data science without necessarily trying to prescribe a particular plan of action. Predictive and descriptive work flow into that category. That includes things like classifying and clustering, doing trend analysis, identifying anomalies. And so, that‚Äôs when data science doesn‚Äôt need prescriptive analytics as opposed to when prescriptive analytics doesn‚Äôt need data science. And so they are distinguishable fields. On the other hand, I do want to finish with this one thing about causality which is so central to prescriptive analytics. Causality may be, at least in theory, impossible. But prescriptive analytics can get you close enough for any practical purposes and help put you and your organization on the right path to maximizing the outcomes that are most important to you.</p>

<h2 id="business-intelligence">Business intelligence</h2>

<p>It‚Äôs an article of faith for me that any organization will do better by using data to help with their strategy, and with their day-to-day decisions. But it reminds me of one of my favorite quotes from over 100 years ago. William James was one of the founders of American psychology and philosophy, and he‚Äôs best known for functionalism in psychology and pragmatism in philosophy, and he had this to say: he said, ‚ÄúMy thinking is first and last and always for the sake of my doing.‚Äù That was summarized by another prominent American psychologist, Susan Fiske, as, ‚ÄúThinking is for doing.‚Äù The point is, when we think, the way that our brain works, it‚Äôs not just there because it‚Äôs there, it‚Äôs there to serve a particular purpose. And I think the same thing is true about data and data science in general. In fact, I like to say data is for doing. The whole point of gathering data, the whole point of doing the analysis, is to get some insight that‚Äôs going to allow us to do something better. And truthfully, business intelligence is the one field that epitomizes this goal. Business intelligence, or B.I., is all about getting the insight to do something better in your business. And business intelligence methods, or B.I. methods, are pretty simple. They are designed to emphasize speed, and accessibility, and insight, right there. You can do them on your tablet, you can do them on your phone. And they often rely on structured dashboards, like these graphs that you see. Maybe you do a social media campaign, and you can go and see the analytics dashboard. Or you have videos on YouTube, or Vimeo, or someplace. You can get the analytics and see how well is this performing, who‚Äôs watching it and when. That‚Äôs a business intelligence dashboard of a form. So, if this is all about the goal of data, that data is for doing, and B.I. does that so well, where does data science come in to all of this? Well, it actually comes in sort of before the picture. Data science helps set things up for business intelligence, and I‚Äôll give you a few examples. Number one, data science can help tremendously in collecting, and cleaning, and preparing, and manipulating the data. In fact, some of the most important developments in business intelligence, say, for instance, companies like Domo. Their major property is about the way that they ingest and process the information to make it easily accessible to other people. Next, data science can be used to build the models that predict the particular outcomes. So, you will have a structure there in your data, that will be doing, for instance, a regression, or a decision tree, or some other model to make sense of the data. And while a person doesn‚Äôt have to specifically manipulate that, it‚Äôs available to them, and that‚Äôs what produces the outcomes that they‚Äôre seeing. And then finally, two of the most important things you can do in business intelligence are find trends, to predict what‚Äôs likely to happen next, and to flag anomalies. This one‚Äôs an outlier, something may be wrong here, or we may have a new case with potential hidden value. Any one of those is going to require some very strong data science to do it well. Even if the user-facing element is a very simple set of graphs on a tablet, the data science goes into the preparation and the offering of the information. And so really, I like to think of it this way: Data science is what makes business intelligence possible. You need data science to get the information together from so many different sources, and sometimes doing complex modeling. And also, I like to think, that business intelligence gives purpose to data science. It‚Äôs one of the things that helps fulfill the goal-driven, application-oriented element of data science. And so, data science makes B.I. possible, but B.I. really shows to the best extent how data science can be used to make practical decisions that make organizations function more effectively and more efficiently.</p>
:ET