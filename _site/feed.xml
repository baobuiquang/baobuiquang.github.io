<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-04-02T20:58:44+07:00</updated><id>/feed.xml</id><title type="html">Creatoper</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Publish your package to npm</title><link href="/notebook/publish-your-package" rel="alternate" type="text/html" title="Publish your package to npm" /><published>2021-03-25T20:00:00+07:00</published><updated>2021-03-25T20:00:00+07:00</updated><id>/notebook/publish-your-package</id><content type="html" xml:base="/notebook/publish-your-package">&lt;h2 id=&quot;1-what-is-npm-create-an-npm-account&quot;&gt;1. What is &lt;a href=&quot;https://www.npmjs.com/&quot;&gt;npm&lt;/a&gt;? Create an npm account.&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; is a package manager for the JavaScript programming language.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; is the command line client that allows developers to install and publish packages - packaged modules of code.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; is an &lt;a href=&quot;https://github.com/npm&quot;&gt;open source&lt;/a&gt; project and free to use.&lt;/p&gt;

&lt;p&gt;Official website: &lt;strong&gt;&lt;a href=&quot;https://npmjs.com/&quot;&gt;npm&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Documentation: &lt;strong&gt;&lt;a href=&quot;https://docs.npmjs.com/&quot;&gt;npm Docs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./post_img/npm/1-npm-landing-page.png&quot; alt=&quot;NPM Landing Page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Create an npm account at: &lt;strong&gt;&lt;a href=&quot;https://www.npmjs.com/signup&quot;&gt;Sign Up&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Login: &lt;strong&gt;&lt;a href=&quot;https://www.npmjs.com/login&quot;&gt;Login&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/2-npm-sign-up.png&quot; alt=&quot;NPM Sign Up&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-what-is-nodejs-download-nodejs&quot;&gt;2. What is &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node.js&lt;/a&gt;? Download Node.js.&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node.js&lt;/code&gt; is an open-source, cross-platform, back-end JavaScript runtime environment.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node.js&lt;/code&gt; is an &lt;a href=&quot;https://github.com/nodejs&quot;&gt;open source&lt;/a&gt; project and free to use.&lt;/p&gt;

&lt;p&gt;Official website: &lt;strong&gt;&lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Nodejs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Documentation: &lt;strong&gt;&lt;a href=&quot;https://nodejs.org/en/docs/&quot;&gt;Nodejs Docs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/3-nodejs-landing-page.png&quot; alt=&quot;NPM Landing Page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Download Node.js at: &lt;strong&gt;&lt;a href=&quot;https://nodejs.org/en/download/&quot;&gt;Download Node.js&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/4-nodejs-download.png&quot; alt=&quot;Nodejs Download&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-prepare-your-package&quot;&gt;3. Prepare your package&lt;/h2&gt;

&lt;p&gt;Put all your package‚Äôs files in 1 folder&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;üìÅyour-pkg-name
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-01
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-02
‚îî‚îÄ‚îÄ üìÅyour-pkg-name-03
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;üìÅyour-pkg-name
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-01
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-02
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-03
‚îî‚îÄ‚îÄ package.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Edit the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;your-pkg-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;version&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;description&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Write your package's description here.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;main&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;your-pkg-name.js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;scripts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;echo &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; &amp;amp;&amp;amp; exit 1&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keywords&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;your-package-keyword&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;author&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Your Name Here&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;license&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;MIT&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-publish-your-package&quot;&gt;4. Publish your package&lt;/h2&gt;

&lt;style&gt;
.youtube {
    width: 100%; height: 46.87vw;
    border: none; background: transparent;
} @media only screen and (min-width: 768px) {
    .youtube {
        width: 42vw; height: 23.625vw;
    }
}
&lt;/style&gt;

&lt;iframe class=&quot;youtube&quot; src=&quot;https://www.youtube.com/embed/lxxndOskI1o&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Open command line and navigate to your package‚Äôs folder&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Login your npm account&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm login
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that when you input the password, there is no clue show that you are typing. This will be confused if this is the first time you use the command line.&lt;/p&gt;

&lt;p&gt;Initialize npm package manager&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you have prepared your package, all you need to do is just enter.&lt;/p&gt;

&lt;p&gt;Finally, type&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Publish your package&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm publish
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you see the line&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ your-pkg-name@1.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;your package has been published on npm successfully!&lt;/p&gt;

&lt;p&gt;If there is any error, you should:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Check your package‚Äôs name, it maybe used by other user (for example: you can‚Äôt name your package &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;react&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vue&lt;/code&gt;). In this case, you should change your package‚Äôs name, or publish your package under your name or organization‚Äôs name.&lt;/li&gt;
  &lt;li&gt;Check your folder‚Äôs structure, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file.&lt;/li&gt;
  &lt;li&gt;Check your npm account.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Bui Quang Bao</name></author><category term="technology" /><category term="web" /><category term="npm" /><summary type="html">1. What is npm? Create an npm account.</summary></entry><entry><title type="html">All markdown syntax</title><link href="/notebook/all-markdown-syntax" rel="alternate" type="text/html" title="All markdown syntax" /><published>2021-03-20T09:50:00+07:00</published><updated>2021-03-20T09:50:00+07:00</updated><id>/notebook/all-markdown-syntax</id><content type="html" xml:base="/notebook/all-markdown-syntax">&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas id imperdiet odio. Etiam quis volutpat mauris. Duis ligula lacus, maximus vel est sed, molestie finibus nisl. Aliquam erat volutpat. Mauris sit amet pretium urna, sit amet tristique enim. In eget arcu mollis, ultricies metus venenatis, tincidunt enim.&lt;/p&gt;

&lt;p&gt;Vestibulum ac sodales nisi, et malesuada tellus. Mauris eu nibh tortor. Aenean egestas enim in est imperdiet, in posuere arcu facilisis. Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# This is an &amp;lt;h1&amp;gt; tag
## This is an &amp;lt;h2&amp;gt; tag
### This is an &amp;lt;h3&amp;gt; tag
#### This is an &amp;lt;h4&amp;gt; tag
##### This is an &amp;lt;h5&amp;gt; tag
###### This is an &amp;lt;h6&amp;gt; tag
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;this-is-an-h1-tag&quot;&gt;This is an &amp;lt;h1&amp;gt; tag&lt;/h1&gt;
&lt;p&gt;Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;
&lt;h2 id=&quot;this-is-an-h2-tag&quot;&gt;This is an &amp;lt;h2&amp;gt; tag&lt;/h2&gt;
&lt;p&gt;Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;
&lt;h3 id=&quot;this-is-an-h3-tag&quot;&gt;This is an &amp;lt;h3&amp;gt; tag&lt;/h3&gt;
&lt;p&gt;Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;
&lt;h4 id=&quot;this-is-an-h4-tag&quot;&gt;This is an &amp;lt;h4&amp;gt; tag&lt;/h4&gt;
&lt;h5 id=&quot;this-is-an-h5-tag&quot;&gt;This is an &amp;lt;h5&amp;gt; tag&lt;/h5&gt;
&lt;h6 id=&quot;this-is-an-h6-tag&quot;&gt;This is an &amp;lt;h6&amp;gt; tag&lt;/h6&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;*Italic text*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Italic text&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;**Bold text**
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Bold text&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~~Strikethrough text~~
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;del&gt;Strikethrough text&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Combine: ***bold + italic*** or **bold + *italic* + ~~strikethrough~~**
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Combine: &lt;strong&gt;&lt;em&gt;bold + italic&lt;/em&gt;&lt;/strong&gt; or &lt;strong&gt;bold + &lt;em&gt;italic&lt;/em&gt; + &lt;del&gt;strikethrough&lt;/del&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* Item 1
* Item 2
  * Item 2a
  * Item 2b
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Item 1&lt;/li&gt;
  &lt;li&gt;Item 2
    &lt;ul&gt;
      &lt;li&gt;Item 2a&lt;/li&gt;
      &lt;li&gt;Item 2b&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. Item 1
2. Item 2
   1. Item 3a
   2. Item 3b
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;Item 1&lt;/li&gt;
  &lt;li&gt;Item 2
    &lt;ol&gt;
      &lt;li&gt;Item 3a&lt;/li&gt;
      &lt;li&gt;Item 3b&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;![Alt Text](https://images.unsplash.com/photo-1535952548450-d7447587e733)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;![Alt Text](https://images.unsplash.com/photo-1535952548450-d7447587e733)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[This is a Link](http://buiquangbao.github.io/)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;http://buiquangbao.github.io/&quot;&gt;This is a Link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; ‚ÄúYour time is limited, so don‚Äôt waste it living someone else‚Äôs life.‚Äù&amp;lt;br&amp;gt;
&amp;gt; Steve Jobs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;‚ÄúYour time is limited, so don‚Äôt waste it living someone else‚Äôs life.‚Äù&lt;br /&gt;
Steve Jobs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;There are 3 important files: `index.html`, `styles.css` and `scripts.js`
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There are 3 important files: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.html&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;styles.css&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scripts.js&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;
&lt;pre&gt;
&lt;div class=&quot;highlight&quot;&gt;
```javascript
function plus(p1, p2) {
  return p1 + p2;
}
```
&lt;/div&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;| First   | Second  | Third   |
| ------- | ------- | ------- |
| Content | Content | Content |
| Content | Content | Content |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- [x] this is a complete item
- [x] this is a complete item
- [ ] this is an incomplete item
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;this is a complete item&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;this is a complete item&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;this is an incomplete item&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Bui Quang Bao</name></author><category term="technology" /><category term="web" /><category term="markdown" /><summary type="html">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas id imperdiet odio. Etiam quis volutpat mauris. Duis ligula lacus, maximus vel est sed, molestie finibus nisl. Aliquam erat volutpat. Mauris sit amet pretium urna, sit amet tristique enim. In eget arcu mollis, ultricies metus venenatis, tincidunt enim.</summary></entry><entry><title type="html">Ethics and Agency in Data Science</title><link href="/notebook/ethics-and-agency-in-ds" rel="alternate" type="text/html" title="Ethics and Agency in Data Science" /><published>2021-01-01T00:00:03+07:00</published><updated>2021-01-01T00:00:03+07:00</updated><id>/notebook/ethics-and-agency-in-ds</id><content type="html" xml:base="/notebook/ethics-and-agency-in-ds">&lt;h2 id=&quot;legal-ethical-and-social-issues-of-data-science&quot;&gt;Legal, ethical, and social issues of data science&lt;/h2&gt;

&lt;p&gt;Data science can make you feel like a superhero who‚Äôs here to save the world or at least your business‚Äôs world. But an alarming amount of data work can also end up in court or on the wrong side of a protest so I want to talk about a few things that can help keep you, your company and your data science work on the up and up. First, there are some important legal issues. Now it used to be when data science first came about, you know, oh, 10 years ago, we were kind of in the Wild West and people just kind of did what they wanted but now we‚Äôve had some major developments in the legal frameworks that govern data and its use. Probably the most important of these is an entire collection of privacy laws, the most significant of which at the moment is the GDPR, that‚Äôs the European Union‚Äôs General Data Protection Regulation. This is a law about privacy that has some very serious teeth. It can potentially have fines of billions of dollars for companies that seriously violate its policies. This is why you have so many cookie notices and why opting in becomes such an important thing when you go to a website. And in the United States, there are a lot of other regulations that also affect privacy, things like HIPAA, that‚Äôs the Health Insurance Portability and Accountability Act and FERPA, the Family Educational Rights and Privacy Act. And then there are state laws like the California Consumer Privacy Act. All of these place serious regulations on how you can gather data, the consent that you need to get from people, what you can do from the data, whether people can request it, whether they can be forgotten from the system and it‚Äôs important for you to remember all of these so you don‚Äôt end up crossing a very significant line when doing your work. And I want to remind you, it‚Äôs not just the 31 member states of the European Union and the European Economic Area that have these kinds of privacy laws. They‚Äôre spreading around all over the world and there are more coming every day. I mean, that‚Äôs an awful lot of the world that‚Äôs covered by these various regulations that you need to keep in mind when doing your work. The next thing is ethical issues. These may or may not specifically address legal barriers but they have a lot to do with how your work is perceived. Now for instance, there are the three forms of fairness. We talked about distributing things by equity, that is proportional to some kind of input or equality, everybody gets the same amount or need, the people who need the most, and get the most. Or forms of justice. This includes distributive justice which is the actual things that you end up with, procedural justice, how are the decisions made and interactional justice, how is the decision communicated? How are people involved in it? And then there‚Äôs issues of authenticity. You need to know who you‚Äôre dealing with and what you‚Äôre dealing with and none of these specifically address legal issues but they have a very big impact on whether people feel that your organization and your work is ethical and can be trusted and whether they want to engage with you. And that finally gets to the social issues. Whenever you or your company or clients engage with people, you need to engage with them with respect. People don‚Äôt like getting fooled, they don‚Äôt like getting exploited, they don‚Äôt like getting ignored and all of those are serious risks when working with data and don‚Äôt forget that unpopular projects can lead to protests, by the general populace and walkouts by the people in your own company and so, there‚Äôs a lot more that I could say about all of these and in fact, in another course, AI Accountability Essential Training, I do say a lot more about every one of these elements and all of them can have an impact on your ability to use data to do something that‚Äôs productive for your company but not just in the short term, also in the long term in a way that is sustainable and respective of the people and the environment that you work in.&lt;/p&gt;

&lt;h2 id=&quot;agency-of-algorithms-and-decision-makers&quot;&gt;Agency of algorithms and decision-makers&lt;/h2&gt;

&lt;p&gt;When we think about Artificial Intelligence and how it works, and how it might make decisions, and act on it‚Äôs own, we tend to think of things like this. You‚Äôve got the robot holding the computer right next to you. But the fact is, most of the time when we‚Äôre dealing with Artificial Intelligence, it‚Äôs something a lot closer to this. Nevertheless, I want to suggest at least four ways that working data science can contribute to the interplay of human and Artificial Intelligence of personal and machine agency. The first is what I call simple Recommendations. And then there‚Äôs Human-in-the-Loop decision making. Then Human-Accessible decisions, and then Machine-Centric processing and action. And I want to talk a little more about each of these. Let‚Äôs start with Recommendations. This is where the algorithm processes your data and makes a recommendation, or suggestion to you and you can either take it or leave it. A few places where this approach shows up are things like, for instance, online shopping, where you have a recommendation engine that says ‚ÄúBased on your past purchase history, ‚Äúyou might want to look at this.‚Äù Or, the same thing with online movies or music, it looks at what you did, it looks at what you like, and it suggests other things. And, you can decide whether you want to pick up on that or not. Another one is an online News Feed. This says ‚ÄúBased on what you‚Äôve clicked in the past ‚Äúand the things that you‚Äôve selected, ‚Äúyou might like this.‚Äù It‚Äôs a little bit different, because this time it‚Äôs just a yes or no decision. But, it‚Äôs still up to you what you click on. Another one is Maps, where you enter your location and it suggests a route to you based on traffic, based on time and you can follow it or you can do something else if you want. But in all of these, data science is being used to take, truly, a huge amount of information about your own past behavior, about what other people have done under similar circumstances, and how that can be combined to give the most likely recommendations to you. But, the agency still rests in the human. They get to decide what to do. Next is Human-in-the-Loop decision making. And, this is where advanced algorithms can make and even implement their own decisions, as with self-driving cars. And, I remember the first time my car turned it‚Äôs steering wheel on it‚Äôs own. But humans are usually at the ready to take over, if needed. Another example might be something as simple as spam filters. You go in every now and then, and you check up on how well it‚Äôs performing. So, it can do it on it‚Äôs own, but you need to be there to take over just in case. A third kind of decision making in the interplay between the algorithm and the human is what I call Human-Accessible decision making. Many algorithmic decisions are made automatically, and even implemented automatically. But they‚Äôre designed such that humans can at least understand what happened in them. Such as, for instance, with an online mortgage application. You put the information in, and it can tell you immediately whether you‚Äôre accepted or rejected. But because of recent laws, such as the European Union GDPR, that‚Äôs the General Data Protection Regulation, the organizations who run these algorithms need to be able to interpret how it reached its decision. Even if they‚Äôre not usually involving humans in making of the decisions, it still has to be open to humans. And then finally, there‚Äôs Machine-Centric. And this is when machines are talking to other machines. And the best example of this is the internet of things. And that can include things like Wearables. My smart watch talks to my phone, which talks to the internet, which talks to my car in sharing and processing data at each point. Also Smart Homes. You can say hello to your Smart Speaker which turns on the lights, adjusts the temperature, starts the coffee, plays the news and so on. And there are Smart Grids, which allows for example, for two way communication between maybe a power utility and the houses or businesses they serve. It lets them have more efficient routing end of power, recovery from blackouts, integration with consumer generated power, and so on. The important thing about this one is this last category, the Machine-Centric decisions or the internet of things, is starting to constitute an enormous amount of the data that‚Äôs available for data science work. But any one of these approaches from the Simple Recommendations up to the Machine-Centric, all of them show the different kinds of relationships between data, human decision makers, and machine algorithms, and the conclusions that they reach. Any one of these is going to work in different circumstances. And so it‚Äôs your job, as somebody who may be working in data science, to find the best balance of the speed and efficiency of machine decision making and respect for the autonomy and individuality of the humans that you‚Äôre interacting with.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="technology" /><category term="web" /><category term="markdown" /><category term="learning_archive" /><summary type="html">Legal, ethical, and social issues of data science</summary></entry><entry><title type="html">The place of Data Science</title><link href="/notebook/the-place-of-data-science" rel="alternate" type="text/html" title="The place of Data Science" /><published>2021-01-01T00:00:02+07:00</published><updated>2021-01-01T00:00:02+07:00</updated><id>/notebook/the-place-of-data-science</id><content type="html" xml:base="/notebook/the-place-of-data-science">&lt;h2 id=&quot;artificial-intelligence&quot;&gt;Artificial intelligence&lt;/h2&gt;

&lt;p&gt;At this exact moment in history, when people think about data science, the mind turns inexorably towards artificial intelligence, often with humanoid robots lost deep in thought. But before I compare and contrast data science and AI, I want to mention a few things about the nature of categories and definitions. First, categories are constructs, and by construct I mean something that you have to infer, something that is created in the mind, doesn‚Äôt have this essential existence. It‚Äôs a little bit like, when is something comedy and when is something performance art, and when is something acting? There‚Äôs nothing that clearly separates one from the other. These are all mental categories, and the same thing is true of any category or definition, including things like data science and AI. The second one is that categories serve functional purposes. A letter opener is anything that‚Äôs used to open letters. I actually use a knife to open letters. On the other hand, I know a family that uses knives to scoop ice cream exclusively. And, the tool is whatever you use it for. It‚Äôs defined by its utility. The same thing is true of categories. And then finally, the use of categories varies by needs. If you‚Äôre putting books on the shelf, you can use the Library of Congress system, the Dewey Decimal system. I know people who stack them by size or by color, or turn them around and do it decoratively. Any of those is going to work because they‚Äôre serving different purposes. And so, when we‚Äôre trying to think about categories and defining whether a particular activity is AI or whether it‚Äôs data science, all of these principles are going to apply. A good example of this is the question of whether tomatoes are fruits or vegetables. Everyone knows that tomatoes are supposed to be fruit, but everyone also knows you‚Äôd never put tomatoes in a fruit salad. Tomatoes go on veggie plates along with carrots and celery. The answer to this paradox, its fruit versus vegetable nature, is simple. The word fruit is a botanical term, and the word vegetable is a culinary term. They‚Äôre not parallel or even very well coordinated systems of categorizations, which is why confusion can arise. It‚Äôs a little like the joke about the bar that plays both kinds of music, country and western. The categories don‚Äôt always divide logically or exclusively, and the same is true for artificial intelligence and data science. So, what exactly is artificial intelligence? Well I‚Äôm going to let you know, there are a lot of different statements about this, and none of them are taken as definitive. And some of them I find to be useful, and some of them I find to be less useful. There‚Äôs a little joke that AI means anything that computers can‚Äôt do. Well, obviously, computers learn to do new things, but as soon as a computer learns how to do something, people say, well that‚Äôs not intelligent, that‚Äôs just a machine doing stuff. And so there‚Äôs a sort of moving target here to this particular definition in terms of things computers can‚Äôt do. You can also think of AI in terms of tasks that normally require humans. Like placing a phone call and making an appointment. Or like returning an email, or categorizing text. Traditionally humans have done that, but when a machine is able to do that, when a program‚Äôs able to do it, that‚Äôs probably a good example of artificial intelligence. Probably the most basic and useful definition is that artificial intelligence refers to programs that learn from data. And so, you give them some data, they build a model, and that that model adapts over time. A few common examples of this are things like categorizing photos. Is this a photo of a horse, a car, a balloon, a person? And programs learn how to do this by first having lots and lots, and lots, and lots of photos that are labeled by the people as one thing or another, as a cat or a dog. But then the algorithm is able to start learning on its own and abstracting the elements of the photo that best represent cat or dog. It‚Äôs also used for translations going from one language, like English, to another, like French. The use of artificial intelligence programs has made enormous leaps in the ability of computers to do this automatically. Another one is games, like Go here. It was a very big deal when not very long ago a computer was able to beat the world champion of Go. And, it was thought to be this intuitive game that couldn‚Äôt really be explained. What‚Äôs fascinating about that is the computer actually taught itself how to play go. And, we‚Äôll talk a little more about that when we talk about the derivation of rules in another video. But all three of these can be good examples of artificial intelligence, simply by the sorts of things it‚Äôs able to do. And so, probably, this is the best working definition of AI. And, while it can include even simple regression models, which really don‚Äôt require much in the way of computing power, it usually refers to two approaches in particular. AI is usually referring to machine learning algorithms, and in particular, deep learning neural networks. I‚Äôm going to talk about those more elsewhere, but I did want to bring up one more important distinction when talking about AI. And that‚Äôs the difference between what is called strong or general AI, which is the idea that you can build a computer replica of the human brain that can solve any cognitive task. This is what happens in science fiction. You have a machine that‚Äôs just like a human in a box. And that was the original goal of artificial intelligence back in the 50s, but it turned out that has been very difficult. Instead, you also have what is called weak or narrow, or specific, or focused AI. And these are algorithms that focus on one specific well defined task. Like, is this a photo of a cat or a photo of a dog? That has been where the enormous progress in AI has been over the last several years. So with all this in mind, how does artificial intelligence compare and contrast to data science? Well, it‚Äôs a little bit like the fruit versus vegetable conundrum. Artificial intelligence means algorithms that learn from data. Broadly speaking, there‚Äôs an enormous amount of overlap between our concept of AI and the field of machine learning. Data science on the other hand is the collection of skills and techniques for dealing with challenging data. You can see that these two are not exclusive. There‚Äôs a lot of overlap between them, and AI nearly always involves the data science skillset. You basically can‚Äôt do modern AI without data science. But there‚Äôs an enormous amount of data science that does not involve artificial intelligence. And I‚Äôll say more about that as we go on in this course. If you want to draw a diagram, I personally think of it this way. If this is data science, here‚Äôs machine learning, ML. There‚Äôs a lot of overlap between those two, and then within machine learning there‚Äôs a specific approach called neural networks. Those have been amazingly productive, and AI refers to this diffuse, not well defined category that mostly overlaps with neural networks and with machine learning. And, it gets at some of the ambiguities, and some of the difficulty in separating these, which is why there‚Äôs no consistent definition, and why there‚Äôs so much debate over what one thing is, and what the other one is. But I will say this. Artificial intelligence has been enormously influential within the field of data science recently, even though data science has many other things that it does. This course focuses specifically on data science, but you‚Äôll see just how much of this information also applies to machine learning, to neural networks, and even to the field of artificial intelligence.&lt;/p&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine learning&lt;/h3&gt;

&lt;p&gt;Back in the day a machine was just a machine. It did whatever machine things it did like stamping metal or turning a propellor or maybe washing your clothes with a fair amount of help on your part. But nowadays, machines have to do more than just their given mechanical function. Now a washing machine‚Äôs supposed to be smart. It‚Äôs supposed to learn about you and how you like your clothes and it‚Äôs supposed to adjust its functions according to its sensors and it‚Äôs supposed to send you a gentle message on your phone when it‚Äôs all done taking care of everything. This is a big change, not just for washing machines, but for so many other machines and for data science processies as well. This gets to the issue of machine learning and a very simple definition of that is the ability of algorithms to learn from data and to learn in such a way that they can improve their function in the future. Now, learning is a pretty universal thing. Here‚Äôs how humans learn. Humans, memorization is hard. I know this, I teach and memorization is something my students struggle with every semester. On the other hand, spotting patterns is often pretty easy for humans as is reacting well and adaptively to new situations that resemble the old ones in many but not all ways. On the other hand, the way that machines learn is a little bit different. Unlike humans, memorization is really easy for machines. You can give them a million digits, it‚Äôll remember it perfectly and give it right back to you. But for a machine, for an algorithm, spotting patterns, in terms of here‚Äôs a visual pattern, here‚Äôs a pattern over time, those are much harder for algorithms. And new situations can be very challenging for algorithms to take what they learned previously and adapt it to something that may differ in a few significant ways. But the general idea is that once you figure out how machines learn and the ways that you can work with that, you can do some useful things. So for instance, there‚Äôs the spam email and you get a new email and the algorithm can tell whether it‚Äôs a spam. I used a couple of different email providers and I will tell you, some of them are much better at this than others. There‚Äôs also image identification. For instance, telling whether this is a human face or who‚Äôs face it is. Or there‚Äôs the translation of languages where you enter text, either written or spoken, and it translates it back. A very complicated task for humans but something that machines have learned how to do much better than they used to. Still not 100% but getting closer all the time. Now, the important thing here is that you‚Äôre not specifying all the criteria in each of these examples and you‚Äôre not laying out a giant collection of if this then that statements in a flow chart. That would be something called an expert system. Those were created several decades ago and have been found to have limited utility and they‚Äôre certainly not responsible for the modern developments of machine learning. Instead, a more common approach it really is to just teach your machine. You train it and the way you do that is you show the algorithm millions of labeled examples. If you‚Äôre trying to teach it to identify photos of cats versus other animals, you give it millions of photos and you say this is a cat, this is a cat, this is not, this is not, this is. And then the algorithm finds its own distinctive features that are consistent across many of the examples of cats. Now what‚Äôs important here is that the features, the things in the pictures that the algorithm latches onto may not be relevant to humans. We look at things like the eyes and the whiskers and the nose and the ears. It might be looking at the curve on the outside of the cheek relevant to the height of one ear to another. It might be looking just at a small patch of lines around the nose. Those may not be the things that humans latch onto and then sometimes they‚Äôre not even visible to humans. It turns out that algorithms can find things that are very subtle, pixel by pixel changes in images or very faint sounds in audio patches or individual letters in text and it can respond to those. That‚Äôs both a blessing and a curse. It means that it can find things that humans don‚Äôt but it also can react in strange ways occasionally. But once you take all this training, you give your algorithm millions of labeled examples and it starts classifying things, well, then you want use something like a neural network which has been responsible for the major growth in machine learning and data science in the past five years or so. These diagrams here are different layouts of possible neural networks that go from the left to the right, some of them circle around or they return back to where they were. But all of these are different ways of taking the information and processing it. Now, the theory of neural networks or artificial neural networks has existed for years. The theory is not new. What‚Äôs different, however, is that computing power has recently caught up to the demands that the theory places and in addition, the availability of labeled data primarily thanks to social media has recently caught up too. And so now we have this perfect combination. The theory has existed but the computing power and the raw data that it needs have both arrived to make it possible to do these computations that in many ways resembles what goes on in the human brain and then allow it to think creatively about the data, find its own patterns and label things. Now, I do want to say something about the relationship between data science and machine learning. Data science can definitely be done without machine learning. Any traditional classification task, logistic regression, decision tree. That‚Äôs not usually machine learning and it‚Äôs very effective data science. Most predictive models or even something like a sentiment analysis of social media text. On the other hand, machine learning without data science, well, you know, not so much. It‚Äôs possible to do machine learning without extensive domain expertise so that‚Äôs one element of data science. On the other hand, you would nearly always want to do this in collaboration with some sort of topical expert. Mostly I like to think of machine learning as a subdiscipline of data science. And that just brings up one more thing I want to say. The neural networks and the deep learning neural networks in particular that have been responsible for nearly all of these amazing developments in machine learning are a little bit of a black box which means it‚Äôs hard to know exactly what the algorithm is looking at or how it‚Äôs processing the data and one result of that is it kind of limits your ability to interpret what‚Äôs going on even though the predictions in classifications can be amazingly accurate. I‚Äôll say more about neural networks and these issues elsewhere, but they highlight the trade-offs, the potential and the compromises that are inherent in some of these really exciting developments that have been taking place in one extraordinary influential part of the data science world.&lt;/p&gt;

&lt;h3 id=&quot;deep-learning-neural-networks&quot;&gt;Deep learning neural networks&lt;/h3&gt;

&lt;p&gt;If you‚Äôve ever been around a baby, you know that babies take very little steps. But the thing about baby steps is that you still get moving and eventually, babies grow and they take bigger steps. And before you know it, you‚Äôve got a world-class sprinter. And there‚Äôs a similar thing, I like to think, that happens with neural networks. And what happens here is that tiny steps with data can lead to amazing analytical results. Now, an artificial neural network in computing is modeled roughly after the neurons that are inside a biological brain. Those neurons are nothing more than simple on and off switches that are connecting with each other, but give rise to things like love and consciousness. In the computing version, the idea is to take some very basic pieces of information, and by connecting it with many other nodes, you can give rise to the sort of emergent behavior, which really is very high-level cognitive decisions and classifications. It works this way. Over here on the left, you start with an input layer. That‚Äôs where your raw data comes in. And then, it gets passed along to one or more hidden layers. That‚Äôs what makes it a neural network, that you have these hidden layers. And these lines all represent connections like the connections between neurons in a biological brain. And then, after going through several hidden layers, you have an output layer, which is where you get the final classification or decision about what‚Äôs happening. And I want to give you an example of how this might work. Now, please understand, this is an analogy. The actual operation of neural networks is much more complicated and sometimes a little more mysterious than what‚Äôs going on here. But let‚Äôs take a simple example where you‚Äôre taking your input data from a digital image. In that case, for each pixel in the image, you‚Äôre going to have basically five pieces of information. You‚Äôre going to have the X and Y coordinates of that pixel. And then, for that pixel, you‚Äôre going to have its red, green, and blue color components. And then you‚Äôre going to repeat these five things for every pixel in the image. But that‚Äôs your raw input data. Those are numerical values. And you put those into the input layer. And then, what it does is it starts to combine these different X and Y positions and the RGB colors, and then, it decides whether it has found a line. Does this represent a distinct line against a color background? So, that might be the first layer. And then, from there, it‚Äôs going to say, I‚Äôve found some lines, and now I‚Äôm going to see if I can combine those lines to determine whether that line is the edge of an object as opposed to some sort of service marker. And then, if I found edges, I can then take the information about edges and then combine that to determine what‚Äôs the shape that I‚Äôm looking at. Is it a circle, a square, a hexagon, or something much more complex than that? And then maybe, it takes all of this shape information and then it goes to the output layer, and it says what the actual object is. So, we‚Äôve gone from the X Y RGB pieces of information about each pixel, and we‚Äôve put that in. And we‚Äôve gone to lines and we‚Äôve gone to edges, and then to shapes, and then possibly to objects. That‚Äôs one idea of how a neural network, and especially a deep-learning neural network, which has many hidden layers, might work. If you want to see something that‚Äôs slightly more complicated, here‚Äôs an example. And neural networks can potentially have millions of neurons. There can be a lot of stuff going on in there. And they might be arranged in a lot of different ways. These are called feedforward ones, where the information starts on the left and just kind of keeps moving forward to the right. But there are a lot of other potential arrangements for the data transfers within a neural network. These are some of the possible examples. They behave slightly differently. You‚Äôll want to use some of the different versions in different circumstances. Fortunately, we have other entire courses dedicated to the design and implementation of artificial neural networks here. There is one interesting thing, though. Just like a human brain, things can get a little complicated in a neural network, or really massively complicated. And it can be hard to know exactly what it is that‚Äôs going on inside there. What that means is you actually have to resort to inference. You sometimes have to infer how the neural network is functioning. What is it looking at? How is it processing that information? And curiously, that means you actually have to use some of the same methods as psychological researchers who are trying to find out what‚Äôs going on inside a human brain. You are testing and then inferring the processes that are going on. One other really important thing to keep in mind about neural networks is there‚Äôs a collection of legal issues that apply to these that don‚Äôt quite apply the same way to other forms of machine learning or data science. For instance, the European Union‚Äôs General Data Protection Regulation, better known as just GDPR, is a collection of policies that govern privacy and really how organizations gather and process information that they get from people. One really important part of this that relates to neural networks is what‚Äôs called a right to explanation. If a person feels that they have been harmed by a decision made by a neural network, such as it refused a loan application, they can sue the organization and demand an explanation. How did it reach that process? Now, because neural networks are so complicated, they tend to be kind of opaque and it‚Äôs hard to know what‚Äôs going on. You may have a difficult situation explaining exactly how it got there. That‚Äôs a problem, because there are some very stiff fines associated with violations of the GDPR. So, you will want to get a little more information on this. Fortunately, we have another course called AI Accountability Essential Training, which addresses some of these issues, gives you the basic parameters. If you‚Äôre going to be using neural networks, you owe it to yourself to spend a little bit of time on the social context and on the legal context of how these things work. But the most exciting thing about them is the amazing progress that‚Äôs been made in machine learning over just the past few years with neural networks and deep-learning neural networks, in particular, to model the general processes going on in the human brain, and to be able to reach some very, very sophisticated and a highly accurate conclusions based on that processing.&lt;/p&gt;

&lt;h2 id=&quot;big-data&quot;&gt;Big data&lt;/h2&gt;

&lt;p&gt;There was a time just a few years ago when data science and big data were practically synonymous terms as were semi-magical words like Hadoop that brought up all the amazing things happening in data science. But things are a little different now, so it‚Äôs important to distinguish between the two fields. I‚Äôll start by reminding you what we‚Äôre talking about when we talk about big data. Big data is data that is characterized by any or all of three characteristics. Unusual volume, unusual velocity, and unusual variety. Again, singly or together can constitute big data. Let me talk about each of these in turn. First, volume. The amount of data that‚Äôs become available even over the last five years is really extraordinary. Things like customer transactions at the grocery store. The databases that track these transactions and compile them and consumer loyalty programs have hundreds of billions of rows of data on purchases. GPS data from a phone includes information from billions of people constantly throughout the day. Or scientific data, for instance, this image of the black hole in Messier 97 from the Event Horizon Telescope that was released in April of 2019. It involved half a ton of hard drives that had to be transported on airplanes to central processing locations because that was several times faster than trying to use the internet. Any one of these is an overwhelming dataset for normal method, and that brought about some of the most common technologies associated with the big data, distributed file systems like Hadoop, that made it possible to take these collections that were simply too big to fit on any one computer, any one drive, put it across many, and still be able to integrate them in ways that let you get collective intelligence out of them. Then there‚Äôs velocity. The prime culprit in this one is social media. YouTube gets 300 hours of new video uploaded every single minute. That gets about five billion views per day. Instagram had 95 million posts per day, and that was back in 2016 when it only had half as many users as it does not. And Facebook generates about four petabytes of data per day. The data is coming in so fast it‚Äôs a fire hose that no common methods that existed before the big data revolution could handle it. This required new ways of transporting data, integrating data, and being able to update your analyses constantly to match the new information. And then finally there‚Äôs the variety, probably one of the most important elements of big data. That included things like multimedia data, images, and video, and audio. Those don‚Äôt fit into spreadsheets. Or biometric data, facial recognition, your fingerprints, your heart readings, and when you move the mouse on your computer to find out where the cursor went, that‚Äôs a distinctive signature that‚Äôs recorded and identified for each user. And then there‚Äôs graph data. That‚Äôs the data about the social networks and the connections between people. That requires a very special kind of database. Again, doesn‚Äôt fit into the regular rows and columns of conventional dataset. So all of these showed extraordinary challenges for simply getting the data in, let alone knowing how to process it in useful ways. Now it is possible to distinguish big data and data science. For instance, you can do big data without necessarily requiring the full toolkit of data science, which includes computer programming, math and statistics, and domain expertise. So for instance, you might have a large dataset, but if it‚Äôs structured and very consistent, maybe you don‚Äôt have to do any special programming. Or you have streaming data. It‚Äôs coming in very fast. But only has a few variables, a few kinds of measurements. Again, you can set it up once and kind of run with it as you go. And so that might be considered big data, but doesn‚Äôt necessarily require the full range of skills of data science. You can also have data science without big data. And that‚Äôs anytime you have a creative combination of multiple datasets or you have unstructured texts like social media posts. Or you‚Äôre doing data visualization. You may not have large datasets with these, but you‚Äôre definitely going to need the programming ability and the mathematical ability as well as the topical expertise to make these work well. So now that I‚Äôve distinguished them I want to return to one particularly important question. You can find this on the internet. And the question is, is big data dead? Because it‚Äôs interest peaked about four or five years ago. And it looks like it‚Äôs been going down since then. So is big data passe? Is it no longer there? Well, it‚Äôs actually quite the opposite. It turns out that big data is alive and well. It‚Äôs everywhere. It has simply become the new normal for data. The practices that it introduced, the techniques that it made possible are used every single day now in the data science world. And so while it‚Äôs possible to separate big data and data science, the two become so integrated now that big data is simply taken for granted as an element of the new normal in the data world.&lt;/p&gt;

&lt;h2 id=&quot;predictive-analytics&quot;&gt;Predictive analytics&lt;/h2&gt;

&lt;p&gt;When a person is convicted of a crime, a judge has to decide what the appropriate response is and how that might help bring about positive outcomes. One interesting thing that can contribute to that is what‚Äôs called restorative justice. This is a form of justice that focuses on repair to the harm done as opposed to punishment, and it often involves, at the judge‚Äôs discretion and the victim‚Äôs desire, mediation between the victim and the offender. Now one of the interesting things about this is it‚Äôs a pretty easy procedure, and it has some very significant outcomes. Participating in restorative justice predicts improved outcomes on all of the following. People feel that they were able to tell their story and that their opinion was considered. They feel that the process or outcome was fair. They feel that the judge or mediator was fair. They feel that the offender was held accountable. An apology or forgiveness was offered. There‚Äôs a better perception of the other party at the end of all of this. The victim is less upset about the crime. The victim is less afraid of revictimization. Those are absolutely critical. And then one more is that there‚Äôs a lower recidivism rate. Offenders who go through restorative justice are less likely to commit crimes again in the future. All of these are very significant outcomes and can be predicted with this one relatively simple intervention of restorative justice. And so when a judge is trying to make a decision, this is one thing they can keep in mind in trying to predict a particular outcome. Now in the world of predictive analytics, where you‚Äôre using data to try to predict outcomes, the restorative justice is a very simple one based on simple analysis. Within data science and predictive analytics, you‚Äôll see more complicated things like, for instance, whether a person is more likely to click on a particular button or make a purchase based on a particular offer. You‚Äôre going to see medical researchers looking at things that can predict the risk of a disease as well as the responsiveness of particular treatments. You‚Äôll also look at things like the classification of photos, and what‚Äôs being predicted there is whether a machine can accurately predict what a human would do if they did the same particular task. These are all major topics within the field of predictive analytics. Now the relationship between data science and predictive analytics is very vaguely like this. Data science is there, predictive analytics is there, and there‚Äôs a lot of overlap. An enormous amount of the work in predictive analytics is done by data science researchers. There are a few important meeting points at that intersection between the two, so predictions that involve difficult data, if you‚Äôre using unstructured data like social media posts or a video that doesn‚Äôt fit into the nice rows and columns of a spreadsheet. You‚Äôre probably going to need data science to do that. Similarly, predictions that involve sophisticated models like the neural network we have here, those require some really high-end programming to make them happen. And so data science is going to be important to those particular kinds of predictive analytics projects. On the other hand, it‚Äôs entirely possible to do predictions without the full data science tool kit. If you have clean, quantitative data sets, nice rows and columns of numbers, then you‚Äôre in good shape. And if you‚Äôre using a common model like a linear regression or a decision tree, both of which are extremely effective, but they‚Äôre also pretty easy to do and pretty easy to interpret. So in these situations, you can do useful and accurate predictions without having to have the entire background of data science. Also, it‚Äôs possible to do data science without necessarily being involved in the business of predictions. If you‚Äôre doing things like clustering cases or counting how often something happens, or mapping like what we see here, or a data visualization, these can be significant areas of data science, depending both on the data that you‚Äôre bringing in and the methods that you‚Äôre using. But they don‚Äôt involve predictions per se, and so what this lets you know is that while data science can contribute significantly to the practice of predictive analytics, they are still distinguishable fields, and depending on your purposes, you may or may not need the full range of data science skills, the full took kit to get to your predictive purposes. But either way, you‚Äôre going to be able to get more insight into how people are likely to react and how you can best adapt to those situations.&lt;/p&gt;

&lt;h2 id=&quot;prescriptive-analytics&quot;&gt;Prescriptive analytics&lt;/h2&gt;

&lt;p&gt;Sometimes you just have to do the impossible. About 2500 years ago the Greek philosopher, Zeno of Elea, argued that it was impossible to get from point a to point b, like walking across your room. His reasoning was that before you could get all the way to point b, you first had to get halfway there. And before you could get the rest of the way you had to go halfway again. The process of getting halfway would occur an infinite number of times, which Zeno said was impossible. So you could never get to point b. Now aside from the fact that Zeno didn‚Äôt know that you could solve an infinite series problem with calculus, the obvious answer is that people walk from one part of the room to the other all the time so the theoretically impossible task was obviously possible and accomplished frequently. And that gets us to an interesting issue about cause and effect relationships. Now strictly speaking, three things need to happen to be able to say one thing causes another. The first is that there needs to be an observed correlation between the putative cause and the effect. That is, the effect needs to be more likely when the cause is present. If it‚Äôs not it can‚Äôt possible cause it. The second thing is temporal precedence, and that simply means that the cause needs to come before the effect if it‚Äôs going to be a cause. And both of those are pretty easy to establish. The first one you just need something like a correlation coefficient. The second one, you just need to show that the cause happened first. You can set that up pretty easily. But the third one‚Äôs the kicker. No other explanations for the association between the possible cause and effect. The connection between those two can‚Äôt be accounted for by anything else. The problem is, that part is theoretically impossible. You can‚Äôt show that there‚Äôs nothing else there. And so, while we go along pretty well with number one, number two, three is this huge sticking point. On the other hand, that doesn‚Äôt mean you can‚Äôt establish causality, it means you just kind of have to get close enough for practical purposes. Now let me go back and compare what I‚Äôm talking about here with cause and effect to something we‚Äôve seen previously. I‚Äôve spoken about predictive analytics. That is where you‚Äôre focusing on correlations because correlations are adequate for saying if this happens then this will probably happen as well. And there‚Äôs a huge amount of work in data science on predictive analytics, and really amazing things have come out of that. On the other hand, prescriptive analytics is about causation. You‚Äôre trying to specifically focus on things that you can do to make something happen that‚Äôs important to you. Now, the gold standard for establishing cause and effect is what‚Äôs called an RCT, or a randomized controlled trial. Theoretically they‚Äôre very simple. You assign a bunch of people to one situation or another. You do that randomly. You control all the other conditions, and then you see how things come out. Theoretically very simple to do, but I can tell you, given my training as an experimental research psychologist, they can be enormously difficult, often complex in practice. And so the theory is nice and clean, but the practice can be really difficult. There is one major exception to that, and that‚Äôs A/B testing for web design, where for instance, you set up your software to have one offer on this version and another offer on another version of your website and you see which one gets more clicks. That can be automated. And it is an experimental design and it‚Äôs randomized. It‚Äôs an example of what we‚Äôre looking for even though that‚Äôs a very simple one. But something more complex like that, like for instance, does making public transportation in the city have a direct effect on the influx of new businesses? That‚Äôs a huge experiment. That‚Äôs very, very difficult to do well. And so the gold standard is the randomized controlled trial, but often very difficult to do in reality. And that leads you to some of the more practical solutions, the alternatives that can help you get close to a cause and effect conclusion even if they can‚Äôt get to you 100% of the way. Those include things like what-if simulations. These are ways of manipulating data in a spreadsheet. They say, well, if this is true and if we have these parameters then what will we expect? And then you can simply see how that matches up with reality a little bit later. You can do optimization models. These are correlational models based on the information you have that say if we balance things out, so we spend a certain amount of time and money on this, a certain amount of time and money on this, or if we price things in a particular way, that will maximize an outcome. Again, it‚Äôs correlational, but it often gives you specific suggestions on what to do based on that past information. You can do what are called cross-lag correlations. This is where you have data at two or more specific points in time, and you‚Äôre able to see if changes in the cause at time one produce corresponding changes in the effect at time two and not vice versa. And then finally there‚Äôs the entire category of what are called quasi-experiments. These are a whole host of research designs that let you use correlational data to try to estimate the size of the causal relationship between the two variables. On the other hand, one of the easiest ways to isolate causality is simply to do things again and again. Iteration is critical. You may be familiar with this chart, which comes from the agile design process. You design, you develop, you try something at once. Well, test it and do it again. Make a variation, do it again, make a variation. And as you do that you will come close enough to causality through your repeated experience that you‚Äôll then be able to isolate and say this particular action is producing the cause that we want. That is the prescriptive analysis. That‚Äôs the result that you‚Äôre looking for. And now, let me say something about how prescriptive analytics and data science compare and contrast with one another. Specifically, you can have prescriptive analytics without requiring the full data science toolkit. If you‚Äôre doing experimental research and you have well-structured data. It‚Äôs nice and quantitative, you got complete data, and that includes most automated A/B experiments. You can do a very good prescriptive analysis without needing everything that goes into data science. On the other hand, there are times where you‚Äôre doing data science without necessarily trying to prescribe a particular plan of action. Predictive and descriptive work flow into that category. That includes things like classifying and clustering, doing trend analysis, identifying anomalies. And so, that‚Äôs when data science doesn‚Äôt need prescriptive analytics as opposed to when prescriptive analytics doesn‚Äôt need data science. And so they are distinguishable fields. On the other hand, I do want to finish with this one thing about causality which is so central to prescriptive analytics. Causality may be, at least in theory, impossible. But prescriptive analytics can get you close enough for any practical purposes and help put you and your organization on the right path to maximizing the outcomes that are most important to you.&lt;/p&gt;

&lt;h2 id=&quot;business-intelligence&quot;&gt;Business intelligence&lt;/h2&gt;

&lt;p&gt;It‚Äôs an article of faith for me that any organization will do better by using data to help with their strategy, and with their day-to-day decisions. But it reminds me of one of my favorite quotes from over 100 years ago. William James was one of the founders of American psychology and philosophy, and he‚Äôs best known for functionalism in psychology and pragmatism in philosophy, and he had this to say: he said, ‚ÄúMy thinking is first and last and always for the sake of my doing.‚Äù That was summarized by another prominent American psychologist, Susan Fiske, as, ‚ÄúThinking is for doing.‚Äù The point is, when we think, the way that our brain works, it‚Äôs not just there because it‚Äôs there, it‚Äôs there to serve a particular purpose. And I think the same thing is true about data and data science in general. In fact, I like to say data is for doing. The whole point of gathering data, the whole point of doing the analysis, is to get some insight that‚Äôs going to allow us to do something better. And truthfully, business intelligence is the one field that epitomizes this goal. Business intelligence, or B.I., is all about getting the insight to do something better in your business. And business intelligence methods, or B.I. methods, are pretty simple. They are designed to emphasize speed, and accessibility, and insight, right there. You can do them on your tablet, you can do them on your phone. And they often rely on structured dashboards, like these graphs that you see. Maybe you do a social media campaign, and you can go and see the analytics dashboard. Or you have videos on YouTube, or Vimeo, or someplace. You can get the analytics and see how well is this performing, who‚Äôs watching it and when. That‚Äôs a business intelligence dashboard of a form. So, if this is all about the goal of data, that data is for doing, and B.I. does that so well, where does data science come in to all of this? Well, it actually comes in sort of before the picture. Data science helps set things up for business intelligence, and I‚Äôll give you a few examples. Number one, data science can help tremendously in collecting, and cleaning, and preparing, and manipulating the data. In fact, some of the most important developments in business intelligence, say, for instance, companies like Domo. Their major property is about the way that they ingest and process the information to make it easily accessible to other people. Next, data science can be used to build the models that predict the particular outcomes. So, you will have a structure there in your data, that will be doing, for instance, a regression, or a decision tree, or some other model to make sense of the data. And while a person doesn‚Äôt have to specifically manipulate that, it‚Äôs available to them, and that‚Äôs what produces the outcomes that they‚Äôre seeing. And then finally, two of the most important things you can do in business intelligence are find trends, to predict what‚Äôs likely to happen next, and to flag anomalies. This one‚Äôs an outlier, something may be wrong here, or we may have a new case with potential hidden value. Any one of those is going to require some very strong data science to do it well. Even if the user-facing element is a very simple set of graphs on a tablet, the data science goes into the preparation and the offering of the information. And so really, I like to think of it this way: Data science is what makes business intelligence possible. You need data science to get the information together from so many different sources, and sometimes doing complex modeling. And also, I like to think, that business intelligence gives purpose to data science. It‚Äôs one of the things that helps fulfill the goal-driven, application-oriented element of data science. And so, data science makes B.I. possible, but B.I. really shows to the best extent how data science can be used to make practical decisions that make organizations function more effectively and more efficiently.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="technology" /><category term="web" /><category term="markdown" /><category term="learning_archive" /><summary type="html">Artificial intelligence</summary></entry><entry><title type="html">What is Data Science?</title><link href="/notebook/what-is-data-science" rel="alternate" type="text/html" title="What is Data Science?" /><published>2021-01-01T00:00:01+07:00</published><updated>2021-01-01T00:00:01+07:00</updated><id>/notebook/what-is-data-science</id><content type="html" xml:base="/notebook/what-is-data-science">&lt;h2 id=&quot;1-supply-and-demand-for-data-science&quot;&gt;1. Supply and demand for data science&lt;/h2&gt;

&lt;p&gt;Back in the early 60‚Äôs, Barbra Streisand sang, ‚ÄúPeople who need people ‚Äúare the luckiest people in the world.‚Äù And really, the need for belonging, the need to connect, and the need to be valued are all fundamental human motivations. As it happens, working in data science can actually help fulfill some of these foundational needs. By placing you in a position to one, do something wonderful for other people and two, in return to be valued for it. It goes back to something that a Harvard Business Review had to say about it back in 2012. Thomas Davenport and D.J. Patil made the extraordinary claim that data science, of all things, was the sexiest job of the 21st century. But they had good reasons for saying this. They are argued that data scientists had one, a valuable combination of rare qualities that two, put them in high demand. So here are some of the rare qualities. Data scientists are able to find order, meaning, and value in unstructured data. That‚Äôs online sources, the graphs of social networks, audio, images, videos, and so on. They‚Äôre able to predict outcomes like who‚Äôs likely to purchase something or who poses a security threat, or who‚Äôs likely to develop a disease, or respond well to a new treatment. They‚Äôre able to automate processes like getting individualized recommendations while shopping, identifying friends in photographs, or giving psychological support in AI chat bots. And they‚Äôre in high demand for a couple of really simple reasons. They provide hidden insight. Data science is able to show you things that you simply can‚Äôt find through other means. And that hidden insight, in turn, provides significant competitive advantage to any organization that has the good foresight to employ and really make the most of data science. Give you a little bit more information about supply and demand here. Number one, there‚Äôs been extraordinary growth in job ads. People are looking for data science. So for example, a January 2019 report from Indeed reported a 29% increase in job ads for data science over one year and 344% over six years. This is extraordinary growth. Next, they showed that there‚Äôs growth in job searches. People actually trying to find jobs in data science. And they found only a 14% growth over one year. Now that may sound a little low, but the important thing to hear is that the demand is outstripping the availability. And any time that happens, you‚Äôve got value. And what this means, you know, again, specifically, the gap in supply and demand is it significant? LinkedIn reported a gap of over 150,000 jobs in data science. And it‚Äôs even more dramatic when you show in related fields like machine learning engineer, artificial intelligence specialist, and so on. It‚Äôs big. There are so many possibilities here to do something that is valued for others. And it‚Äôs reflected in the salaries for data science. The average salary in data science is $107,000 a year. Which, just for comparison purposes, is over twice the national median in the U.S. of $47,000 a year. And that means that this is one of the best jobs in the U.S. Glass Door in January of 2019 published it‚Äôs annual list of best jobs in America and for the fourth year in a row, data scientist is at the top of the list, based on job satisfaction, number of openings, salary. It really lets you know there is extraordinary potential here, something that you can provide of amazing value for potential employers. And you fan fulfill that great need and you can be valued for the things that you‚Äôre able to contribute by embracing the methods and the benefits of data science in your work.&lt;/p&gt;

&lt;h2 id=&quot;2-the-data-science-venn-diagram&quot;&gt;2. The data science Venn diagram&lt;/h2&gt;

&lt;p&gt;Sometimes the whole is greater than the sum of its parts, and you can see this in a lot of different places. Take, for instance, music. You take John, and Paul, and George, and Ringo, all wonderful musicians in their own rights, but put them together and you have The Beatles and you have revolutionized popular culture. Or take the fact that everybody has a circle of friends and basically everybody has the internet now, and you have created social networks and you have revolutionized the computing world. Or in 2013, Drew Conway proposed the combination of hacking skills, that‚Äôs computer programming, and math and statistics, and substantive or topical domain expertise, together give you data science, a new field that has revolutionized both the technology and the business world. And I want to talk a little more about why each of those three elements in the Venn diagram of data science are so important. First one, the hacking skills or computer programming, the reason that‚Äôs important is because you have such novel sources of data. You have social media and social networks, you have challenging formats like the graph data from those social networks or images or video that don‚Äôt fit into the rows and columns of a spreadsheet, or you have streaming data like sensor data or live web data that comes in so fast that you can‚Äôt pause it to analyze it. All of these require the creativity that comes with hacking and the ability to work freely with what you have in front of you. Now in terms of actual computer programming skills, there‚Äôs a few things that are very useful in data science. The ability to work with a language like Python or R, these are programming languages that are very frequently used for data manipulation and modeling. There‚Äôs C, and C++, and Java. These are general-purpose languages that are used for the back end, the foundational elements of data science, and they provide maximum speed. There‚Äôs S-Q-L or SQL. That stands for structured query language. This is a language for working with relational databases to do queries and data manipulation. And then there are packages you can use in other languages like TensorFlow. This is an open-source library that‚Äôs used for deep learning and it has revolutionized the way that data science is performed right now. And then there‚Äôs the mathematical elements of data science. First off, there‚Äôs several forms of mathematics that are particularly useful in data science. There‚Äôs probability, and linear algebra, and calculus, and regression, and I‚Äôll talk about some of each of these, but they allow you to do something important. Number one, they allow you to choose the procedures. You want to judge the fit between your question, which is always the first and most important thing, the data that you have available to you, and then you choose a procedure that answers your questions based on your data. And if you understand the mathematics and how it works, you‚Äôll be able to make a much better and more informed choice. And also, you‚Äôll be able to diagnose problems. Murphy‚Äôs Law applies in data science as well as everywhere else that anything that can go wrong, will go wrong, and you need to know what to do when the procedures that you‚Äôve chosen fail or they give sometimes impossible results. You need to understand exactly how the data‚Äôs being manipulated so you can see where the trouble areas are and how to resolve them. And then the third area of Conway‚Äôs data science Venn diagram is substantive expertise. This is each domain or topic area has its own goals, methods, and constraints. If you‚Äôre working in social media marketing, you‚Äôre going to have a very different set of goals and methods than if you‚Äôre working in biomedical informatics. And you need to know what constitutes value in the particular domain you‚Äôre working in. And finally, how to implement the insights because data science is an action-oriented field. It‚Äôs designed to tell you what to do next to get the most value, provide the best service that you possibly can based on the data that you have. So taken together, the hacking or programming, the math and statistics, and the substantive expertise are the individual elements or components, the parts that make up the larger-than-the-sum whole of data science.&lt;/p&gt;

&lt;h2 id=&quot;3-the-data-science-pathway&quot;&gt;3. The data science pathway&lt;/h2&gt;

&lt;p&gt;The insights you get from data science can feel like a gift to your business, but you don‚Äôt get to just open your hands and get it delivered to you with a bow on it. Really, there are a lot of moving parts and things that have to be planned and coordinated for all of this to work properly. I like to think of data science projects like walking down a pathway, where each step gets you closer to the goal that you have in mind. And with that I want to introduce you to a way of thinking about the data science pathway. It begins with planning your project. You first need to define your goals. What is it that you‚Äôre actually trying to find out or accomplish? That way you can know when you‚Äôre on target or when you need to redirect a little bit. You need to organize your resources. That can include things as simple as getting the right computers and the software, accessing the data, getting people and their time available. You need to coordinate the work of those people because data science is a team effort. Not everybody‚Äôs going to be doing the same thing and some things have to happen first and some happen later. You also need to schedule the project so it doesn‚Äôt expand to fill up an enormous amount of time. Time boxing, or saying we will accomplish this task in this amount of time, can be especially useful in working on a tight timeframe or you have a budget and you‚Äôre working with a client. After planning, the next step is going to be wrangling, or preparing the data. That means you need to first get the data. You may be gathering new data, you may be using open data sources, you may be using public APIs, but you have to actually get the raw materials together. The next one, step six, is cleaning the data, which actually is an enormous task within data science. It‚Äôs about getting the data ready so it fits into the paradigm, for instance, the program and the applications that you‚Äôre using, that you can process it to get the insight that you need. Once the data‚Äôs prepared and it‚Äôs in your computer, you need to explore the data, maybe making visualizations, maybe doing some numerical summaries, a way of getting a feel of what‚Äôs going on in there. And then, based on your exploration, you may need to refine the data. You may need to re-categorize cases. You may need to combine variables into new scores. Any of the things that can help you get it prepared for the insight. The third category in your data pathway is modeling. This is where you actually create the statistical model and you do the linear regression. You do the decision tree. You do the deep learning neural network. But then, you need to validate the model. How well do you know this is going to generalize from the current data set to other data sets. In a lot of research that step is left out and you often end up with conclusions that fall apart when you go to new places. So, validation‚Äôs a very important part of this. The next step is evaluating the model. How well does it fit the data? What‚Äôs the return on investment for it? How usable is it going to be? And then, based on those, you may need to refine the model. You may need to try processing a different way, adjust the parameters in your neural network, get additional variables to include in your linear regression. Any one of those can help you build a better model to achieve the goals that you had in mind in the first place. And then finally, the last part of the data pathway is applying the model and that includes presenting the model, showing what you learned to other people, to the decision makers, to the invested parties, to your client, so they know what it is that you‚Äôve found. Then you deploy the model. Say for instance, you created a recommendation engine. You actually need to put it online so that it can start providing these recommendations to clients or you put it into a dashboard so it can start providing recommendations to your decision makers. You will eventually need to revisit the model, see how well it‚Äôs performing, especially when you have new data and maybe a new context in which it‚Äôs operating. And then, you may need to revise it and try the process over again. And then finally, once you‚Äôve done all of this there‚Äôs the matter of archiving the assets, really cleaning up after yourself is very important in data science. It includes documenting where the data came from and how you process it. It includes commenting the code that you used to analyze it. It includes making things future proof. All of these together can make the project more successful, easier to manage, easier to get the return on investment calculations for it, and those together will make the project more successful by following each of these steps. Taken together those steps on the pathway get you to your goal. It could be an amazing view at the end of your hike, or it could be an amazing insight into your business model, which was your purpose all along.&lt;/p&gt;

&lt;h2 id=&quot;4-roles-and-teams-in-data-science&quot;&gt;4. Roles and teams in data science&lt;/h2&gt;

&lt;p&gt;Data science is fundamentally a team sport. There are so many different skills and so many different elements involved in a data science project that you‚Äôre going to need people from all sorts of different backgrounds with different techniques to contribute to the overall success of the project. I want to talk about a few of these important roles. The first one is the data engineers. These are the developers, and the system architects, the people who focus on the hardware and the software that make data science possible. They provide the foundation for all of the other analyses. They focus on the speed, and the reliability, and the availability of the work that you do. Next are machine learning specialists. These are people who have extensive work in computer science and in mathematics. They work in deep learning. They work in artificial intelligence. And they‚Äôre the ones who have the intimate understanding of the algorithms and understand exactly how they‚Äôre working with the data to produce the results that you‚Äôre looking for. And then, an entirely different vein are people who are researchers, and by that I mean topical researchers. They focus on domain-specific research like, for instance, physics and genetics are common, so is astrophysics, so is medicine, so is psychology, and these kinds of researchers, while they connect with data science, they are usually better versed in the design of research within their particular field and doing common statistical analyses, that‚Äôs where their expertise lies, but they connect with data science in that they‚Äôre trying to find the answers to some of these big-picture questions that data scientists can also contribute to. Also, any business doing its job has analysts. These are people who do the day-to-day data tasks that are necessary for any business to run efficiently. Those include things like web analytics, and S-Q-L, that‚Äôs SQL or Structured Query Language, data visualizations, and the reports that go into business intelligence. These allow people to make decisions. It‚Äôs for good business decision-making that lets you see how you‚Äôre performing, where you need to reorient, and how you can better reach your goals. Then there are the managers. These are the people who manage the entire data science project, and they‚Äôre in charge of doing a couple of very important things. One is they need to frame the business-relevant questions and solutions. So, they‚Äôre the ones who have the big picture. They know what they‚Äôre trying to accomplish with that. And then, they need to keep people on track and moving towards it. And, to do that, they don‚Äôt necessarily need to know how to do a neural network, they don‚Äôt need to make the data visualization, but they need to speak data so they can understand how the data relates to the question they‚Äôre trying to answer, and they can help take the information that the other people are getting and putting it together into a cohesive whole. Now, there are people who are entrepreneurs. And, in this case, you might have a data-based startup. The trick here is you often need all of the skills, including the business acumen, to make the business run well. You also need some great creativity in planning your projects and the execution that get you towards your entrepreneurial goals. And then there‚Äôs the unicorn, also known as the rock star, or the ninja. This is a full-stack data scientist who can do it all, and do it at absolute peak performance. Well, it‚Äôs a nice thing to have, on the other hand, that thing is very rare which is why we call them the unicorn. Also, you don‚Äôt want to rely on one person for everything. Aside from the fact that they‚Äôre hard to find, and sometimes hard to keep, you‚Äôre only getting a single perspective or approach to your business questions, and you usually need something more diverse than that. And what suggests is the common approach to getting all the skills you need for a data project, and that is by team, and you can get a unicorn by team where you can get the people who have all the necessary skills, from the foundational data engineer, to the machine learning specialist, to the analyst, to the managers, all working together to get the insight from your data and help your project reach its greatest potential in moving your organization towards its own goals.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="technology" /><category term="web" /><category term="markdown" /><category term="learning_archive" /><summary type="html">1. Supply and demand for data science</summary></entry></feed>