<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-04-07T16:12:17+07:00</updated><id>/feed.xml</id><title type="html">Creatoper</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Publish your package to npm</title><link href="/notebook/publish-your-package" rel="alternate" type="text/html" title="Publish your package to npm" /><published>2021-03-25T20:00:00+07:00</published><updated>2021-03-25T20:00:00+07:00</updated><id>/notebook/publish-your-package</id><content type="html" xml:base="/notebook/publish-your-package">&lt;h2 id=&quot;1-what-is-npm-create-an-npm-account&quot;&gt;1. What is &lt;a href=&quot;https://www.npmjs.com/&quot;&gt;npm&lt;/a&gt;? Create an npm account.&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; is a package manager for the JavaScript programming language.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; is the command line client that allows developers to install and publish packages - packaged modules of code.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; is an &lt;a href=&quot;https://github.com/npm&quot;&gt;open source&lt;/a&gt; project and free to use.&lt;/p&gt;

&lt;p&gt;Official website: &lt;strong&gt;&lt;a href=&quot;https://npmjs.com/&quot;&gt;npm&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Documentation: &lt;strong&gt;&lt;a href=&quot;https://docs.npmjs.com/&quot;&gt;npm Docs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/1-npm-landing-page.png&quot; alt=&quot;NPM Landing Page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Create an npm account at: &lt;strong&gt;&lt;a href=&quot;https://www.npmjs.com/signup&quot;&gt;Sign Up&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Login: &lt;strong&gt;&lt;a href=&quot;https://www.npmjs.com/login&quot;&gt;Login&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/2-npm-sign-up.png&quot; alt=&quot;NPM Sign Up&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-what-is-nodejs-download-nodejs&quot;&gt;2. What is &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node.js&lt;/a&gt;? Download Node.js.&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node.js&lt;/code&gt; is an open-source, cross-platform, back-end JavaScript runtime environment.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node.js&lt;/code&gt; is an &lt;a href=&quot;https://github.com/nodejs&quot;&gt;open source&lt;/a&gt; project and free to use.&lt;/p&gt;

&lt;p&gt;Official website: &lt;strong&gt;&lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Nodejs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Documentation: &lt;strong&gt;&lt;a href=&quot;https://nodejs.org/en/docs/&quot;&gt;Nodejs Docs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/3-nodejs-landing-page.png&quot; alt=&quot;NPM Landing Page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Download Node.js at: &lt;strong&gt;&lt;a href=&quot;https://nodejs.org/en/download/&quot;&gt;Download Node.js&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../post_img/npm/4-nodejs-download.png&quot; alt=&quot;Nodejs Download&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-prepare-your-package&quot;&gt;3. Prepare your package&lt;/h2&gt;

&lt;p&gt;Put all your package‚Äôs files in 1 folder&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;üìÅyour-pkg-name
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-01
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-02
‚îî‚îÄ‚îÄ üìÅyour-pkg-name-03
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;üìÅyour-pkg-name
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-01
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-02
‚îú‚îÄ‚îÄ üìÅyour-pkg-name-03
‚îî‚îÄ‚îÄ package.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Edit the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;your-pkg-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;version&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;description&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Write your package's description here.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;main&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;your-pkg-name.js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;scripts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;echo &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; &amp;amp;&amp;amp; exit 1&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keywords&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;your-package-keyword&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;author&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Your Name Here&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;license&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;MIT&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-publish-your-package&quot;&gt;4. Publish your package&lt;/h2&gt;

&lt;style&gt;
.youtube {
    width: 100%; height: 46.87vw;
    border: none; background: transparent;
} @media only screen and (min-width: 768px) {
    .youtube {
        width: 42vw; height: 23.625vw;
    }
}
&lt;/style&gt;

&lt;iframe class=&quot;youtube&quot; src=&quot;https://www.youtube.com/embed/lxxndOskI1o&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Open command line and navigate to your package‚Äôs folder&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Login your npm account&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm login
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that when you input the password, there is no clue show that you are typing. This will be confused if this is the first time you use the command line.&lt;/p&gt;

&lt;p&gt;Initialize npm package manager&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you have prepared your package, all you need to do is just enter.&lt;/p&gt;

&lt;p&gt;Finally, type&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Publish your package&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm publish
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you see the line&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ your-pkg-name@1.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;your package has been published on npm successfully!&lt;/p&gt;

&lt;p&gt;If there is any error, you should:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Check your package‚Äôs name, it maybe used by other user (for example: you can‚Äôt name your package &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;react&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vue&lt;/code&gt;). In this case, you should change your package‚Äôs name, or publish your package under your name or organization‚Äôs name.&lt;/li&gt;
  &lt;li&gt;Check your folder‚Äôs structure, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file.&lt;/li&gt;
  &lt;li&gt;Check your npm account.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Bui Quang Bao</name></author><category term="technology" /><category term="web" /><category term="npm" /><summary type="html">1. What is npm? Create an npm account.</summary></entry><entry><title type="html">All markdown syntax</title><link href="/notebook/all-markdown-syntax" rel="alternate" type="text/html" title="All markdown syntax" /><published>2021-03-20T09:50:00+07:00</published><updated>2021-03-20T09:50:00+07:00</updated><id>/notebook/all-markdown-syntax</id><content type="html" xml:base="/notebook/all-markdown-syntax">&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas id imperdiet odio. Etiam quis volutpat mauris. Duis ligula lacus, maximus vel est sed, molestie finibus nisl. Aliquam erat volutpat. Mauris sit amet pretium urna, sit amet tristique enim. In eget arcu mollis, ultricies metus venenatis, tincidunt enim.&lt;/p&gt;

&lt;p&gt;Vestibulum ac sodales nisi, et malesuada tellus. Mauris eu nibh tortor. Aenean egestas enim in est imperdiet, in posuere arcu facilisis. Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# This is an &amp;lt;h1&amp;gt; tag
## This is an &amp;lt;h2&amp;gt; tag
### This is an &amp;lt;h3&amp;gt; tag
#### This is an &amp;lt;h4&amp;gt; tag
##### This is an &amp;lt;h5&amp;gt; tag
###### This is an &amp;lt;h6&amp;gt; tag
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;this-is-an-h1-tag&quot;&gt;This is an &amp;lt;h1&amp;gt; tag&lt;/h1&gt;
&lt;p&gt;Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;
&lt;h2 id=&quot;this-is-an-h2-tag&quot;&gt;This is an &amp;lt;h2&amp;gt; tag&lt;/h2&gt;
&lt;p&gt;Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;
&lt;h3 id=&quot;this-is-an-h3-tag&quot;&gt;This is an &amp;lt;h3&amp;gt; tag&lt;/h3&gt;
&lt;p&gt;Donec rutrum elit vitae sodales congue. Suspendisse sit amet dolor laoreet quam tempus rhoncus. Morbi viverra diam eu orci convallis, id sollicitudin justo blandit. Curabitur mattis dolor non ex rutrum, a auctor nisi malesuada.&lt;/p&gt;
&lt;h4 id=&quot;this-is-an-h4-tag&quot;&gt;This is an &amp;lt;h4&amp;gt; tag&lt;/h4&gt;
&lt;h5 id=&quot;this-is-an-h5-tag&quot;&gt;This is an &amp;lt;h5&amp;gt; tag&lt;/h5&gt;
&lt;h6 id=&quot;this-is-an-h6-tag&quot;&gt;This is an &amp;lt;h6&amp;gt; tag&lt;/h6&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;*Italic text*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Italic text&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;**Bold text**
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Bold text&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~~Strikethrough text~~
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;del&gt;Strikethrough text&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Combine: ***bold + italic*** or **bold + *italic* + ~~strikethrough~~**
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Combine: &lt;strong&gt;&lt;em&gt;bold + italic&lt;/em&gt;&lt;/strong&gt; or &lt;strong&gt;bold + &lt;em&gt;italic&lt;/em&gt; + &lt;del&gt;strikethrough&lt;/del&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* Item 1
* Item 2
  * Item 2a
  * Item 2b
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Item 1&lt;/li&gt;
  &lt;li&gt;Item 2
    &lt;ul&gt;
      &lt;li&gt;Item 2a&lt;/li&gt;
      &lt;li&gt;Item 2b&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. Item 1
2. Item 2
   1. Item 3a
   2. Item 3b
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;Item 1&lt;/li&gt;
  &lt;li&gt;Item 2
    &lt;ol&gt;
      &lt;li&gt;Item 3a&lt;/li&gt;
      &lt;li&gt;Item 3b&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;![Alt Text](https://images.unsplash.com/photo-1535952548450-d7447587e733)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;![Alt Text](https://images.unsplash.com/photo-1535952548450-d7447587e733)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[This is a Link](http://buiquangbao.github.io/)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;http://buiquangbao.github.io/&quot;&gt;This is a Link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; ‚ÄúYour time is limited, so don‚Äôt waste it living someone else‚Äôs life.‚Äù&amp;lt;br&amp;gt;
&amp;gt; Steve Jobs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;‚ÄúYour time is limited, so don‚Äôt waste it living someone else‚Äôs life.‚Äù&lt;br /&gt;
Steve Jobs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;There are 3 important files: `index.html`, `styles.css` and `scripts.js`
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There are 3 important files: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.html&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;styles.css&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scripts.js&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;
&lt;pre&gt;
&lt;div class=&quot;highlight&quot;&gt;
```javascript
function plus(p1, p2) {
  return p1 + p2;
}
```
&lt;/div&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;| First   | Second  | Third   |
| ------- | ------- | ------- |
| Content | Content | Content |
| Content | Content | Content |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
      &lt;td&gt;Content&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- [x] this is a complete item
- [x] this is a complete item
- [ ] this is an incomplete item
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;this is a complete item&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;this is a complete item&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;this is an incomplete item&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Bui Quang Bao</name></author><category term="technology" /><category term="web" /><category term="markdown" /><summary type="html">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas id imperdiet odio. Etiam quis volutpat mauris. Duis ligula lacus, maximus vel est sed, molestie finibus nisl. Aliquam erat volutpat. Mauris sit amet pretium urna, sit amet tristique enim. In eget arcu mollis, ultricies metus venenatis, tincidunt enim.</summary></entry><entry><title type="html">Risk management in real world</title><link href="/notebook/risk-management-in-real-world" rel="alternate" type="text/html" title="Risk management in real world" /><published>2021-01-03T00:06:00+07:00</published><updated>2021-01-03T00:06:00+07:00</updated><id>/notebook/risk-management-in-real-world</id><content type="html" xml:base="/notebook/risk-management-in-real-world">&lt;h2 id=&quot;1-risk-identification&quot;&gt;1. Risk identification&lt;/h2&gt;

&lt;p&gt;There‚Äôs a saying, ‚ÄúA plan has no chance when it meets reality.‚Äù I hope that doesn‚Äôt apply to your risk management. Here are some specific approaches I recommend to ensure your risk management plans effectively help you manage risks and their impacts on your project. Apply these as appropriate based on the type of project you‚Äôre running. First, seek out experienced project managers to participate in building or to review your risk identification list. Having people who‚Äôve been there and done that gives you a great advantage when building risk plans. You don‚Äôt want to call upon just any project manager however. Two sets of experience are most helpful. Finding a project manager who has worked with your specific client or area of the business before can give you valuable insights. Knowing your client‚Äôs risk sensitivities, those areas they‚Äôll be most concerned about, can focus your risk management planning. If you‚Äôre working in an industry or technology that‚Äôs new to you, find a project manager with that industry or technology experience. They can help you anticipate potential risks you might otherwise miss. My second real-world tip relates to those of you who are managing business process changes as part of your scope. Conduct a step-by-step process risk workshop. Gather your team together and brainstorm possible risks, examining your business processes step by step. While this may sound overly detailed, you‚Äôll be surprised how effective and efficient this can be. You end up surfacing risks that are very business focused which is extremely useful. And because there are several process steps you can skip over as you search for potential risks, the process risk brainstorming process doesn‚Äôt take as long as you might think. Finally, consider the immersion approach to risk identification. If you‚Äôre in construction or working on a project that‚Äôll be implemented in a specific environment, this is very effective at surfacing risks. Go to the location where your project will be implemented and immerse yourself in the environment. Spend time there to brainstorm your risks. A colleague of mine is in the mining industry. She won‚Äôt finalize her risk list without using the immersion approach. Seeing the environment, roads to and from the mine site, the attitude of the local community to the mine‚Äôs activities, and the nature of the terrain is invaluable to her. Although she could read schematics, industry reports, and study topographical maps, nothing surpasses being there. This is an underappreciated approach that also applies to projects where changes are anticipated for a specific business area. Go to the offices where the changes will be realized and get an understanding of the environment to identify potential risks. These techniques are useful to help you ensure your risk plan is pragmatic which is valuable to ensure you deliver your project successfully. And just maybe, your risk plans will indeed survive the clash with reality.&lt;/p&gt;

&lt;h2 id=&quot;2-risk-analysis&quot;&gt;2. Risk analysis&lt;/h2&gt;

&lt;p&gt;Real life is often a bit random, scattered, and even chaotic. While the steps for managing risk, identification, analysis, and response, flow nicely on paper, when working with stakeholders on a live project, things can jump around. As you start to analyze the risks you‚Äôve identified, people will try to derive response approaches or jump back to identifying more risks. Don‚Äôt worry, that‚Äôs okay. Here are a few very common instances when the risk management process doesn‚Äôt flow smoothly. These occur during real world risk analysis processing and you need to be sure the conversations don‚Äôt become too chaotic. First, your team may leap to conclusions and decide to change scope to avoid identified risks. As you start to discuss risks, your stakeholders may determine that some risks will likely have a high impact for your project. Almost always your team will start to determine ways to respond to the risk. If you find a reasonable way to address the risks, your team will move on. If not, it‚Äôs common for the team to talk about a different way to address project scope or even reduce scope to avoid the risk. Let them go through this process. Otherwise, you might have distracted stakeholders who aren‚Äôt engaged in assessing other risks as they keep thinking about this dangerous risk that might hurt your project. Second thing to look for, determining that risk is low impact without thorough analysis. Beware of instances where your team believes a risk is low impact, but they have not discussed the possibilities thoroughly. You should guide your team to look at all the ways a risk can impact your project. Ensure you look at scope, schedule, cost, and quality. Third, watch for risks that are improperly discarded because your team considers the risk too difficult to address. Your job as a project manager is to ensure your team pays appropriate attention to the risks you‚Äôve identified. When you believe a risk is being discarded because handling it‚Äôs too hard, it‚Äôs time for you to restore discipline. Ensure an assessment of the risk potential impacts and the probability of occurrence are captured. You can do research to prepare to address the risk during the response stage of risk management. These, and how to address other issues with risk analysis in the real world are flow-charted in a template I‚Äôve included in the exercise files for the course. Discussing risk often surfaces emotions, which can reduce your team‚Äôs sense of discipline. Let people surface their concerns and jump around with their thoughts, but be sure the appropriate risk analysis is completed and you‚Äôll be prepared to handle risks on your project. And if you do that well, you‚Äôll have a little less chaos in your life.&lt;/p&gt;

&lt;h2 id=&quot;3-risk-response&quot;&gt;3. Risk response&lt;/h2&gt;

&lt;p&gt;Have you ever walked into a room, flipped on the light switch, and nothing happens? You end up stumbling around, disoriented, trying to find a light source so you can see what you‚Äôre doing. Unfortunately, that type of thing happens often when risk response sessions don‚Äôt yield the proper results. A risk occurs, you invoke a response plan you and your team have agreed upon, and nothing happens. The risk still proceeds to impact your project and you stumble around looking for other solutions. You can avoid this unfortunate fate by being aware of certain real-world occurrences. Here are a few to look out for. You proceed without agreement. While you discuss and write down a response to a risk, your team doesn‚Äôt fully agree. This could be because they have not thought of something better, they don‚Äôt believe the risk will actually occur, or they don‚Äôt believe they‚Äôll be responsible for implementing the response solution. Ensure you poll your critical team members and confirm that they agree each risk response is doable and will legitimately address the risk. Your risk responses are business-as-usual activities. At times, people will suggest typical project management activities like draft and execute a communication plan as a response to a project risk. Risks are events that will occur despite the business-as-usual activities you engage in as a project manager. So using a standard tool is not a viable response approach. Ensure your team goes above and beyond the use of standard project artifacts when creating a risk response approach. Your risk responses create other risks and you fail to account for these new risks. For example, your risk response may be to hire a vendor to perform a task you would normally perform in-house. Should you need to execute that response plan, then you‚Äôll have vendor management-related risks you might not otherwise have in your plan. You neglect to include risk triggers in your response plan. While you might have created a sound response action for a risk, it does not become a response plan until you identify any indication a risk might be occurring and the timing for executing your risk response. For example, a complete risk response with a trigger and timing would be: should vendor X miss two deadlines, we will contract a back-up vendor on Y date. To help you review the integrity of risk responses, I‚Äôve provided a checklist of these and other risk response issues in the exercise files for this course. Risk response management is a critical exercise to maintain the viability of your project. With a bit of diligence, you can ensure your responses always shine a light on the right way to handle the risks that surface on your project.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="project_management" /><category term="risk" /><category term="learning_archive" /><summary type="html">1. Risk identification</summary></entry><entry><title type="html">Monitor and control project risks</title><link href="/notebook/monitor-and-control-project-risks" rel="alternate" type="text/html" title="Monitor and control project risks" /><published>2021-01-03T00:05:00+07:00</published><updated>2021-01-03T00:05:00+07:00</updated><id>/notebook/monitor-and-control-project-risks</id><content type="html" xml:base="/notebook/monitor-and-control-project-risks">&lt;h2 id=&quot;1-risk-management-in-reporting&quot;&gt;1. Risk management in reporting&lt;/h2&gt;

&lt;p&gt;I once had the hair-raising task of taking 12 kids camping. Getting everyone‚Äôs attention, then successfully communicating when I was needing them to hear was one of the biggest challenges of my life. You wouldn‚Äôt think communicating something on a project would be as difficult as working with those kids. However, communicating something as comprehensive as the risk on your project can be a far-reaching and tedious task. Incorporating risk management into your regular reporting approach is a great way to bring your risk management to light and keep a bit of balance in your own life. Here are some tips to do that. First and foremost, put a risk section in your regular status report. Discuss what you‚Äôve accomplished, deadlines you might have missed, and risk mitigation tasks you‚Äôre going to be tackling in the next reporting period. Status reporting should be concise, consistent, and frequent. So should your references to risk. Documenting risks in your status report ensures you‚Äôre communicating the risk to your project team, keeping your sponsor up to date on the true position of your project, preparing stakeholders for any corrective action you may need to take, and shows you‚Äôre planning ahead. The second way to incorporate risk management in your reporting is to use your project schedule. It‚Äôs a good practice to associate risks with tasks. Using dates from your project schedule, you can create sections in your schedule or risk response plan for risks that have been bypassed, that you must be aware of in the moment, and that you‚Äôll be looking at in future periods. A third technique is to distribute significant parts of your risk response plan. Highlights the risks you‚Äôre currently focused on and provide details to stakeholders that can help you detect and manage them. This is particularly helpful if you need to provide more detail on your risks or your organization has a particular sensitivity to a certain risk. For example, if your organization is sensitive to schedule risk, you might have a separate, detailed report to indicate when your schedule has varied from the plan. You can include details as to why it‚Äôs varied and any specific actions you‚Äôre planning to get you back on schedule. During times when there are lots of schedule risks, your risk response plan extract can go even further. You can detail the risk triggers and the actions to take if the risk triggers are noticed. It‚Äôs also useful to make note of any meetings or communications that happen around the risks, such as a phone call or email. This basically highlights how you‚Äôre managing the risk throughout your project. Make the effort to focus on your risk reporting, and you‚Äôll likely be able to suggest the best way to enhance or avoid most any risk that can surface on your project, and none of your kids or project stakeholders will get lost in the woods.&lt;/p&gt;

&lt;h2 id=&quot;2-when-to-execute-a-risk-response&quot;&gt;2. When to execute a risk response&lt;/h2&gt;

&lt;p&gt;Author Mandy Hale has said, ‚ÄúPick your battles. ‚ÄúYou don‚Äôt have to show up ‚Äúfor every argument you‚Äôre invited to.‚Äù So it goes with project risk responses. Executing every risk response action all the time will drive everyone crazy and take up precious time and money. Project managers who understand when to execute a risk response and when to hold off are the most effective when managing their projects. There are three ways to approach the execution of your risk response actions. The first is to execute proactively. For example, in a component design and assembly project, you may believe there‚Äôs a risk in making a telephone component out of fiberglass because you may need a solution that‚Äôs going to be more rigid. So using steel to make the component has been proposed as a response action. You can address this risk proactively by spending the money and time to have sample fiberglass components manufactured ahead of time. From these samples, you can determine if the rigidity risk is likely to occur. Basically, you‚Äôre trying to balance your triple constrains, time, scope, and cost. Being proactive and doing something ahead of time typically gives you the best result when it comes to risk management. But it can have drawbacks in costs and potentially time. Second, use an assess and respond approach. You test the fiberglass parts at the prescribed time in your schedule and then you decide on the immediate actions to take based on the results. If the fiberglass works well, you don‚Äôt spend any money on a response action you don‚Äôt need. If the risk is valid and the fiberglass is too flexible, you spend the money to correct situation by using steel. Going down this assess and respond route could cost you nothing if it works. But if the result isn‚Äôt the level of quality you need, you could incur triple constraint impacts when you least need those challenges. Consider your options carefully. The third option is to be reactive, you change something after the impact of the risk has been felt. If the fiberglass isn‚Äôt acceptable once you deploy it, then you correct it after installation. This will probably involve some additional testing processes and coming up with something like reinforcing the fiberglass part. It can also upset your client and your reputation. In this case, we‚Äôve let the risk pan out and then reacted to it. This is not typically a good option, but can be considered for very low probability or low-cost risks. Whatever the case, it pays to analyze your risk before deciding which way to execute your response to maintain the integrity of your project. Assess the impact of the risk. Look at how much control you need to put in place and when to get the optimal risk management result. And share your thoughts with your stakeholders so you don‚Äôt trigger stakeholder risks and arguments.&lt;/p&gt;

&lt;h2 id=&quot;3-assess-overall-project-risk&quot;&gt;3. Assess overall project risk&lt;/h2&gt;

&lt;p&gt;If you aren‚Äôt careful, you can create a substantial risk while managing risk on your project. While you deal with risks that are tied to tasks, you can forget what you‚Äôre really here for: to deliver an entire project. We need to step back and see, as they say, the forest through the trees. We need to assess overall project risk. There are two major considerations when evaluating overall project risk. First, your ability to deliver the project with the risks you know about, and then controlling the various directions the project can take to reach a conclusion. Let‚Äôs take a look at each of these. Risks, should they come to pass, will have an impact on your project outcomes, along with the money and time it takes to deliver those outcomes. If the impacts of your risks or the cost to address those risks outweigh the benefits you‚Äôll get from the project, you probably shouldn‚Äôt proceed. For example, if you work in an insurance company developing new products, you need to watch insurance regulations to be sure you can legally sell the products you design. Let‚Äôs say the government starts discussing new regulations and your experts determine there‚Äôs a 70% chance a law change will make your new insurance offering illegal to sell. You might want to reconsider your project as being too high risk until you know more about the regulations that are put into law. This was a very high risk example. It isn‚Äôt always that obvious. So, the viability of your project should be examined frequently. As your individual risks change, so will your overall project risk. This should be reviewed with your sponsor on a regular basis. Then, your ability to control the various directions your project takes is the other major factor to consider when addressing overall project risk. As your project unfolds, unexpected discoveries may surface. So, let‚Äôs say the technical approach planned for your project turns out to have more variables than you expected. I had this happen on an IT project I managed. After starting the project, my company bought another small company as a means of expanding their product offerings. This new scope created many complications. What started as a straightforward technical solution was going to have to interact with three other systems. So I had a larger number of variables to consider. I could no longer reliably predict what course of action was best to deliver the project. This introduced significant risk, and we canceled the project to allow us to study our options and launch a new project. Other examples of overall project risk are in the exercise files for the course. Overall risk is the key to determine if a project is appropriate. Surfacing concerns with overall risk isn‚Äôt a failure on your part. Rather, it‚Äôs the smart thing to do to protect your organization. Though many might see big healthy trees around you, making sure you‚Äôre in the right forest is one of your jobs as a project manager.&lt;/p&gt;

&lt;h2 id=&quot;4-agile-risk-management&quot;&gt;4. Agile risk management&lt;/h2&gt;

&lt;p&gt;Ever have the feeling you‚Äôve experienced something before like your life history is repeating itself? When you‚Äôre managing risk on an agile project, that‚Äôs the case and it‚Äôs absolutely fantastic. The iterative nature of an agile project is ideal for risk management if you have the right mindset. Here are my recommendations for performing risk management in an agile environment. First, understand that by design risks will change more rapidly in an agile environment. At the end of every sprint you may add, delete, or reprioritize features. This flexibility in providing functionality for the client is great, but it also changes the risk profile for your upcoming sprint and potentially the entire project. For example, let‚Äôs say you‚Äôre working on a project to create an executive dashboard for your company. The dashboard will provide your senior management team with critical information about financial status, competitors‚Äô performance, and sales projections. Each feature that is produced could surface risks such as ensuring that data retrieved for the dashboard is up-to-date, information is from the same timeframe when combined with other datasets, ensuring search capabilities for the executives will yield the intended report. As the executives use each feature and ask for new capabilities, the chances of these risks increasing or other risks surfacing is very high. Diligence in managing these rapidly changing risks is critical. The second characteristic is fortunately that risks can be revisited naturally due to the agile life cycle. Given the dashboard project that I‚Äôve just shared with you, at the end of each sprint the backlog of features will be reviewed and reprioritized. This is a very convenient and appropriate time to revisit risk. New features, the sequence used to produce features, and reviewing the results of features already produced are a great source of potential risk going forward. Taking time at the end of each sprint to review risk should be part of the habits your agile team uses to manage your project. Third, risks can be assessed frequently. As agile sprints are typically only a few weeks long, reviewing risks at the end of each sprint creates a risk management culture within the project. In our project example, the project team and executives that are using the dashboard can discuss risks while the information is fresh. So the concept of risk management is kept front of mind while progressing the project. Leveraging the agile life cycle to control your risk is one of the greatest benefits agile brings to project management. Take full advantage of this, as it‚Äôs a prudent way to ensure risks are known and addressed during your project. I guess it‚Äôs one of those instances where history repeating itself is a good thing.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="project_management" /><category term="risk" /><category term="learning_archive" /><summary type="html">1. Risk management in reporting</summary></entry><entry><title type="html">Respond to project risks</title><link href="/notebook/respond-to-project-risks" rel="alternate" type="text/html" title="Respond to project risks" /><published>2021-01-03T00:04:00+07:00</published><updated>2021-01-03T00:04:00+07:00</updated><id>/notebook/respond-to-project-risks</id><content type="html" xml:base="/notebook/respond-to-project-risks">&lt;h2 id=&quot;1-common-risk-responses&quot;&gt;1. Common risk responses&lt;/h2&gt;

&lt;p&gt;Project managers are like Superman or Wonder Woman with bullets coming at them. The bullets are risks and you want to plan risk responses to the incoming bullets. You could step out of the way, avoiding the risks. You could use a shield to deflect the bullets or mitigate the risk. You could pick up a bad guy and put him in the way of the bullets transferring the risk. Or, having super powers, you could accept the risk of being hit by the bullets if they won‚Äôt harm you. While we aren‚Äôt actually superheroes, we do have the same variety of risk responses. Let‚Äôs take a close look. Avoiding a risk means we eliminate it. Whatever risk might be present, we take action to make it irrelevant. Let‚Äôs say your project involves something out of fiberglass, however, a risk exists that the fiberglass might be too flexible so instead, you and the team decide to make the component out of steel. You avoided the risk by using steel. Another response, is to mitigate the risk. You do so by reducing the probability or reducing the impact of a risk occurring. Let‚Äôs look at reducing the probability of a risk occurring first. Let‚Äôs say you‚Äôre concerned that the vendor you‚Äôre working with might be late in delivering their products to you. One approach, reducing the probability of lateness being an impact is to put a contingency contract in place with a second vendor. You could call upon them if the primary vendor will be late. The second approach, is to reduce the impact of a risk occurring. You could create an alternate project schedule to perform tasks later than involve the parts you‚Äôre receiving from the vendor. You can also respond with transference. In transference, you shift the risk to someone else. The most common example of this is taking out insurance. When you get insurance on your car, much of the risk impact is transferred to the insurance company. You can also accept the risk. This means you do nothing to avoid the risk. It‚Äôs a common response for low priority risk events. Lastly, you can escalate the risk. You do this when risk is beyond the project manager‚Äôs scope. For example, a change in strategy for the company, isn‚Äôt a risk that the property manager would normally be involved in. The responses for positive risks or opportunities are similar. Excepting and escalating have the same meaning. Instead of avoiding the risk, we strive to exploit it. Increase the possibility of it occurring to 100% when possible. Share, replace as transfer, you involve another party to increase the positive effects or probability of the opportunity occurring. Finally, enhance replaces mitigate where we increase the probability or impact of the positive risk occurring. As you can see, you have great options for response approaches to address your risk. Even if you aren‚Äôt a superhero. Think through them and you‚Äôll easily clean-up your project.&lt;/p&gt;

&lt;h2 id=&quot;2-write-your-risk-plan&quot;&gt;2. Write your risk plan&lt;/h2&gt;

&lt;p&gt;I have a problem. I love building risk plans, but sometimes I forget I have those plans when I get into the day to day excitement of project execution. So, how do I ensure the risk activities I plan for are executed when I need them? The answer is create a risk response plan, a document that captures your risks, the analysis you‚Äôve performed, and guides your actions going forward. Let‚Äôs talk about what to include in your risk response plan. First, the risk response plans lists your risks, including identified risk causes, descriptions, and potential impacts. Second, include your qualitative and quantitative analysis results and your response plan for each risk. You may include a primary and secondary risk response plan if appropriate. Third, include contingency reserve funds that have been allocated. If you have risks that include contract-related actions you‚Äôll discuss with your vendors, note these as well. After these fundamentals are in your risk response plan, these additional elements can turn a risk response plan into a powerful control document. The most significant item to add to each risk is the timing for when you need to either A, assess the status of the risk, or B, execute a response action. These can be added as tasks in your project schedule and assigned to a specific individual. Here‚Äôs an example. When I was moving from the US to a work assignment in Australia and having my household goods sent to Australia by sea, I didn‚Äôt know when I packed the container, whether it would go from LA to Sydney directly or via Singapore. Therefore, when I arrived in Australia, I didn‚Äôt know if I needed to get a short-term furnished apartment or arrange for a permanent place to live where I would have my furniture delivered. I had a housing risk to manage. I had to know two timing-critical actions against that risk. When to check the schedule status of my shipment to determine if my furniture would be available and when I needed to find a temporary furnished apartment if needed. The next significant item to have in your risk response plan are status dates for your vendors, or to check on products from areas not under your control. Going back to my furniture shipment, I had another risk to manage. The customs agent in Australia could decide to inspect my goods shipment or hold it in quarantine for a period of time. I had to monitor the progress of my household goods through Australia customs. I had no control over them and had to establish dates when I needed to get temporary housing, even though my furniture might be in the country with me. By ensuring your plan is robust and helps you track the actions required to monitor and execute responses against risks, you can dramatically reduce the impact of risk on your project and not experience things like getting stuck with a house but no furniture.&lt;/p&gt;

&lt;h2 id=&quot;3-understand-risk-triggers&quot;&gt;3. Understand risk triggers&lt;/h2&gt;

&lt;p&gt;Good project risk managers resemble park rangers. Park rangers construct towers to keep an eye on the landscape, looking for signs of trouble. This works well because where there‚Äôs smoke, there‚Äôs usually fire. You should do the same thing. As smoke is the warning sign for fire, I suggest you spend time thinking of what are called risk triggers, early warning signs like smoke that indicate a project risk is about to become a reality. Let‚Äôs look at two common types of risk trigger. The first type of risk trigger is one that gives you an immediate indication that a risk may be happening. You may have technical experts that are going to join your project at some point downstream. You request these technical experts to start attending status meetings one month before they‚Äôre due to start so they can hit the ground running and know what‚Äôs happening on the project. The time for them to participate has arrived, you remind them of their commitment, and they don‚Äôt show up for the status meeting. This is a likely risk trigger that other priorities might put the expert‚Äôs participation in your project at risk. The second type of risk trigger are forward indicators. Unlike smoke, which indicates the fire is happening now, forward indicator risk triggers are signals something is going to happen in the future. Tuna fishermen provide a useful example of a forward indicator risk trigger because they have risk triggers tied to the temperature of the water at different times of the year. They understand if it‚Äôs going to be plentiful fishing season or if there‚Äôs a risk of poor fishing depending on the water temperature. Project risk triggers can vary and typically involve people‚Äôs behavior, unexpected schedule changes, or task deadline failures. No matter the type or variety, here are hints for determining and handling risk triggers. I‚Äôve provided a short checklist of potential risk triggers in the exercise files. First, do some research. Potential sources for risk triggers include prior risk logs, post-implementation reviews, and issues logs from past projects. Second, once you‚Äôve determined reasonable risk triggers, empower your team to search for them. The reality is that while you have to keep your eye on things, you can‚Äôt be everywhere. Empower your project team so they understand the risk triggers too. Get them to staff the watchtowers and look for smoke. Third, plan what you‚Äôre going to do when you spot a risk trigger. The whole idea of utilizing risk triggers is to enable you to react quickly and decisively. Have a risk response plan for when you spot that smoke. Just like your doctor uses a series of tests to assess your health, risk triggers help you validate the health of your project. So, just like the park rangers, watch diligently, understand what you‚Äôre looking for, and react promptly and you‚Äôll have a healthy project without large fires.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="project_management" /><category term="risk" /><category term="learning_archive" /><summary type="html">1. Common risk responses</summary></entry><entry><title type="html">Analyze project risks</title><link href="/notebook/analyze-project-risks" rel="alternate" type="text/html" title="Analyze project risks" /><published>2021-01-03T00:03:00+07:00</published><updated>2021-01-03T00:03:00+07:00</updated><id>/notebook/analyze-project-risks</id><content type="html" xml:base="/notebook/analyze-project-risks">&lt;h2 id=&quot;1-qualitative-and-quantitative-risk-analysis&quot;&gt;1. Qualitative and quantitative risk analysis&lt;/h2&gt;

&lt;p&gt;All these risks, it‚Äôs just too much. They‚Äôre making me crazy. How could you manage a project without spending 120% of your time managing risk? The answer is perform a qualitative risk analysis to prioritize your risks. To do so, perform a quick high-level assessment of their probability and impact. Here‚Äôs my approach. First, assess the impact of each risk. Determine if each risk would have a high, medium, or low project impact. The impacts you consider should include cost, schedule, and deliverable quality. Second, do the same for probability, high, medium, or low. Keep it simple. The point is to get a quick high-level ranking for all your risks. It‚Äôs a filter to help you work out which risks are worth spending your time on. Now, the next step, sort the results. This will give you a high-level reference for which risks need to be examined further. You‚Äôll want to address your high probability, high-impact risks first, then look at your risks rated with lower probabilities and impacts. For all of your risks with low ratings, you‚Äôre probably not going to examine them much further, and that‚Äôs okay. After you‚Äôve performed a qualitative analysis and identified the risks you should consider managing, then you conduct a quantitative risk analysis on your top-ranked risks. Quantitative analysis is the process that informs you how much you could spend to address a risk. For example, you don‚Äôt want to spend $10,000 to address a risk that will cost you $5,000 if the risk event occurs. Here are my steps for quantitative analysis. First, refine the probability for each risk occurring. Because we‚Äôre looking for a more refined estimate, assign a probability in increments of 10. So, 10%, 20%, and so forth. Second, estimate the cost of your project if a risk occurs. This could be hard to estimate, but give it a try. The third step is to multiply your estimates for the probability and cost impact for each risk and sort the result. This will highlight your most important risks. For example, Risk A has a probability of occurring of 70%, and an impact of $10,000. The resulting answer would be 70% of 10,000 or $7,000. If Risk B had a probability of 30% and a cost impact of $150,000 the result would be 30% of $150,000 or $45,000 so Risk B should be addressed before Risk A. The last step is to take your most important risks and ask, if I was going to address this risk, how much would this cost? There could be a number of ways to address a risk. However, the greater the potential impact, the more analysis you‚Äôll want to perform. So that‚Äôs it. Understanding which risks you need to manage and determining how much you can spend to address them is vital for proper project risk management. The key is to be methodical. Categorize and address your most vital risks and save yourself from the risk of going crazy.&lt;/p&gt;

&lt;h2 id=&quot;2-variability-and-ambiguity-risks&quot;&gt;2. Variability and ambiguity risks&lt;/h2&gt;

&lt;p&gt;Not knowing what you need to know can be stressful. Not even knowing what you don‚Äôt know can be distressing. Let‚Äôs look at two categories of project risk that involve things you don‚Äôt fully know. These risks can create problems if they‚Äôre not considered. The first is variability risk. This is risk that comes from variables in your environment that always exist, but over which you have no control. For example, weather can have a significant impact on the schedule of a construction project. While you might target a time of year when the weather‚Äôs more cooperative, weather will always vary. The second category is ambiguity risk. In contrast with variability risks where you know something will happen but the results will vary, like the weather, ambiguity risks deal with unknown factors about what will happen in the future. Examples of this are legislation that may be signed into law during the course of your project that require changes, new technical inventions that may improve or detract from your project, or a new product that may be introduced by a competitor that exceeds your deliverable‚Äôs capabilities. To help you identify these two risk types, I‚Äôve included a checklist with examples in the exercise file for this course. These two risk types are especially difficult as they have characteristics that are unknown. So how do you deal with them? Let‚Äôs return to our variability risks. Timeframes or circumstances where the variability is less is the first place to look, so for example scheduling construction during periods when the weather is more favorable would demonstrate this approach. Here‚Äôs another approach. If you have access to records from several past projects similar to the project you‚Äôre running, you can compile a list of schedule possibilities for completing the project based on that history and plan your project around the information you uncover. If that project history is not available or you need more detailed schedule predictions, you can use Monte Carlo analysis. Monte Carlo analysis uses probability spreads compiled from running large numbers of possibilities through a math-based model to determine the range of possibilities for your project schedule. This can inform you about the chances of your schedule completing in varying amounts of time to help you manage schedule risk. Ambiguity risks are typically addressed by collecting expert opinions. For example, people who are close to the workings of government can help predict where and when laws might change. Industry experts would likely signal an upcoming new development like the moving downloading services that ultimately spelled the end for brick and mortar DVD rental stores. While you can never know every risk that may surface for your project, having a standard process for considering the possibilities is important so you don‚Äôt get stung. Spending time looking at the potential impacts of variability and ambiguity risks can save you time, help you be ready for the unexpected, and increase your perception as a project leader.&lt;/p&gt;

&lt;h2 id=&quot;3-assess-and-prioritize-analyzed-risks&quot;&gt;3. Assess and prioritize analyzed risks&lt;/h2&gt;

&lt;p&gt;I hate spiders but I think snakes are pretty cool. My wife however, is terrified by both of them. Eliminating either of these critters in my yard is a high priority for her. However, I‚Äôd rather leave the snakes and get rid of the spiders. Our priority for risks is different. A similar situation will take place on your projects. It‚Äôs important to remember that your stakeholders, sponsors, and project team may want you to treat risks differently. Here are the steps you can take to make sure you and your risk sensitive stakeholders will be aligned when it comes to managing your project risks. First, split your risks into impact type. Time impacts, scope impacts, and cost impacts. Once you‚Äôve done this, consider your stakeholders‚Äô tolerance for these three types of risk. Second, consider prioritizing your risks to ensure the impact type with the lowest stakeholder tolerance gets a high priority. By understanding the sensitivities of your stakeholders and sponsor and adjusting the way you prioritize things, you‚Äôll have an easier time managing risk on your project. The third step in refining your risk analysis is to consider your potential risk treatment actions and their cost. Then compare the actual cost the risk would add to your project and most importantly the impact to the perception of your stakeholders. A project manager and sponsor rarely have a large fund to mitigate risks. As a result, you need to decide how to allocate those funds wisely. If you only have $200,000 of risk treatment funding available to manage risk on your project, you want to have the risk prioritized and only allocate the $200,000 to the risks that should be addressed. This prioritization should consider the overall financial impact to the risk, the cost of addressing the risk, and the risk tolerance of your sponsor and senior stakeholders. Once you‚Äôve done this, you‚Äôre ready to take the fourth and final step to completing your risk analysis. Share your prioritized risks with your sponsor. I have included a table in the exercise files to provide you with a format I recommend. Here are some tips to finalize your risk analysis. It‚Äôs important that you communicate your estimates and assumptions so you and your stakeholders understand your thought process. And last, fault on the side of being inclusive, involve as many stakeholders as you can. Not only will you produce a better risk analysis product but in the event an unexpected risk does become an issue, you won‚Äôt be alone when answering the dreaded why didn‚Äôt you think of that question? Taking these steps to assess and prioritize risks is well worth it. Understanding who will react to each type of risk can help you understand and proactively work with your stakeholders. Kind of like understanding that your boss might be terrified of that snake. So even though you think it‚Äôs cool with beautiful markings, best keep it away from him.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="project_management" /><category term="risk" /><category term="learning_archive" /><summary type="html">1. Qualitative and quantitative risk analysis</summary></entry><entry><title type="html">Identify project risks</title><link href="/notebook/identify-project-risks" rel="alternate" type="text/html" title="Identify project risks" /><published>2021-01-03T00:02:00+07:00</published><updated>2021-01-03T00:02:00+07:00</updated><id>/notebook/identify-project-risks</id><content type="html" xml:base="/notebook/identify-project-risks">&lt;h2 id=&quot;1-risk-identification-methods&quot;&gt;1. Risk identification methods&lt;/h2&gt;

&lt;p&gt;Moving forward on a project without performing risk identification is like heading on a hike in the wilderness without a GPS. It‚Äôs easy to get yourself quite lost when you encounter the unexpected and don‚Äôt have anything to help you navigate. Risks represent the unexpected in my hiking analogy. Different types of projects have different risks and if you don‚Äôt know your risks, the probability of them occurring and the impact they‚Äôll have, it‚Äôs impossible to manage them. So an appropriate risk identification process is crucial. Here are risk identification approaches I recommend for use with your projects. The first approach is to hold a brainstorming session, also called a risk workshop. As they say, several heads are better than one, and this holds true when identifying project risks. For these workshops however, don‚Äôt limit yourself to your project team. It‚Äôs a good idea to involve your stakeholders, sponsor, and potentially other project managers in this workshop. To make these sessions more effective, it‚Äôs important that you use a list of questions, also called a prompt list. For example, is your customer organization used to change? Are there external factors that will impact your project? Does a lack of a particular skill in the organization present a risk? What are the lessons learned from previous projects? In the this session, have everyone come up with their top five risks, and remember that through this exercise, traditional brainstorming rules apply. Capture all the potential risks. There are no bad ideas. You‚Äôll sort through them later. If you need some ideas for your prompt list, I‚Äôve provided sample questions that you can download in the Exercise Files for this course. Examples include, what would be most likely to become more expensive to produce than what we expect, and why? Which of our project team members is mostly likely to have another priority item assigned to him? What would the impact be? The second risk identification method I recommend is to use industry-specific risk categories. For example, in the construction industry, there are safety risks. In IT, there are information security risks and risk involving making solutions too complex. To help, most industry associations have online resources and risk tools that you can leverage. Use them to identify risks if you‚Äôre a member of an association that makes risk resources available. You might also find resources through other project managers involved in your industry. The Project Management Institute also has project management standards for projects in government, software, and construction. The last technique to consider for risk identification is to examine your work breakdown structure, or WBS, and identify risk by task or groups of tasks. Using the tasks in the WBS can trigger risk ideas that you otherwise might miss. This is a good last step to help ensure you‚Äôve thoroughly considered risks that may impact your project. You can‚Äôt address risks you haven‚Äôt identified. Launching your risk management approach with thorough and well-considered risk identification practices will help you avoid being lost in the project wilderness without a GPS.&lt;/p&gt;

&lt;h2 id=&quot;2-categorizing-and-consolidating-risks&quot;&gt;2. Categorizing and consolidating risks&lt;/h2&gt;

&lt;p&gt;Risks are like having a large cart of groceries. You need to sort things out, place items in separate bags for the freezer, fridge and pantry so you‚Äôre organized when you get home. The same pertains to risks on your project. How will you ensure your risks are well-organized so you can manage them? Categorizing risks for your project is a great way to ensure you‚Äôre well-organized. Let me share some typical ways to categorize risks and some tips for using those categories wisely. First, try to identify any risks that have common causes. For example, one common area for risks might be not having enough people, or you lack people with the relevant skills. You could have a substantial list of risks, but many can be managed collectively by tying them back to a category of people and skills. A second way to categorize risk is by business area, such as external market risks or business strategy changes. This can be very helpful when you‚Äôre dealing with your client and the risks they bring to the project. Taking this approach can enhance the perception that you‚Äôre managing the project with your client and their needs in mind. It can also help engage your client to ensure you manage their risks appropriately. A third way to categorize risks is by technical area. These might include design and development challenges, testing and maintenance risks and uncertainty with technical vendors. Fourth, you can utilize an integration risk category. Integration risks surface when you‚Äôre working on your project while there are other things happening in your organization. This activity can cause priority problems or conflicts with other project deliverables. If you have nine projects targeting a single business area, this might signal a need to address integration risks, as solutions may need to be coordinated or even merged together. Although these are common risk categories, you may find other categories that are more useful on the specific projects you manage. No matter which categories you use, here are a few tips for using those categories to manage risks. Revise your categories as necessary. As the project progresses, you may learn more about the risks that are substantial. Therefore, more relevant categories may surface. My final tip is to always keep your list of categories short and simple. Try to avoid a heap of categories for you and your team to sort out. Package the risks so they‚Äôre relevant for your project team and other stakeholders. For help with this, I‚Äôve included a risk identification checklist in the exercise files for the course to give you an example. Using well-crafted risk categories can help you manage your project risks more easily. But it also helps your stakeholders see the risks for what they are, and helps you work with your risks more effectively, kind of like ensuring you don‚Äôt leave frozen items on your kitchen counter when you get home from the store.&lt;/p&gt;

&lt;h2 id=&quot;3-risk-records-and-registers&quot;&gt;3. Risk records and registers&lt;/h2&gt;

&lt;p&gt;Risk management plans fill up lots of waste baskets, accompanied by frustrated project managers screaming things like, ‚ÄúThis risk plan is useless.‚Äù The difference between risk plans that work and those that do not usually comes down to one simple element: the way risks are written. Let me share a story where risk records were written inadequately. An airport identifies a risk that their fuel trucks may be unable to make it to refuel airplanes in a timely manner. This‚Äôll cause flight delays. As a response, the project manager assumes the risk involves the fuel trucks having a mechanical failure. He decides to have more fuel trucks available so they‚Äôll always have a truck ready to refuel the aircraft. Sounds like a reasonable risk mitigation strategy. However, during the next month the fuel truck drivers go on strike. They could have all the fuel trucks in the world, and none of them would show up. What went wrong here? The project team only considered one cause for the risk occurring. So you don‚Äôt end up like our unfortunate airport manager, let‚Äôs take a look at the formula for writing effective risk records. A properly structured risk record is as easy as pie. The probability of impact as the result of an event. Add the cause of the event and you have a useful risk record. Back to our airport example. An appropriate risk record would be there is an x% chance that the fuel truck drivers will go on strike, causing the fuel trucks and aircraft departures to be delayed. This will increase costs by $y per flight. It‚Äôs notable here that you may need more than one risk record to cover other items, flat tires, for instance, that may delay fuel truck arrivals. This could be covered with additional trucks. Doing good risk identification and analysis is important, but it all has to go somewhere. That place would be your risk register. First, your risk register captures the risks that have been identified in an overall assessment of project risk. Your project level risk comes from looking at your risk overall, and total potential impact to your project. Many high-impact risks that would be expensive to avoid would lead to a high risk project. Few risks overall or few risks that have high cost response plans likely means your project is low risk. Between these two end points you probably have a medium risk project. Second, include your plans for treating each risk, as well as the cost of any treatment strategy. You might do this for medium and high risks only. Third, identify the owner of each risk and how the risk is tied to tasks in your project schedule. Finally, keep it current. Make sure the risk register is updated after every status meeting. Follow these activities and it will bring your risk management to life and keep your project healthy. Oh, and it‚Äôll also reduce your need to empty your waste basket.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="project_management" /><category term="risk" /><category term="learning_archive" /><summary type="html">1. Risk identification methods</summary></entry><entry><title type="html">Create a risk plan</title><link href="/notebook/create-a-risk-plan" rel="alternate" type="text/html" title="Create a risk plan" /><published>2021-01-03T00:01:00+07:00</published><updated>2021-01-03T00:01:00+07:00</updated><id>/notebook/create-a-risk-plan</id><content type="html" xml:base="/notebook/create-a-risk-plan">&lt;h2 id=&quot;1-understanding-risks-and-opportunities&quot;&gt;1. Understanding risks and opportunities&lt;/h2&gt;

&lt;p&gt;Projects deal with change, and dealing with change is risky business, as many businesses don‚Äôt handle change very well. My experience is that many project managers aren‚Äôt prepared so they don‚Äôt appropriately manage risk. When I talk about risk, I‚Äôm talking about things that haven‚Äôt happened yet. There‚Äôs a probability of some sort of event occurring that‚Äôll have an impact on your project. There are two major categories for risk, positive and negative risk. Positive risks are often called opportunities. These are things that can happen that will enhance the outcome of your project. For example, your project team might make a breakthrough that cuts the time to complete a set of tasks in half the time. As there are typically more instances of negative things happening in projects that have to be managed, project managers typically focus on negative risk. Negative risks are events that could cause your project to be thrown off course, so it‚Äôs vital that you pay attention to them. Whether you‚Äôre dealing with positive or negative risk, there are a standard series of steps to follow when managing risk. First, you need to identify the risks on your project. When you see something that will probably happen, you should take action ahead of time, before the impacts affect your project. Be proactive rather than being reactive. The second step is to assess the likelihood of a risk happening and determine which risks you will address. You don‚Äôt address all risks, as some, like an asteroid destroying your building, is so unlikely you won‚Äôt want to deal with it via risk management. Addressing risks means taking action. Determining the actions to take is step three. This is to investigate alternatives to address your risks. You‚Äôll want to steer your project around the bumpy section of the road, or you might try to smooth out part of the road for a more comfortable ride. Using either alternative, the idea for you as a project manager is to control how much your projects are exposed to risk. The last step in the risk management process is to control risks on an ongoing basis. This is important to do because risks change over time. You should frequently assess your project for the likelihood of a risk happening and its potential impact. Understanding the consequences of any risk will help you manage it appropriately. Any sort of change comes with a level of risk. It‚Äôs how you manage that risk that makes all the difference. Ultimately, project management is risk management. By clearly understanding your risks in light of what you‚Äôre trying to achieve, your project has a greater chance of being delivered successfully, and you might not be perceived as a risk taker for working on your project.&lt;/p&gt;

&lt;h2 id=&quot;2-incorporating-risk-management&quot;&gt;2. Incorporating risk management&lt;/h2&gt;

&lt;p&gt;Don‚Äôt try this at home. We hear this a lot on action or experiment based TV programs. Why? Because the risks of harm are great. The average person should never try the skateboard tricks you see on TV. Projects, while not typically physically dangerous, should come with a warning like those TV programs. They come with risk. As a project manager, not a day goes by when I don‚Äôt see something that could present a risk to my project. My advice to you? Deal with risk thoroughly without it consuming every moment of your day. Here are a few survival tips to help you do this. First, use risk to prioritize what you do on a day-to-day basis. At the start of every day, prioritize your tasks. Seek to tackle the riskiest things first. For example, if you think that one of your vendors might miss a deadline, you should prioritize your time to visit with them to understand and examine your options if necessary. If you think a risk is going to impact an implementation process, look at that process, assess it, and attempt to control it. Better yet, change the process to reduce the risk. Second, discuss risk openly with your sponsor. Ask what risks they think are important and determine what they think of your strategies to deal with risks. Ask for suggestions and garner their support. Third, make risks a regular topic at your status meetings. You should include your customers and your sponsor in these discussions. Having regular, open, and frank discussions about risk will help you manage risk as a regular course of doing business. Finally, after each of these risk assessment discussions, create or update your overall risk plan. This plan details the risks you are managing and provides an ongoing means of reporting what actions you‚Äôre taking and the status of each risk. Your vendor potentially being late would be added to your plan, if you didn‚Äôt have one in there already. The risk plan helps you ensure you‚Äôre on top of what‚Äôs going on with risk on your project. Working the plan proactively helps you be cool, calm, and collected in your risk management approach. I like to treat risk management as an everyday event and an essential part of keeping my projects on track. If you ignore the whole idea of risk management, you‚Äôll end up fighting fires and this is a tough way to spend your day. Fighting fires can have a negative impact on your schedule, your costs, and the quality of the products you deliver. Not to mention the emotional drain it puts on your and your team. And you‚Äôll be so busy putting out the fires that any process improvement opportunities will be largely overlooked. If you look and act like you‚Äôre in control of risk, then you‚Äôll have a better chance of getting other engaged in a sensible risk management approach. In addition, you‚Äôll help your management perceive you as a person with a balanced business approach to implementing your project and not engaging on those crazy skateboard stunts you‚Äôd only see on TV.&lt;/p&gt;

&lt;h2 id=&quot;3-stakeholders-risk-tolerance&quot;&gt;3. Stakeholder‚Äôs risk tolerance&lt;/h2&gt;

&lt;p&gt;World renowned boxer Muhammad Ali said, ‚ÄúHe who is not courageous enough to take risks ‚Äúwill accomplish nothing in life.‚Äù Now, his idea of risk, however, may be different than yours and mine. After all, he used to step into the boxing ring with someone trying to knock his head off. Most project managers don‚Äôt want anything to do with being in a boxing ring, but they‚Äôre happy to tolerate other risks. So, how do you find out about your stakeholder‚Äôs risk tolerance? First, be prepared that your stakeholders, sponsors, and the people on your project team will each tolerate risk differently. Some people might actually step into that boxing ring while others are cautious just walking down stairs. And there‚Äôs everyone in between. You need to take this into consideration when you talk about risk in your project. The key is to always listen carefully as you discuss elements of your project. The second thing to keep in mind is that people have business motivations to protect scope, time, or money when these constraints are discussed. We need to understand these motivations. For example, one organization I know of is involved in yearly industry trade shows. At these shows the company is expected to display new products. If they don‚Äôt have new products ready to show off at the trade shows, it‚Äôll impact their business. A project stakeholder in this instance will be totally focused on time constraints because it‚Äôs critical they have products ready to demonstrate at that trade show. Risk impacts to cost and scope are a much lower priority for them as long as they get their new product when required. A third factor when considering risk tendency is your stakeholder‚Äôs performance evaluation. How is your stakeholder being appraised by their manager? What are they being encouraged to do or change in their business area? Candid discussions about your stakeholder‚Äôs expectations and concerns can give you a feel for which project constraints they‚Äôll want to focus on. To obtain this information, it‚Äôs necessary to pose critical questions, and listen very carefully to the answers you receive. Without directly asking about their personal performance evaluation you can ask them what business outcomes are they most excited about, and what potential negative business outcomes most concern you? What are you being incented to achieve this year? Fourth, is the culture of the organization. It has a substantial impact on risk tolerance. Some entrepreneurial organizations will take significant risk, whereas more conservative industries will more aggressively seek to mitigate risk. And as their project manager, they‚Äôll expect you to conform to their style. Muhammad Ali used to say, ‚ÄúI float like a butterfly, sting like a bee.‚Äù Appreciate the risk tolerance of your stakeholders, and you might not float like a butterfly, but you won‚Äôt be accused of stinging like a bee.&lt;/p&gt;

&lt;h2 id=&quot;4-the-components-of-a-risk-plan&quot;&gt;4. The components of a risk plan&lt;/h2&gt;

&lt;p&gt;Murphy‚Äôs Law states if anything can go wrong, it will. Well, I believe Murphy has relatives, and they all live in project circles. Doesn‚Äôt take much for risk to haunt your project. So, to control this potential chaos, you build a risk plan. A risk plan is a document that describes how project risk management will be structured and performed on a project. I‚Äôve included a sample plan in the exercise files, and shortly, I will talk you through an example based on that plan structure. First, your risk plan needs to describe your risk identification approach. The most common way to do this is to run a risk identification workshop. Get a group together, including sponsors and project team members, and brainstorm risks. You could use risk registers from prior projects as a start. The second element of a risk plan is to capture how you‚Äôll describe the risks. For example, you‚Äôll want to capture the characteristics of the risks. Characteristics include categories like personnel or technical issues. You might also capture the nature of impact to the project should the risk occur. Schedule, cost, and scope are common impact descriptions. The third element of your risk plan is to document how you will perform qualitative and quantitative risk analysis. Qualitative analysis is when you prioritize risks based on their probability and impact of occurring. Quantitative analysis is when you estimate their effects on project objectives. Here‚Äôs an example of a qualitative analysis. The risk is, will a power outage impact the installation of your deliverables. If so, what impact would this have on your project? What‚Äôs the likelihood of it occurring? To do this efficiently, I suggest you use high, medium, and low to answer each of those questions. You don‚Äôt need to get overly detailed at this point. After this qualitative analysis, you take a further look at your significant risks via a quantitative analysis. You try to quantify the impact. By doing the quantitative analysis you can assess how much you could spend to try and reduce the risk. Using our power outage example, you don‚Äôt want to use $10,000 to buy a power generator to prevent the power outage risk that will cost $5,000 if it occurs. The fourth element of a risk plan is the approach you‚Äôll take to address each significant risk. For example, will you purchase the power generator to avoid a total power outage, or will you schedule alternate installation times in the event of a power disruption. The last element of your risk management plan is how you will monitor and update risks as your project progresses. This section describes things like regular risk assessment meetings to keep on top of changing risks. It also describes how you‚Äôll update and communicate new risk status items on your project. Using these elements to create and manage your risk plan will put you on solid ground to handle risks, and uninvite all the Murphys from your project party.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="project_management" /><category term="risk" /><category term="learning_archive" /><summary type="html">1. Understanding risks and opportunities</summary></entry><entry><title type="html">Acting on Data Science</title><link href="/notebook/acting-on-ds" rel="alternate" type="text/html" title="Acting on Data Science" /><published>2021-01-01T00:00:09+07:00</published><updated>2021-01-01T00:00:09+07:00</updated><id>/notebook/acting-on-ds</id><content type="html" xml:base="/notebook/acting-on-ds">&lt;h2 id=&quot;1-interpretability&quot;&gt;1. Interpretability&lt;/h2&gt;

&lt;p&gt;You‚Äôve done all the work. You‚Äôve planned the project. You‚Äôve found data. You cleaned and organized the data. You created a model, you validated the model and you just want to put a bow on it and be done. Well, one thing that you need to consider before you wrap it all up, is who is going to make the decision? Who‚Äôs using the results and the insights that you got from your analysis? Because you have a couple of choices. One is, maybe you‚Äôre developing something that is for the benefit and use of algorithms. This is, for instance, a recommendation system which automatically puts something in front of people or a mortgage application system, which process it immediately while people are still on the website. In that case, the machines are the ones making the decisions and machines don‚Äôt need to understand what they‚Äôre working with. They have the data and if you set up the algorithm properly, they can just kind of run with it. Also, machines and algorithms can create complex models much more complex than a human can easily understand and implement them directly and immediately. And so if you‚Äôve done your analysis in such a way there is going to be finished working with by an algorithm, then you don‚Äôt need to worry too much about how interpretable it is, because the machines not spending time on that. On the other hand, if you have done your work for the benefit of humans, humans need to understand the principles involved. They need to know why things are happening the way that they are. So, they can then take that information, they can reason from the data, to apply it to new situations. It‚Äôs the principles that are going to be important and so you‚Äôre going to have to be able to explain that to them as a result of your work in Data Science. Now, the trick is, some results are easy to interpret. Here‚Äôs a decision tree I showed you earlier. It‚Äôs about classifying flowers as one of the three different species. You only have to make three decisions. It says, first look at the pedal length and if it‚Äôs long, then look at the pedal width and if that is short, then look at the pedal length again and if you do that, you can make a very good classification. This is a very simple system and human accessible, anybody can work with this. On the other hand, some other results are very difficult to interpret. This is another decision tree that I showed you earlier. It‚Äôs enormously complicated by regular human standards, you‚Äôd have kind of a hard time following through with this. And algorithms that are made in Data Science, like with Deep Learning, are infinitely more complex than this. And so you‚Äôre going to have a hard time explaining to somebody else, how this works and why it set up the way it is and what they can do with it. The point of all this, is it in your analysis, interpretability is critical. You‚Äôre telling a story and you need to be able to make sense of your findings, so you can make reasonable and justifiable recommendations. Tell a story that makes sense, is clear and compelling. Only then, can you see the value from your Data Science project.&lt;/p&gt;

&lt;h2 id=&quot;2-actionable-insights&quot;&gt;2. Actionable insights&lt;/h2&gt;

&lt;p&gt;If you‚Äôre working in a startup or really any entrepreneurial or organizational setting then you know that your work is all about getting results and that brings up something that I mentioned earlier in this course I want to mention again from one of my heroes, the American psychologist and philosopher William James who said ‚Äúmy thinking is first and last ‚Äúand always for the sake of my doing.‚Äù His point is that human cognition is designed to fulfill goals, to help us reach particular ends and I like to summarize that and apply it towards data science with this thought that data and data science is for doing. It exists to help us do things and the reason we do these projects is to help us accomplish things that are important to us. Remember, when you did the project, there was a goal, there was some motivation. What motivated the project? What sorts of things did you stick up on the wall? These are questions you wanted answered. Why was the project conducted? The goal is usually to direct some kind of particular action. Should we open a new store over here? Should we reduce the price over here? Should we partner up with this other organization over here and your analysis should be able to guide those actions and so can you remember what those clear questions were and can you give a clear well articulated and justifiable response to those questions based on your data science project? When you do, there‚Äôs a few things you want to keep in mind. You need to focus on things that are controllable. The analysis might say that companies founded in the 80s have greater success but if you‚Äôre founded in 2015, there‚Äôs not much you can do about it. So focus on something that is under your control and try to make it something that‚Äôs specific. Also, be practical. Think about the return on investment or ROI. You need to work on things and give actions where the impact will be large enough to justify the efforts. Also, if you‚Äôre giving recommendations to a client, make sure it‚Äôs something that they are actually capable of doing and then also you want to build up. You want to have sequential steps. You want to make a small recommendation, carry through on it and then build on it as you see the results of each earlier step. The data science project is designed to fulfill all of these requirements in a way that the benefits will be visible to the client as you help them find an answer to their question and if you can get that done then you‚Äôve done exactly what you meant to do when you started in data science and that is worthy of an office celebration so congratulations.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;Consider learning new things, like, for instance, how to program in Python or R, or how to work with open data, or how to build algorithms for machine learning and artificial intelligence. Any of these would be fantastically useful tools and approaches in data science. Also, learn how to apply the things that you‚Äôve worked with. Get some courses on data-driven decision making in business settings, get more information on business strategy and how the information you use can help any organization make better decisions in their own operations. And then get information on how people work, and the elements that are most important in fields like marketing or nonprofits or healthcare or education, or whatever is of greatest use and interest to you.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="technology" /><category term="data_science" /><category term="learning_archive" /><summary type="html">1. Interpretability</summary></entry><entry><title type="html">Analyses for Data Science</title><link href="/notebook/analyses-for-ds" rel="alternate" type="text/html" title="Analyses for Data Science" /><published>2021-01-01T00:00:08+07:00</published><updated>2021-01-01T00:00:08+07:00</updated><id>/notebook/analyses-for-ds</id><content type="html" xml:base="/notebook/analyses-for-ds">&lt;h2 id=&quot;1-descriptive-analyses&quot;&gt;1. Descriptive analyses&lt;/h2&gt;

&lt;p&gt;When it comes to business decisions, humans and machines approach things very differently. One element of this is that machines have essentially perfect memory. You can give it to ‚Äòem once and they‚Äôll probably give it back to you exactly the same way later. They are also able to see all of the data at once in detail at a way that humans can‚Äôt. On the other hand, they‚Äôre not very good at spotting general patterns in data. There‚Äôs some ways around that but it‚Äôs not one of the strong points of algorithms. Human decision-makers, on the other hand, are very good at finding patterns and connecting the data to outside situations. On the other hand, humans have limited cognitive bandwidth. We can only think of so many things at a time. One of the consequences of that is that we need to simplify the data. We need to narrow it down to a manageable level and try to find the signal in the noise. And so descriptive analyses are one way of doing this. It‚Äôs a little like cleaning up the mess in your data to find clarity in the meaning of what you have. And I like to think that there are three very general steps to descriptive statistics. Number one, visualize your data, make a graph and look at it. Number two, compute univariate descriptive statistics. There‚Äôs things like the mean. It‚Äôs an easy way of looking at one variable at a time. And then go on to measures of association, or the connection between the variables in your data. But before I move on, I do want to remind you of my goal in this course. I‚Äôm not trying to teach you all of the details of every procedure. Rather, I‚Äôm trying to give you a map, an overview of what‚Äôs involved in data science. We have excellent resources here at LinkedIn Learning and when you find something that looks like it‚Äôs going to be useful for you, I encourage you to go find some of the other resources that can give you the step-by-step detail you need. Right now, we‚Äôre trying to get a feel for what is possible and what sorts of things you can integrate. And so, with that in mind, let‚Äôs go back to the first step of descriptive analyses. And that‚Äôs to start by looking at your data. We‚Äôre visual animals and visual information is very dense in data. So you might try doing something as simple as a histogram. So this shows the distribution of scores in a quantitative variable. That‚Äôs also sometimes called a continuous variable. The bell curve, which is high in the middle, tapers off nicely into each side, doesn‚Äôt have any big outliers, is our common occurrence and it forms the basis of a lot of methods for analyzing data. On the other hand, if you‚Äôre working with something like financial data, you‚Äôre going to have a lot of positively-skewed distributions. Most of the numbers are at the low end and a very small number go very, very high up. Think of the valuations at companies, the cost of houses. That requires a different approach. But it‚Äôs easy to see it by looking what you have. Or maybe you have negative skew, where most of the people are at the high end and the trailing ones are at the low end. If you think of something like birth weight, that‚Äôs an example of this. Or maybe you have a U-shaped distribution where most of the people are either all the way at the right, all the way at the left, and although it‚Äôs possible for people to be in the middle there aren‚Äôt many. That‚Äôs a little bit like a polarizing movie and the reviews that it gets. But once you get some visualizations, you can look for one number that might be able to represent the entire collection. That‚Äôs a univariate descriptive. The most common of these is going to be the mode. If each box here represents one data point the mode is simply the most common. And that‚Äôs going to be right here on the left at one because there are more ones than there are of any other score. Or maybe you want the median, the score that splits the distribution into two equal-sized halves. We have six scores down here, we have six scores right here. So the median is 3.5. That splits the data set into two equal halves. Or you have the mean. This one actually has a formula, which means the sum of X divided by N. It also has a geometric expression. The mean is actually the balance point. If you put these as actual boxes on a seesaw the mean is where it‚Äôs going to balance. And in this case, it‚Äôs exactly at four. It‚Äôs going to rest flat at that point. And so these are very common procedures. I imagine you know them already but think of them as a good place to start when you‚Äôre looking at your data. And if you can choose a second number to describe your data, you should consider a measure of variability, which tells you how different the scores are from each other. So that can include things like the range, which is simply the distance between the highest and lowest score, the quartiles or IQR, which split the data up into 25% groups, the variance and the standard deviation, two very closely-related measures that are used in a lot of statistics, and you will also want to look at associations. And so for instance, this is a scatterplot that shows the association between the psychological characteristic of openness and agreeableness at a state-by-state level. You can look at some measures that give you a numerical description of association like the correlation coefficient or regression analysis, like I just barely showed you, or depending on your data, maybe an odds ratio or a risk ratio. But remember there‚Äôs a few things. The data that you‚Äôre analyzing must be representative of the larger group you‚Äôre trying to understand. And things like the level of measurement. Is it nominal, ordinal, interval, or ratio is going to have an impact on what measures you use and the kinds of inferences you can make. You always need to be attentive to the effect of outliers. You have one score that‚Äôs very different from all the others ‚Äòcause that‚Äôs going to throw off a lot of these measures. Also open-ended scores where you have like one, two, three, four, five, plus or undefined scores where somebody started something but didn‚Äôt finish can also have a dramatic effect on the data. So you want to screen your data for these things. Now, I can‚Äôt go into the detail of all of these things right here but we do have other courses here that can do that for you, such as Data Fluency, Exploring and Describing Data. Go there, go to the other courses available that give you an introduction to these basic concepts of understanding what‚Äôs going on in your data and describing the patterns that you can find so you can get started on the further exploration of your data science analyses.&lt;/p&gt;

&lt;h2 id=&quot;2-predictive-models&quot;&gt;2. Predictive models&lt;/h2&gt;

&lt;p&gt;Marriage is a beautiful thing where people come together and set out on a new path full of hope and possibilities. Then again, it‚Äôs been suggested that half of the marriages in the U.S. end up in divorce, which is a huge challenge for everyone involved. But 50 percent‚Äôs just a flip of a coin. If you were trying to predict whether a particular marriage would last or whether it would end in divorce, you could just predict that everybody would stay married or maybe everybody would get divorced and you‚Äôd be right 50% of the time without even trying. In a lot of fields, being right 50% of the time would be an astounding success. For example, maybe only 5% of companies that receive venture capital funding end up performing as projected and there‚Äôs billions of dollars at stake. If you could be right 50% of the time in your venture capital investments, you‚Äôd be on fire. And that brings up the obvious question: How can you tell which companies will succeed and which will fail? Not surprisingly, many methods have been proposed. Apparently, being too wordy in your emails is a sign of eminent business failure, but I think that‚Äôs anecdotal data and not a proper data science predictive analysis. But here‚Äôs the general approach for trying to use data to predict what‚Äôs going to happen. Find and use relevant past data. It doesn‚Äôt have to be really old. It can be data from yesterday. But you always have to use data in the past because that‚Äôs the only data you can get. And then you model the outcome using any of many possible choices. And then you take that model and you apply it to new data to see what‚Äôs going on in there. There‚Äôs actually a fourth critical step and it‚Äôs separate from applying, and that‚Äôs to validate your model by testing it against new data, often against data that‚Äôs been set aside for this very purpose. This is the step that‚Äôs often neglected in a lot of scientific research, but it‚Äôs nearly universal in predictive analytics and it‚Äôs a critical part of making sure that your model works well outside of the constraints of the data that you had available. Now there‚Äôs a number of areas where predictive analytics as a field has been especially useful. Things like predicting whether a particular person will develop an illness or whether they‚Äôll recover from an illness; whether a particular person is likely to pay off a mortgage or a loan, or whether an investment will pay off for you; and then even the more mundane things like building a recommendation engine to suggest other things that people can buy when they‚Äôre shopping online. All of these are hugely influential areas and major consumers of predictive analytics methods. Now, I do want to mention there are two different meanings of the word prediction when we talk about predictive analytics. One of them is trying to predict future events, and that‚Äôs using presently available data to predict something that will happen later in the future, or use past medical records to predict future health. And again, this is what we think of when we hear the word prediction. We think about trying to look into the future. On the other hand, it‚Äôs not even necessarily the most common use of that word in predictive analytics. The other possibly more common use is using prediction to refer to alternative events, that is, approximating how a human would perform the same task. So you‚Äôre going to have a machine do something like classifying photos and you want to see whether this is a person, whether this is a dog, whether this is a house, and you‚Äôre not trying to look into the future, but you‚Äôre trying to say if a person were to do this, what would they do, and we‚Äôre trying to accurately estimate what would happen in that case. And so, you also might try inferring what additional information might reveal. So we know 20 pieces of information about this medical case; well, from that, we might infer that they have this particular disease, but we wouldn‚Äôt know for sure until we do a direct test, so we‚Äôre trying to estimate what‚Äôs happening there. Now, when you go about your analysis, there‚Äôs a few general categories of methods for doing a predictive analytics project. Number one is classification methods. That includes things like k nearest neighbors and nearest centroid classification and also is connected to clustering methods such as k means. You can also use decision trees and random forests, which is several decision trees put together, as a way of tracking the most influential data in determining where a particular case is going to end up. And then also extremely powerful in data science are neural networks, a form of machine learning that has proven to be immensely adaptive and powerful, although very hard sometimes to follow exactly what‚Äôs going on in there. But all of these methods have been very useful within trying to predict what‚Äôs going to happen with a particular case. But I do want to mention one other approach that‚Äôs been enormously useful and dates back a lot further than a lot of these, and that‚Äôs regression analysis, which gives you an understandable equation to predict a single outcome based on multiple predictor variables. And it can be a very simple thing, like this is an equation that uses the amount of time a person spends on your website to predict their purchase volume. Now this is fictional data, but you get to see we have a scatter plot, we draw a regression line through it, and we even have an equation there at the top of the chart. And this is a regression equation written entirely symbolically. I showed this to you before. It‚Äôs where you‚Äôre trying to predict an outcome of y for individual i and you‚Äôre using several predictors, X1, X2, X3, and their regression coefficients to predict their score. So for instance, the example I used was predicting salary, and you can write it out this way, too, where the salary for individual i is going to be $50,000, that‚Äôs the intercept, plus $2,000 for each year of experience, plus $5,000 in each step of their negotiating ability on a one-to-five scale, plus $30,000 if they‚Äôre the founder or owner of the company. And so that‚Äôs a regression equation, and it‚Äôd be very useful for predicting something like salary. And it‚Äôs a very easy, conceptually easy way to analyze the data and make sense of the results. And there are a few nice things about regression models. Number one is they‚Äôre very flexible in the kind of data they can work with. Different versions of regression can work with predictors or outcomes that are quantitative or continuous, ordinal, dichotomous or polychotomous categorical variables. They also can create flexible models. They‚Äôre usually linear. They can also be curvilinear, they can be quantile based, they can be multi-leveled. You have a lot of choices. And generally, they‚Äôre easy to interpret, that‚Äôs compared to many other data science procedures. The results of regression analysis are easy to read, interpret, present, and even to put into action. But this is simply one choice among many for predictive analytics where you‚Äôre trying to use your data to estimate what‚Äôs going to happen in the future. We have a lot of resources here where you can find other courses that will give you specific instruction on predictive analytics methods and help you find the actionable next steps in your data.&lt;/p&gt;

&lt;h2 id=&quot;3-trend-analysis&quot;&gt;3. Trend analysis&lt;/h2&gt;

&lt;p&gt;When you go out hiking in a new place, it‚Äôs nice to have a path to help you get where you‚Äôre going. It‚Äôs also nice to know that the path might actually take you to some place you want to be, so how can you see where you‚Äôre going, and how long it‚Äôs going to take you to get there? Well, as a data scientist, your job is to figure out the path your data is on, so you can inform decisions about whether to stay on the current path, or whether changes need to be made. The most basic way to do this is with trend analysis, and it starts by plotting a line. Simply make a graph of the changes over time, and then connect the points to make a clear line of one kind or another. Now, when you‚Äôre doing the analysis, you have to be worried about something a little different from other analyses we may have looked at, and that‚Äôs something called autocorrelation, or self-correlation. The idea here is that every value is influenced by the previous values, more or less. So today‚Äôs value, say, for instance, on number of visitors to your site, is going to be associated with yesterday‚Äôs value, which is going to be associated with the day before, and what you‚Äôre looking for is consistency of change, and there are several different ways to think about the change that happens over time. In fact, what you‚Äôre trying to do is to find the function, so you‚Äôre trying to get the outcome variable, like number of visitors to a site, as a function of time and the previous value. So you‚Äôre trying to find the function, like a mathematical function, for that particular line, and it actually may be cyclical. It may go up and down over time, or it may be several functions combined all at once. Let me show you some of the most basic ones, and I‚Äôm just showing you the line, not the data that would determine the line. There would be points all around it, and maybe you have something that has perfect linear growth, where you add the exact same quantity at each time period, like dollars per hour, or per year for an employee. So maybe you‚Äôll have $100 for a certain amount of time, and if you work twice as much you get 200, and so on, but it always goes up the same amount, so it‚Äôs linear growth. It‚Äôs easy to work with. On the other hand, in a lot of situations, you actually have what‚Äôs called exponential growth, where the rate of acceleration, think about when you‚Äôre squaring something, this is x squared, or you grow by 2% at every time period, or maybe 10% per year, then the curve is going to look like this. It‚Äôs what you expect when you‚Äôre adding the same percentage at each time. Or maybe you have logarithmic growth, where it starts off rapidly, but it approaches a ceiling value, like operating at 100% capacity, if the initial growth is fast, and you can‚Äôt go past that, so it diminishes, the rate of change diminishes, even if you‚Äôre still going up over time. Sometimes you can have something slightly more complicated like a sigmoid, or a logistic function, where it starts slowly and then it accelerates rapidly, and then tapers off as limits are reached. Again, like reaching market saturation once your ad campaign has been massively successful. And then you may have a sinusoidal, or a cyclic sine wave, where things go up and down over time. Sometimes you have patterns that go over time. For instance, a lot of my work appeals to people who are in school, and so I see ups and downs that correspond with the fall and the spring semester, and with winter and summer breaks, and I get a pattern, approximately like this. Now, there are a few advanced options for trend analysis, like a change point analysis, where you‚Äôre looking for a substantial, perhaps qualitative change over time, like a flock that‚Äôs moving together, then perching, moving again, and so on, and you‚Äôre trying to look at those transitions. So change points are the changes in the resting state of the data. There may be fluctuations still going around it, and you will probably want to check for historical events that can explain those changes, things you know are going on in the environment. So for instance, here‚Äôs an example that I‚Äôve used before, and it shows the number of inventions registered from 1860 up through 1960. And a change point analysis, which I conducted using the programming language R, shows that there are these relatively stable periods, with some fluctuation around it, but you can see that it jumps up dramatically around the early 1880s, and then settles down for a long period of time, and then drops down again. These are the sorts of qualitative changes that you‚Äôll want to be able to explain as result of your analysis. You can also try breaking things down from the whole into their elements, to try to see what‚Äôs happening with your data over time. This is decomposition. Think of it like disassembling a clock or some other item. You‚Äôre going to take the trend over time and break it down into several separate elements. You‚Äôre going to look at the overall trend, you‚Äôre going to look at seasonal or a cyclical trend, and you‚Äôre going to have some leftover random noise that you haven‚Äôt modeled yet. So here‚Äôs a graph showing some stock prices over a period of time, from 1990 up to about 2017. And what we can find here, is if we do the decomposition analysis, which again, I did in R, this is the original trend. It‚Äôs a compressed version of what I just showed you, but when we decompose it into several elements, we get this smooth trend, and this is removing a lot of the day to day fluctuation. You can see it‚Äôs basically uphill. Then we have the seasonal variation. I set it for a one year repetition, and you see it going up and down over time. And then this is the left over random noise. But this is one way of looking at changes over time, and trying to get some of the meaning out of it by using one kind of analysis or another. All of these start by simply plotting the dots and connecting the line over time, and then there are different ways to explore what the meaning of that might be. And depending on the situation, the field that you‚Äôre working in, or exactly what you‚Äôre trying to get out of it, you‚Äôll use one approach or another, but any of these will be an excellent way of getting started on finding out what path you‚Äôre on, and what you can expect in the near future.&lt;/p&gt;

&lt;h2 id=&quot;4-clustering&quot;&gt;4. Clustering&lt;/h2&gt;

&lt;p&gt;Everybody in a crowd is their own person. Each person is a unique individual, and perhaps, in an ideal world, your organization would acknowledge that and interact with each person in a tailored and unique way. But for right now, we face a lot of limitations, and there are plenty of times when it‚Äôs helpful to create groups or clusters of people that might be similar in important ways. These can include marketing segments, where you might give the same ads or the same offers to a group of people. Or developing curricula for exceptional students, like gifted and talented or artistic students, or maybe developing treatments for similar medical groups. Now, when you look at clusters in the United States, it‚Äôs easy to start with each state represented separately, but it‚Äôs really common practice to group these states into, say, four large regions of geographically adjacent states, like the South, the West, the North East and the Midwest. And that makes a lot of sense if you‚Äôre actually having to travel around from one to another, but you don‚Äôt have to group by just what‚Äôs physically next to each other. For example, a soccer team has matching jerseys, and they coordinate their movement, ‚Äòcause they‚Äôre a team. These could serve as the basis of maybe a behavioral cluster as opposed to a geographic one. And you can use a lot of different measures for assessing similarity, not just physical location. You can look at things like a K-dimensional space. So you locate each data point, each observation, in a multidimensional space with K-dimensions for K variables. So if you have five dimensions, K is five. If you have 500, then you have 500 dimensions. What you need to do then, is you need to find a way to measure the distance between each point, and you‚Äôre going to do one point, every other point, and you‚Äôre looking for clumps and gaps. You can measure distance in a lot of ways. You can use Euclidean distance, that‚Äôs the standard straight line between points in a multidimensional space. You can use things like Manhattan distance, and Jaccard distance, cosine distance, edit distance, there‚Äôs a lot of choices in how you measure the distance, or the similarity, between points in your data set. Let me give you an example, though, of cluster analysis in real life. So for instance, one of my favorite studies is based on what‚Äôs called the Big 5. I have a background in social and personality psychology. The Big 5 is a group of five very common personality factors that show up in a lot of different places under a lot of different situations. The actual factors are extraversion versus introversion, agreeableness, conscientiousness, neuroticism, which means your emotions change, and as opposed to stability, and then openness, specifically openness to new experiences. Once study I know actually tried to group the states in the U.S. using these Big 5 personality factors. They got information from social media posts, and then evaluated each state and created a profile. And from that, they found that the states in the U.S. went into three very broad groups. The big group there in orange down the middle, they called the friendly and conventional. The yellow off to the west coast, and actually a little bit off on the east coast, they called relaxed and creative, and then in green, which is mostly the north east, but also Texas, is temperamental and uninhibited, and these are different ways of thinking about the kinds of things that people think about and the way that they behave. Now, you could use psychological characteristics, or maybe you could group states by, for instance, how they search for things online, which might be more relevant if you‚Äôre doing e-commerce. So, I went to Google Correlate, and I chose a dozen search terms that I thought might roughly correspond to the Big 5 personality factors, and what that data tells you is the relative popularity of each search term on a state-by-state basis. I then did an analysis in R, doing what‚Äôs called a hierarchical cluster, where all of the states start together, and then it splits them apart one step at a time. And you can see, for instance, that my state of Utah is kind of unusual by itself over here, but you can see the degree of connection between each of the states, until finally all of the 48, it doesn‚Äôt include Alaska or Hawaii, because the original researchers didn‚Äôt have that in their personality data, but I could say, ‚ÄúGive me two groups,‚Äù and then it groups them this way. You can see we have just these five states over here listed on the right, or we could say, ‚ÄúGive us three groups,‚Äù in which case all it does is it separates Utah from those other five. But you can go down to a level that seems to work well, something that makes sense and that works with your organization‚Äôs needs. Now, I want you to know that when you‚Äôre doing a cluster analysis, you could do a hierarchical clustering, which I just did, that‚Äôs a very common approach, but there‚Äôs a lot of alternatives. You can do something called K-means, or a group centroid model. You can use density models or distribution models, or a linkage clustering model. Again, we have other resources here that will show you the details on each of these and how to carry them out. Mostly I want you to be aware that these alternatives exist, and they can be useful in different situations for putting your data together. Remember, with any analysis, something like clustering exists to help you decide how you want to do things. So use your own experience, and use common sense as you interpret and implement the results of your analysis, and you will get more value and more direction out of that for your own organization.&lt;/p&gt;

&lt;h2 id=&quot;5-classifying&quot;&gt;5. Classifying&lt;/h2&gt;

&lt;p&gt;So maybe you‚Äôve got a dog and maybe your dog does cute things like sticking its nose in your camera. Now, my dog‚Äôs too short for that, but you take a picture or a video to save the moment. But one interesting consequence of that process is that now your phone‚Äôs photo program is going to start analyzing the photo to determine what it‚Äôs a photo of. That way, you can search for it later by typing dog without ever having had to tell the program that‚Äôs what it is. And that‚Äôs the result of a machine learning algorithm taking the data to analyze the photos and classify it as a dog, a cat, a child, and add those labels to the data. In fact, classifying is one of the most important tasks that data science algorithms perform, and they do it on all kinds of data. The general idea of automated classification is pretty simple to describe. Locate the case in a k-dimensional space where k is the number of variables or different kinds of information that you have. And there‚Äôs probably going to be more than three. It might be hundreds or thousands. But once you get it located in that space, compare the labels on nearby data, that of course assuming that other data already has labels that it says whether it‚Äôs a photo of a cat, or a dog, or a building. And then once you‚Äôve done that, assign the new case to the same category as the nearby data. So in principle it‚Äôs a pretty simple process. Now in terms of what data you‚Äôre going to assign it to, you can do that using one of two different methods among other choices. A very common one is called k-means, and this is where you choose the number of categories that you want. You can actually say I only want two, or I want five, or I want 100. And then what the algorithm does is it creates centroids. That‚Äôs like a mean in multi-dimensional space, and it will create as many centroids as you want groups. And so when you put your new data in, it will assign that new case to the closest of those k centroids. Again, might be two, might be five, might be 100. Another approach is called k-nearest neighbors, and what it does in this case is it finds where your data is in the multi-dimensional space, it looks at the closest cases next to it, and you can pick how many you want. It might be the five closes, the 20 closest, the 100 closest. And look at the categories of those cases and assign your new data to the most common category among them. Now as you might guess, classification is a huge topic in data science, machine learning, and artificial intelligence, and so there are many, many options on how to do this process, and you‚Äôre going to have to spend a little time talking with your team to decide which approach is going to best meet your individual goals. Now some of the things you‚Äôre going to have to consider are things like whether you want to make a binary classification, that‚Äôs just a yes, no, like whether a credit card transaction is or is not fraudulent, or whether you have many possible categories like what‚Äôs in a photo or what kind of movie to recommend to someone. You also have a lot of choices for how you measure the distance, how close is it to something else. You can use euclidean distance, Manhattan distance, edit distance, and so on. And you also need to decide whether you‚Äôre going to compare it to one central point like a centroid or several nearby points. And then you also need to make a decision about confidence level, especially when you have a significant classification, how certain do you have to be that that‚Äôs the right one. Some cases fit beautifully, others are much harder to classify. Now, once you‚Äôve done the classification, you want to evaluate your performance, and there‚Äôs a few different ways to do that. You can look at the total accuracy. So if you have like a binary classification, is a legitimate transaction, is a fraudulent transaction, what percentage of the total cases got put into the right category. This is simple to calculate and it‚Äôs intuitive to understand, but it‚Äôs problematic because if one category is much more common than the others, then you can get high overall accuracy without even having a functional model. So you want to start looking at things a little more particularly like for instance sensitivity. This is the true positive rate or if a person‚Äôs supposed to be in a particular category, what‚Äôs the likelihood that that will actually happen. So if a person has a disease, what‚Äôs the probability they will be correctly diagnosed with that disease? And there‚Äôs also specificity, which is like the true negative rate, and what this means is that the case should only be categorized when it is supposed to go in there. You don‚Äôt want these other cases accidentally going in. And that‚Äôs one of the purposes of Bayes‚Äô Theorem, which I‚Äôve talked about elsewhere. Bayes‚Äô Theorem allows you to combine data about sensitivity, specificity, and the base rates, how common the thing is overall. And again, my goal here is not to show you the step-by-step details, but to give you an overall map. For more information on classification methods, we have a wide variety of courses uses languages like Python and R that can walk you through the entire process. But the goal is the same, using automated methods to help you identify what you have and by placing it into relevant categories, helping you get more context and more value out of the data so you can provide better products and services.&lt;/p&gt;

&lt;h2 id=&quot;6-anomaly-detection&quot;&gt;6. Anomaly detection&lt;/h2&gt;

&lt;p&gt;Some time ago, I opened up Launchpad on my Mac, which is a way of launching applications, and it‚Äôs supposed to look like this. However, this particular time, something weird happened, and this is what I saw instead. Now, normally, when you get an anomaly like this, you just restart the app or reboot the computer, but it turns out I‚Äôm fascinated by generative art or art that comes through as the result of an algorithm, often with a fair amount of randomness thrown in. So before I restarted things and got it back to normal, I took a screenshot, and I‚Äôve gone back to it several times. I consider this an excellent example of found generative art, really, a happy digital glitch or a fortuitous anomaly. It‚Äôs also an example of serendipity or the unexpected insight that can come along. Well-known examples of serendipity include Silly Putty, Velcro, Popsicles, and of course, the Post-It Notes that every office has. You can think about these as trying to find anomalies, unusual things, and latching onto them. Now, usually when we talk about anomalies, we talk about things like fraud detection. Is a particular transaction legitimate or fraudulent? You can also use it to detect imminent process failure like a machine‚Äôs going to break or an employee has a heightened risk of burnout or leaving the company, but you can also think of this as a way of identifying cases with potentially untapped value, a new category, a new audience that you can work with. Now, what all of these have in common are the focus on outliers. These are cases that are distant from the others in a multidimensional space. They also can be cases that don‚Äôt follow an expected pattern or a trend over time, or in the case of fraud, they may be cases that match known anomalies or other fraudulent cases. Any of these can be ways of identifying these anomalies and responding appropriately to them, and when you do that, it brings up the usual suspects, the usual method for analyzing data in data science, things like regression. Does this particular observation fit well with the prediction, or is there a large error? You can do Bayesian analysis to get a posterior probability that this is a fraudulent transaction. You can do hierarchical clustering or even do neural networks as a way of finding how well the data fits these known patterns, and if it doesn‚Äôt, you may have an anomaly. Now, there are a couple of things that make this a little harder than it might be otherwise. Number one is that we are dealing with rare events. By definition, if it‚Äôs an anomaly, it‚Äôs not common. So things like fraud are uncommon, and that leads to what are called unbalanced models. When you‚Äôre trying to predict something that happens only 1% or 1/10 of a percent of the time, you got to have a huge amount of data, and you have to have a model that can deal well with that kind of categorical imbalance. The second thing is difficult data. You may not be dealing just with a nice SQL database. You may have biometrics data. You may have multimedia data. You may have things like time-sensitive signatures where you have to measure how it happened over an event. So as an example of all of this, think about when you‚Äôve used your credit card to make a purchase online. You, the online store, and your credit card company all have a vested interest in making sure the transaction is legitimate because fraud costs money, it takes times, and it causes headaches. So your credit card company could take several steps to identify legitimate cases and potential anomalies. They might look at something like the purchase characteristics. What was purchased? For how much? When and where? Through what means, and so on. I got a call a few years ago from my credit card company when someone tried to spend several thousand dollars on a hotel several thousand miles from my home. You can also use personal measures, things like biometrics or latency and typing, or you can measure a person‚Äôs height approximately by the angle at which they hold their cell phone, the mode of transportation they‚Äôre on by getting the vibrations through the accelerometer, or an interesting one is a signature of their name or a person trying to find the cursor on their computer is, in fact, a signature that can be measured and stored, and new data can be compared against that, and then, there are general trends. Are there new scams going around? Are they more common in one area or another? Have scammers found ways around old technology and so on. Needless to say, fraud detection‚Äôs a cat-and-mouse game, so there‚Äôs constant research and progress in data science to deal with new methods of fraud and harnessing the evolving capabilities of machines and algorithms, and that means that you‚Äôll want to stay in touch with the resources available here to learn the specific details about the latest and greatest methods in data science for things like fraud detection and any kind of anomaly detection, including the potential for new discoveries via serendipity.&lt;/p&gt;

&lt;h2 id=&quot;7-dimensionality-reduction&quot;&gt;7. Dimensionality reduction&lt;/h2&gt;

&lt;p&gt;Back in 1957 in his legendary song, Rock ‚Äòn Roll Music, Chuck Berry sang a lament about musicians who make things too complicated and to quote, ‚Äúchange the beauty of the melody ‚Äúuntil it sounds just like a symphony.‚Äù And that‚Äôs why he loves rock ‚Äòn roll music. The same idea explains why most bands have four people like the Beatles right here or possibly three or five. That‚Äôs enough people, enough instruments to fill all the sonic regions without overwhelming with too much information and resulting in cacophony. Jumping way ahead in time, there‚Äôs a similar problem in data science. We think of data coming down in a matrix-like stream here as really cool, but it‚Äôs hard to get meaning out of it and it‚Äôs hard to know what to do as a result of it. We need a way to get through the confusion and the haze and pull things into focus. Fortunately, there‚Äôs a way to do that in data science. The idea of dimension reduction is to actually reduce the number of variables and the amount of data that you‚Äôre dealing with. So instead of dealing with dozens or hundreds or maybe even thousands of variables, you‚Äôre dealing with a single score like how likely a person is to behave in a particular way. It sounds counterintuitive, but there are actually some very good reasons for doing this. First off, each variable, each factor or feature has error associated with it. It doesn‚Äôt measure exactly what you want. It brings in some other stuff. But when you have many variables or features together that you combine, the errors tend to cancel out. So if they‚Äôre all pointing in slightly different directions, you end up centered on what it is you want. Also, by going from many individual measurements to a single conglomerate measurement, that reduces the effect of something called colinearity, which is the association, the overlap between predictor variables in the model, which creates some significant problems. So if you have fewer variables, there‚Äôs less problems for colinearity. Also, not surprisingly when you have a few features you‚Äôre dealing with instead of hundreds, you are able to do things faster. Your computer is able to process the information with greater speed. And another really nice consequence of this is it improves generalizability. Again, because you‚Äôre getting rid of or averaging out the idiosyncratic variation with each observation, with each variable, and you‚Äôre going to get something much more stable that you‚Äôre able to apply to new situations better. Now, there are two general ways to do this. There are a lot more options, but the two most common are these. Number one is principal component analysis, often just called principal components or PCA. And the idea here is that you take your multiple correlated variables and you combine them into a single component score. So let‚Äôs say you give a personality questionnaire and it‚Äôs got 50 questions on it, but you have 10 questions for each element of personality, then you can combine those into 10 components if the analysis supports that combination. And then you only have five things to deal with as opposed to 50 and it‚Äôs much easier to deal with. Another very common approach is factor analysis. And functionally, it works exactly the same way. People use it for the same thing, although the philosophy behind factor analysis is very different. Here your goal is to find the underlying common factor that gives rise to multiple indicators. So in principal component analysis, the variables come first and the component results from it. In factor analysis, this hidden factor comes first and gives rise to the individual variables. That said, even though they are conceptually very different that way, people tend to use the two often interchangeably. What they let you do is group variables in ways that make sense. Now, there are a lot of variations on methods for dimension reduction. You, for instance, might be engaged in an exploratory analysis where you‚Äôre just trying to find out what‚Äôs there in the data in front of you or a confirmatory analysis where you have a known structure and you‚Äôre trying to see how well your current data fit. You have different methods for different levels of measurement. If you have a quantitative thing where you‚Äôre looking at how it takes somebody to do something or the value of their purchases, that‚Äôs one approach. But if you‚Äôre counting yes or no are they in this particular category, you‚Äôre going to need to do something else. Also, there are multiple algorithms, many different ways of measuring the similarity between variables and measuring ways of overlap and the degree that they share. And so there are some very important details in these, but we can save that for a more detailed analysis in another video. Right now I want you to know that the procedure exists. Right now I want you to know that there‚Äôs the possibility of doing this and that it‚Äôs worth looking into. I mean, think about it. Dimension reduction in data is like learning to read a language. At first you just see random shapes. Then you see individual characters, then words, then sentences, and then finally ideas. You can go from 100 pieces of information, a line here or a circle there to just a handful and that‚Äôs what you need to get meaning out of your data and to do something useful with it.&lt;/p&gt;

&lt;h2 id=&quot;8-feature-selection-and-creation&quot;&gt;8. Feature selection and creation&lt;/h2&gt;

&lt;p&gt;I teach statistics to undergraduate students who don‚Äôt always see how it connects to their lives. I can give specific examples about each of the fields, but I found that even the most recalcitrant student can get excited about data when we talk about sports like baseball. Baseball‚Äôs a data-friendly sport. It‚Äôs been going on for over 100 years, there are 162 games in the regular season, and they count everything. If you‚Äôre trying to figure out how good, for example, a particular batter is, you can start with these basic bits of data and you‚Äôll have an enormous amount of information to work with. These are the features in the dataset that you start with. But if you‚Äôre a coach or a manager, you can do a lot more than just use those raw data points to make a strategy. You can start combining them to create new features in your dataset and finding value and possibilities in your team. Now you can start with really simple ones. This is the batting average, and all it is is the number of hits divided by the number of at bats, and you need to know that those are defined in particular ways, but it‚Äôs just one number divided by the other. Or you can get something more sophisticated like the on-base percentage, where you take three things, the number of hits, the number of bases on balls and hit by pitch and divide that by four things. At bats, bases on balls, hit by a pitch, and sacrificed flies. That gives you a better measure, according to some judgment, or if you want to jump ahead to the 21st century, you can start getting really fancy with something like the weighted runs created plus where you have a whole plethora of things you‚Äôre putting together and what‚Äôs interesting is every one of these is actually its own formula going into it, so that one‚Äôs complicated, but it‚Äôs all based on these little bits and pieces of information that are available. Before I go ahead, I want to mention one thing and that‚Äôs feature selection and creation is a different process than the dimension reduction that I mentioned elsewhere. Dimension reduction‚Äôs often used as a part of getting the data ready so you can then start looking at which features to include in the models you‚Äôre creating and that‚Äôs what we‚Äôre addressing right now. So given that you have these formulas to create all these new features to pick the best players or best outcomes, which one should you actually use when you‚Äôre making that decision? Which ones have the greatest decision value? Well, if you‚Äôve seen the movie Moneyball, which is a dramatized account of how the Oakland A‚Äôs general manager Billy Beane used data to select and assign players, you will remember he keeps directing the scouts towards one primary factor over any other. Whether a player reliably gets on base. He had data to drive that decision and to guide him to that focus, although they didn‚Äôt share that process with us in the movie, but I can tell you basically how it works outside of baseball. There are a few methods that you can use for feature selection and feature creation in your data science projects. So for instance, you can start with just basic correlation. Is this variable correlated with the outcome or is this variable correlated? Which one has a bigger correlation? That works, but it‚Äôs one variable at a time and ‚Äòcause correlation generally looks at linear associations, it has some limits. Or you could do something called stepwise regression where you take all of your potential predictor variables, you put them in the computer, and you say this is the outcome variable and it looks at correlations and picks the best one and then it starts doing what are called partial correlations, and it‚Äôs a really easy way to sift through the data. You know, you just hit go and it‚Äôs done. The problem, however, is that stepwise regression really capitalizes on chance fluctuation in your dataset, and you can set stuff that simply is not going to generalize to anything else, and so stepwise is generally a poor choice, even if it‚Äôs an easy one. On the other hand, more modern methods like lasso regression, that‚Äôs least absolute shrinkage and selection operator, and ridge regression are better ways that are most robust to these flukes of chance variation, and they give a better impression of the variables‚Äô role in the equation and which ones you should emphasize. And if you do something like a neural network, you can do variable importance and there‚Äôs a lot of other different ways of evaluating each one of these, but when you‚Äôre selecting your variables, there‚Äôs a few things you want to keep in mind. Number one, is it something that you can control? Ideally, if you‚Äôre trying to bring about a particular outcome, you can to have the ability to make it happen. So look at variables that are under your control or that you can select, at least, and then look at the ROI, the return on investment. Not everything that can be manipulated or controlled can be controlled easily or inexpensively, and os you need to look at the combined cost and the value or the benefit that you get from working with that particular predictor. And then the third one is is it sensible? Does the model make sense? Does it make sense to include this particular variable in your equation? You‚Äôve got experience. You know your domain. Always keep that in mind as you‚Äôre evaluating the information that you can use in your model to make predictions. That taken together will let you make an informed choice about the best things in your data for predicting and ideally, for bringing about the things that matter to you and to your organization.&lt;/p&gt;

&lt;h2 id=&quot;9-validating-models&quot;&gt;9. Validating models&lt;/h2&gt;

&lt;p&gt;Several years ago, my wife and I adopted our second child. No, this isn‚Äôt her, this is stunt double. We‚Äôve loved and we‚Äôve raised her the best we could but we did make one critical error that has actually caused her unanticipated grief and could take her years to recover from. We used a non-standard character in her name. Those two dots over the E are a diaeresis, which indicates that the second vowel is to be pronounced as its own syllable. And, by the way, that‚Äôs not to be confused with the identical looking, but functionally distinct umlaut which softens the sound of a vowel or indicates that you‚Äôre a heavy metal band. It turns out, there is still a lot of web forms out there that don‚Äôt like non ASCII characters and will tell you that you‚Äôve entered invalid data even if it is the name that your parents gave you. And there are other people whose names have trouble with modern computers, aside from having things like apostrophes or hyphens. So maybe you‚Äôve got a mononym, just a single name. It‚Äôs common among pop singers and it‚Äôs also not unheard of in Indonesia and Yanmar. Or even have as single letter for a name. O happens in Korea, although it‚Äôs often spelled as OH and E occurs occasionally in China. Or, you are Hawaiian and you‚Äôve got a really expansive last name or the most challenging of all are the handful of people whose last name is Null, which wreaks all sorts of havoc with databases and leads to either hilarity or immense frustration trying to get things done online. Now, what‚Äôs happening here, I imagine, is that a well meaning programmer has created a name validation system that checks whether a person has entered an actual name. And they‚Äôve checked how well that worked against a database of names that they had that unfortunately wasn‚Äôt representative of all the possibilities. Remember, the world is a big place, and apparently programmers don‚Äôt name their kids Zoe so problems come up and the system breaks down. What that lets you know is that you should always check your work. That‚Äôs the principle of validating your models in data science. You may have tailored it really nicely to the data that you had, but is it going to work with anything else? Is it going to survive out there? It reminds me of one of the all time great quotes from computer science, beware of bugs in the above code, I have only proved it correct, not tried it. And that‚Äôs from Donald Knuth, an illustrious computer science professor and author of the Multi-volume, The Art of Computer Programming. So, you need to validate your data. You need to make sure that your model works. The basic principle is pretty easy, even if people outside of data science don‚Äôt do it very often. Take your data and split it up into two groups. Training data and testing data. And training data‚Äôs like the data that you send to class and you teach it how to identify the outcome that you‚Äôre looking at and you build a model with that training data. But then you need to check how well you‚Äôve taught it and you go into the testing data, now there‚Äôs two kinds of testing data, one of them doesn‚Äôt really count and that‚Äôs cross-validation. Now you can say it‚Äôs testing data but it‚Äôs actually using the training data. What you do here is you take the training data and you split it up into several pieces, maybe six different groups and then you use five at a time to build a model and then you use the sixth group to test it and then you rotate through a different set of five and you verify them against a different one sixth of the data and so on an so forth. So that‚Äôs internal, but it still allows you to build models that are going to be a little more robust against variations in the data. But the gold standard is holdout testing data, or holdout validation. This is where you take that maybe 20% of data that you set aside way at the beginning and you‚Äôve never looked at it, you‚Äôve never touched it, now you take the model you‚Äôve built from your training data and ideally you have gone through the cross validation process also, you take that model and you apply it just once to the holdout data and that one is going to give you the true measure of the accuracy of your model. Not, when you‚Äôre able to twist it and tweak it however you wanted but testing it against data sort of in the wild and the general idea here is now you have an idea of how robust your model is and how well it can function outside the box. Once you do that, you‚Äôre going to be certain that your work does what you think it should do and you can be confident that your model is ready to go out there into the real world.&lt;/p&gt;

&lt;h2 id=&quot;10-aggregating-models&quot;&gt;10. Aggregating models&lt;/h2&gt;

&lt;p&gt;There‚Äôs a saying that life imitates art. Well, for some time as I‚Äôve been preparing for this presentation I‚Äôve planned to talk about how people estimate the amount of money in a jar full of coins. And then literally today we inherited a giant jar of coins from my mother-in-law and we‚Äôre currently asking extended family members for their guesses as to how much money is in this very heavy jar. I‚Äôve guessed a low-ball estimate of 165. My wife was more optimistic and guessed $642.50. We actually won‚Äôt know the answer until next week when we cash in all the change, but I bring this up because it illustrates an important point. Any one guess, like an arrow shot at a target, maybe high, maybe low, maybe more or less accurate, but as it happens, if you take many guesses and average them, the errors tend to cancel out, and you end up with a composite estimate that‚Äôs generally closer to the true value than any one single guess is. This is sometimes called the wisdom of the crowd, although in statistics it‚Äôs a function of something called the central limit theorem and the way that sampling distributions behave. But the idea is that combining information is nearly always better than individual bits and pieces of information. In data science, the wisdom of the crowd comes in the form of combining the results of several different models looking at the same outcome and the same data set. Or you maybe use models like linear regression, and a lasso regression, and a decision tree, and a neural network, all predicting the same outcomes. And there‚Äôs several different ways that you can combine the estimates from each of your models to create an ensemble estimate. If you‚Äôre modeling a categorical or nominal outcome like trying to decide what‚Äôs in a picture or whether a new contact is likely to make a purchase, each model will give its prediction and then you can take the most common category across the predictions. It‚Äôs like having people raise their hands to vote. Or, if you‚Äôre modeling a quantitative or a continuous outcome like the number of people who will respond to a nonprofit‚Äôs fundraising appeal, you can take the numbers that each model predicts and average them, sort of like mixing ingredients in a bowl. Or maybe you want to try something a little more sophisticated and use Bayesian methods to combine the posterior probabilities that each model gives you into a single aggregated or ensemble probability. Now, these are just simple methods and ways of thinking about it. There‚Äôs a lot of work in the field of ensemble modeling, or models that combine the results of multiple models but this gives you a general idea. Now, let me explain very quickly what the benefits of this are, ‚Äòcause it does take a little extra time and effort. First off you get multiple perspectives on your data and on your outcome. Each method that you use, each algorithm, has its own strengths but it also things that it tends to skip over or get tripped up by. By combining the results you can compensate for some of those weaknesses and capitalize on those combined strengths. You also have a greater ability to find the signal, meaning the true value, the true outcome amid the noise of random variation and measurement error. You tend to get estimates that are both more stable across time and across methods and that are more generalizable to new cases and new situations. All of those are enormous benefits. You can think of it as a kind of cooperation between the models, the ensemble modeling. It‚Äôs the idea that many eyes on the same problem can lead to the best possible solution and that really is why you got involved in data science in the first place.&lt;/p&gt;</content><author><name>Learning Archive</name></author><category term="technology" /><category term="data_science" /><category term="learning_archive" /><summary type="html">1. Descriptive analyses</summary></entry></feed>