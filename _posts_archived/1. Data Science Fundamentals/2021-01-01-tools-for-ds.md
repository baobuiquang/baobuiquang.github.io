---
layout: post
title: "Tools for Data Science"
date: 2021-01-01 00:00:06 +0700
author: "Learning Archive"
tags: technology data_science learning_archive
series: DS101
preview: "When people think about data science, machine learning and artificial intelligence, the talk turns almost immediately to tools. Things like programming languages and sophisticated computer setups, but remember, the tools are simply a means to an end, and even then only a part of it."
---

## 1. Applications for data analysis

When people think about data science, machine learning and artificial intelligence, the talk turns almost immediately to tools. Things like programming languages and sophisticated computer setups, but remember, the tools are simply a means to an end, and even then only a part of it. The most important part of any data science project by far is the question itself, and the creativity that comes in exploring that question, and working to find possible answers using the tools that best match your questions. And sometimes, those tools are simple ones. It's good to remember even in data science that we should start with the simple, and not move on to the complicated until it's necessary. And for that reason, I suggest we start with data science applications. And so, you may wonder, "Why apps?" Well number one, they're more common. They're generally more accessible, more people are able to use them. They're often very good for exploring the data, browsing the data. And they can be very good for sharing. Again, because so many people have them and know how to use them. By far the most common application for data work is going to be the humble spreadsheet, and there are a few reasons why this should be the case. Number one, I consider spreadsheets the universal data tool. It's my untested theory that there are more datasets in spreadsheets than in any other format in the world. The rows and columns are very familiar to a very large number of people and they know how to explore the data and access it using those tools. The most common by far is Microsoft Excel and its many versions. Google Sheets is also extremely common, and there are others. The great thing about spreadsheets is they're good for browsing. You sort through the data, you filter the data. It makes it really easy to get a hands-on look at what's going on in there. They're also great for exporting and sharing the data. Any program in the world can read a .csv file, a "comma separated values", which is the generic version of a spreadsheet. Your client will probably give you the data in a spreadsheet, they'll probably want the results back in a spreadsheet. You can do want in-between, but that spreadsheet is going to serve as the common ground. Another very common data tool, even though it's not really an application, but a language, is S-Q-L or SQL, which stands for "Structured Query Language." This is a way of accessing data storing databases, usually relational databases, where you select the data, you specify the criteria you want, you can combine it and reformat in ways that best work. You only need maybe a dozen or so commands in SQL to accomplish the majority of tasks that you need. So a little bit of familiarity with SQL is going to go a very long way. And then there are the dedicated apps for visualization. That includes things like Tableau, both the desktop and the public and server version, and Qlik. What these do is they facilitate data integration, that's one of their great things. They bring in data from lots of different sources and formats, and put it together in a pretty seamless way. Their purpose is interactive data exploration. To click on set groups, to drill down, to expand what you have, and they're very very good at that. And then there are apps for data analysis. So these are applications that are specifically designed for point-and-click data analysis. And I know a lot of data scientists think that coding is always better at everything, but the point-and-click graphical user interface makes things accessible to a very large number of people. And so this includes common programs like SPSS, or JASP, or my personal favorite, jamovi. JASP and jamovi are both free and open source. And what they do is they make the analysis friendly. Again, the more people you can get working with data, the better, and these applications are very good at democratizing data. But whatever you do, just remember to stay focused on your question, and let the tools and the techniques follow your question. Start simple, with the basic applications, and move on only as the question requires it. That way, you can be sure to find the meaning and the value as you uncover it in your data.

## 2. Languages for data science

I love the saxophone I play it very badly but I love to listen to it and one of the curious things about the saxophone is that if you want to play gigs professionally you can't play just the saxophone at the very least you have to play both the alto and tenor saxophone as well as the flute and the clarinet and for other gigs you may need to be able to play obo, English horn, bassoon bass clarinet, and even recorder and chrome horn like one of my teachers. You have to be a musical polyglot. I mention this because one of the most common questions in data science is whether you should work in Python or in R, two very common languages for working with data. The reason this question comes up is because programming languages give you immense control over your work and data science. You may find that your questions go beyond the capabilities of data analysis applications and so the ability to create something custom tailored that matches your needs exactly, which is the whole point of data science in the first place is going to be critical. But let me say something more about Python and R Now Python is currently the most popular language for data science and machine learning. It's a general purpose programming language. You can do anything with Python and people do enormous numbers of things that are outside of data science with it. Also, Python code is very clean and it's very easy to learn So there are some great advantages to Python R on the other hand, is a programming language that was developed specifically for work in data analysis. And R is still very popular with scientists and with researchers. Now, there are some important technical differences between the two such as the fact that R works natively with vectorized operations and as non standard evaluation and Python manages memory and large data sets better in its default setup but neither of those is fixed, both of them can be adapted to do other things. And really, the thumb of this is that like any professional saxophonist is going to need to be able to play several different instruments any professional data scientist is going to need to be able to work comfortably in several different languages. So those languages can include both Python and R they can include SQL or Structured Query Language or Java or Julia or Scala or MATLAB really, all of these serve different purposes they overlap but depending both on the question that you are trying to answer, the kind of data that you have, and the level at which you're working, you may need to work with some, many or all of these. Now, I do want to mention one other reason why programming languages are so helpful in data science and that's because you can expand their functionality with packages these are collections of code that you can download that give extra functionality or facilitate the entire process of working with data and often, it is the packages that are more influential than the actual language. So things like TensorFlow which make it so easy to do deep learning neural networks you can use that in Python or in R and it's going to facilitate your work but no matter what language you use and what packages you use it is true that the programming languages that are used in data science are going to give you this really fine level control over your analysis and let you tailor it to the data and to the questions that you have.

## 3. Machine learning as a service

One of the things that is most predictable about technology is that things get faster, smaller, easier, and better over time. This is the essence of Moore's Law, which originally talked about just the density of transistors on circuits doubling every two years, but think about, for instance, the women working here on ENIAC, that's the Electronic Numerical Integrator and Computer, which was the first electronic general-purpose computer back in 1945. It was huge. It filled up a room and it took a whole team of people to run it. Then things evolved, for instance, to very colorful reel-to-reel computers, then you get your desktop Macintosh, I still have my Classic II, and before you know it, you're running your billion-dollar tech company from your cell phone. One of the most important developments in the internet era has been SaaS, or software as a service. Just think of anytime you've used an online application like Excel Online instead of an application installed locally on your computer like the regular desktop version of Excel. That is a way of making the application more accessible because anybody can get onto it with any machine connected to the internet, and really more useful to people. Well, a similar revolution is happening now in data science with machine learning as a service. It's not as easy to pronounce MLaaS, but it's a way of making the entire process of data science, machine learning, and artificial intelligence easier to access, easier to setup, and easier to get going. All the major cloud data providers have recently announced these machine learning as a service offerings. So for instance, there's Microsoft Azure ML, there's Amazon Machine Learning, and Google AutoML, and IBM Watson Analytics, and all of these have some very closely-related advantages, things that make your life a lot easier. Number one, they put the analysis where the data is stored. You've got your massive and complex data sets but they're stored in the servers that each of these services have, and so you don't have to do an export and import, you just go right where the data is. Also, most of them give you very flexible computing requirements. It's not like you have to purchase the hardware. You can rent CPUs and GPUs. You can rent RAM and hard drive space as you need it. They also frequently give you a drag-and-drop interface that makes the programming and the setup of the analysis dramatically easier. Again, the point here is that it democratizes the process, it makes it more accessible for more people in more circumstances. And that is part of the promise of data science. Now, it's too early to project very far into the future and see what all of the exact consequences of this revolution will be, especially because new services are being announced and major changes are being made all the time. But the idea, again, with machine learning as a service is that it puts the analysis where the data is and it makes it more open and more available to more people. Again, it's the democratization of data science, and that's the promise of machine learning as a service.